{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 17:29:24.917458: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-22 17:29:30,742 - INFO - Processing dataset: CUSPH-SR-AF with filters: [32, 64, 128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "73/73 [==============================] - 232s 3s/step - loss: 0.2714 - accuracy: 0.8843 - val_loss: 0.5711 - val_accuracy: 0.7903\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 214s 3s/step - loss: 0.0694 - accuracy: 0.9822 - val_loss: 0.4811 - val_accuracy: 0.9497\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 200s 3s/step - loss: 0.0353 - accuracy: 0.9900 - val_loss: 0.4180 - val_accuracy: 0.8839\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 189s 3s/step - loss: 0.0447 - accuracy: 0.9861 - val_loss: 0.2381 - val_accuracy: 0.9757\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 190s 3s/step - loss: 0.0238 - accuracy: 0.9905 - val_loss: 0.1989 - val_accuracy: 0.9671\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 189s 3s/step - loss: 0.0257 - accuracy: 0.9931 - val_loss: 0.0715 - val_accuracy: 0.9827\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 216s 3s/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.0782 - val_accuracy: 0.9653\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 181s 2s/step - loss: 0.0388 - accuracy: 0.9879 - val_loss: 0.0440 - val_accuracy: 0.9879\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 182s 3s/step - loss: 0.0197 - accuracy: 0.9931 - val_loss: 0.0490 - val_accuracy: 0.9913\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 176s 2s/step - loss: 0.0096 - accuracy: 0.9978 - val_loss: 0.0313 - val_accuracy: 0.9931\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 176s 2s/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.0394 - val_accuracy: 0.9931\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 177s 2s/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0388 - val_accuracy: 0.9913\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 190s 3s/step - loss: 8.9465e-04 - accuracy: 1.0000 - val_loss: 0.0358 - val_accuracy: 0.9931\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 192s 3s/step - loss: 0.0049 - accuracy: 0.9996 - val_loss: 0.0570 - val_accuracy: 0.9879\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 186s 3s/step - loss: 0.0659 - accuracy: 0.9827 - val_loss: 0.0902 - val_accuracy: 0.9688\n",
      "23/23 [==============================] - 11s 419ms/step\n",
      "23/23 [==============================] - 12s 507ms/step\n",
      "Epoch 1/100\n",
      "289/289 [==============================] - 914s 3s/step - loss: 0.1094 - accuracy: 0.9565 - val_loss: 0.2555 - val_accuracy: 0.9705\n",
      "Epoch 2/100\n",
      "289/289 [==============================] - 846s 3s/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.1276 - val_accuracy: 0.9827\n",
      "Epoch 3/100\n",
      "289/289 [==============================] - 731s 3s/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 0.0589 - val_accuracy: 0.9896\n",
      "Epoch 4/100\n",
      "289/289 [==============================] - 895s 3s/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0320 - val_accuracy: 0.9913\n",
      "Epoch 5/100\n",
      "289/289 [==============================] - 829s 3s/step - loss: 0.0224 - accuracy: 0.9928 - val_loss: 0.0327 - val_accuracy: 0.9879\n",
      "Epoch 6/100\n",
      "289/289 [==============================] - 789s 3s/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0214 - val_accuracy: 0.9913\n",
      "Epoch 7/100\n",
      "289/289 [==============================] - 729s 3s/step - loss: 6.3023e-04 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 0.9931\n",
      "Epoch 8/100\n",
      "289/289 [==============================] - 738s 3s/step - loss: 1.8425e-04 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 0.9913\n",
      "Epoch 9/100\n",
      "289/289 [==============================] - 765s 3s/step - loss: 9.4040e-05 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9913\n",
      "Epoch 10/100\n",
      "289/289 [==============================] - 790s 3s/step - loss: 1.3708e-04 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.9913\n",
      "Epoch 11/100\n",
      "289/289 [==============================] - 896s 3s/step - loss: 6.3363e-05 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9896\n",
      "23/23 [==============================] - 13s 452ms/step\n",
      "23/23 [==============================] - 11s 494ms/step\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 228s 3s/step - loss: 0.2355 - accuracy: 0.8973 - val_loss: 0.6822 - val_accuracy: 0.5425\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 256s 4s/step - loss: 0.1019 - accuracy: 0.9671 - val_loss: 0.6896 - val_accuracy: 0.5425\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 241s 3s/step - loss: 0.0691 - accuracy: 0.9801 - val_loss: 0.7057 - val_accuracy: 0.5425\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 246s 3s/step - loss: 0.0750 - accuracy: 0.9766 - val_loss: 0.5807 - val_accuracy: 0.8423\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 241s 3s/step - loss: 0.0495 - accuracy: 0.9870 - val_loss: 0.4868 - val_accuracy: 0.6586\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 237s 3s/step - loss: 0.0571 - accuracy: 0.9822 - val_loss: 0.1552 - val_accuracy: 0.9757\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 231s 3s/step - loss: 0.0496 - accuracy: 0.9844 - val_loss: 0.1254 - val_accuracy: 0.9688\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 243s 3s/step - loss: 0.0599 - accuracy: 0.9796 - val_loss: 0.1793 - val_accuracy: 0.9671\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 242s 3s/step - loss: 0.0392 - accuracy: 0.9900 - val_loss: 0.0816 - val_accuracy: 0.9792\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 236s 3s/step - loss: 0.0432 - accuracy: 0.9887 - val_loss: 0.0687 - val_accuracy: 0.9809\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 226s 3s/step - loss: 0.0319 - accuracy: 0.9879 - val_loss: 0.0507 - val_accuracy: 0.9809\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 231s 3s/step - loss: 0.0303 - accuracy: 0.9918 - val_loss: 0.1695 - val_accuracy: 0.9445\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 260s 4s/step - loss: 0.0271 - accuracy: 0.9922 - val_loss: 0.0670 - val_accuracy: 0.9844\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 218s 3s/step - loss: 0.0252 - accuracy: 0.9939 - val_loss: 0.0762 - val_accuracy: 0.9827\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 212s 3s/step - loss: 0.0643 - accuracy: 0.9801 - val_loss: 0.4001 - val_accuracy: 0.9099\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 217s 3s/step - loss: 0.0344 - accuracy: 0.9905 - val_loss: 0.0604 - val_accuracy: 0.9792\n",
      "23/23 [==============================] - 14s 492ms/step\n",
      "23/23 [==============================] - 12s 523ms/step\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 257s 3s/step - loss: 0.2402 - accuracy: 0.9055 - val_loss: 1.2750 - val_accuracy: 0.4575\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 246s 3s/step - loss: 0.1243 - accuracy: 0.9640 - val_loss: 1.2447 - val_accuracy: 0.4575\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 231s 3s/step - loss: 0.0745 - accuracy: 0.9796 - val_loss: 1.5900 - val_accuracy: 0.4575\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 271s 4s/step - loss: 0.0749 - accuracy: 0.9757 - val_loss: 2.6338 - val_accuracy: 0.4575\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 227s 3s/step - loss: 0.0638 - accuracy: 0.9822 - val_loss: 1.1562 - val_accuracy: 0.4575\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 217s 3s/step - loss: 0.0554 - accuracy: 0.9861 - val_loss: 0.7211 - val_accuracy: 0.5321\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 217s 3s/step - loss: 0.0486 - accuracy: 0.9853 - val_loss: 0.6011 - val_accuracy: 0.6430\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 219s 3s/step - loss: 0.0561 - accuracy: 0.9827 - val_loss: 0.0724 - val_accuracy: 0.9861\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 202s 3s/step - loss: 0.0376 - accuracy: 0.9896 - val_loss: 0.0945 - val_accuracy: 0.9792\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 198s 3s/step - loss: 0.0689 - accuracy: 0.9801 - val_loss: 1.2285 - val_accuracy: 0.7782\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 193s 3s/step - loss: 0.0399 - accuracy: 0.9887 - val_loss: 0.1689 - val_accuracy: 0.9636\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 190s 3s/step - loss: 0.0263 - accuracy: 0.9935 - val_loss: 0.1542 - val_accuracy: 0.9549\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 187s 3s/step - loss: 0.0223 - accuracy: 0.9926 - val_loss: 0.0881 - val_accuracy: 0.9809\n",
      "23/23 [==============================] - 11s 416ms/step\n",
      "23/23 [==============================] - 10s 449ms/step\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 208s 3s/step - loss: 0.3604 - accuracy: 0.8279 - val_loss: 0.7615 - val_accuracy: 0.4575\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 184s 3s/step - loss: 0.1614 - accuracy: 0.9363 - val_loss: 0.7950 - val_accuracy: 0.4575\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 184s 3s/step - loss: 0.1030 - accuracy: 0.9632 - val_loss: 0.8392 - val_accuracy: 0.4575\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 182s 2s/step - loss: 0.1011 - accuracy: 0.9684 - val_loss: 0.7739 - val_accuracy: 0.4575\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 183s 3s/step - loss: 0.0661 - accuracy: 0.9783 - val_loss: 0.6747 - val_accuracy: 0.5598\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 184s 3s/step - loss: 0.0824 - accuracy: 0.9705 - val_loss: 1.3196 - val_accuracy: 0.4679\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 189s 3s/step - loss: 0.0592 - accuracy: 0.9792 - val_loss: 0.1840 - val_accuracy: 0.9393\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 195s 3s/step - loss: 0.0758 - accuracy: 0.9727 - val_loss: 0.1106 - val_accuracy: 0.9584\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 195s 3s/step - loss: 0.0552 - accuracy: 0.9831 - val_loss: 0.1103 - val_accuracy: 0.9688\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 194s 3s/step - loss: 0.0584 - accuracy: 0.9805 - val_loss: 0.1693 - val_accuracy: 0.9705\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 196s 3s/step - loss: 0.0541 - accuracy: 0.9835 - val_loss: 0.1263 - val_accuracy: 0.9636\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 195s 3s/step - loss: 0.0429 - accuracy: 0.9857 - val_loss: 0.4438 - val_accuracy: 0.9272\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 196s 3s/step - loss: 0.0308 - accuracy: 0.9896 - val_loss: 0.0805 - val_accuracy: 0.9757\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 195s 3s/step - loss: 0.0488 - accuracy: 0.9853 - val_loss: 0.1610 - val_accuracy: 0.9740\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 195s 3s/step - loss: 0.0801 - accuracy: 0.9697 - val_loss: 0.0957 - val_accuracy: 0.9757\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 195s 3s/step - loss: 0.0383 - accuracy: 0.9870 - val_loss: 0.1053 - val_accuracy: 0.9723\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 196s 3s/step - loss: 0.0650 - accuracy: 0.9783 - val_loss: 0.2976 - val_accuracy: 0.9601\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 196s 3s/step - loss: 0.0307 - accuracy: 0.9892 - val_loss: 0.1299 - val_accuracy: 0.9757\n",
      "23/23 [==============================] - 11s 417ms/step\n",
      "23/23 [==============================] - 11s 463ms/step\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 218s 3s/step - loss: 0.1923 - accuracy: 0.9228 - val_loss: 0.7145 - val_accuracy: 0.4575\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 183s 3s/step - loss: 0.0772 - accuracy: 0.9779 - val_loss: 0.7258 - val_accuracy: 0.4575\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 176s 2s/step - loss: 0.0671 - accuracy: 0.9770 - val_loss: 0.6628 - val_accuracy: 0.5477\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 176s 2s/step - loss: 0.0619 - accuracy: 0.9840 - val_loss: 0.6844 - val_accuracy: 0.5251\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 177s 2s/step - loss: 0.0507 - accuracy: 0.9827 - val_loss: 0.6120 - val_accuracy: 0.7470\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 177s 2s/step - loss: 0.0492 - accuracy: 0.9861 - val_loss: 0.3861 - val_accuracy: 0.8735\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 177s 2s/step - loss: 0.0453 - accuracy: 0.9883 - val_loss: 0.1545 - val_accuracy: 0.9619\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 176s 2s/step - loss: 0.0519 - accuracy: 0.9857 - val_loss: 0.1066 - val_accuracy: 0.9671\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 176s 2s/step - loss: 0.0376 - accuracy: 0.9892 - val_loss: 0.1063 - val_accuracy: 0.9809\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 175s 2s/step - loss: 0.0324 - accuracy: 0.9896 - val_loss: 0.0789 - val_accuracy: 0.9757\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 176s 2s/step - loss: 0.0317 - accuracy: 0.9909 - val_loss: 0.1014 - val_accuracy: 0.9688\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 176s 2s/step - loss: 0.0222 - accuracy: 0.9926 - val_loss: 0.0895 - val_accuracy: 0.9757\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 177s 2s/step - loss: 0.0268 - accuracy: 0.9926 - val_loss: 0.0937 - val_accuracy: 0.9827\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 176s 2s/step - loss: 0.0272 - accuracy: 0.9926 - val_loss: 0.0833 - val_accuracy: 0.9809\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 176s 2s/step - loss: 0.0568 - accuracy: 0.9809 - val_loss: 0.2206 - val_accuracy: 0.9359\n",
      "23/23 [==============================] - 10s 383ms/step\n",
      "23/23 [==============================] - 9s 411ms/step\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 192s 2s/step - loss: 0.4595 - accuracy: 0.7720 - val_loss: 0.6867 - val_accuracy: 0.5303\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 177s 2s/step - loss: 0.2199 - accuracy: 0.9198 - val_loss: 1.0119 - val_accuracy: 0.4575\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 177s 2s/step - loss: 0.1476 - accuracy: 0.9484 - val_loss: 1.1292 - val_accuracy: 0.4575\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 177s 2s/step - loss: 0.1415 - accuracy: 0.9528 - val_loss: 0.9369 - val_accuracy: 0.4575\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 177s 2s/step - loss: 0.1013 - accuracy: 0.9662 - val_loss: 0.8016 - val_accuracy: 0.4714\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 176s 2s/step - loss: 0.1044 - accuracy: 0.9593 - val_loss: 0.2563 - val_accuracy: 0.9081\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 177s 2s/step - loss: 0.0876 - accuracy: 0.9710 - val_loss: 0.1435 - val_accuracy: 0.9497\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 176s 2s/step - loss: 0.1005 - accuracy: 0.9645 - val_loss: 0.1429 - val_accuracy: 0.9497\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 176s 2s/step - loss: 0.1044 - accuracy: 0.9649 - val_loss: 0.0970 - val_accuracy: 0.9636\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 175s 2s/step - loss: 0.0653 - accuracy: 0.9775 - val_loss: 0.1082 - val_accuracy: 0.9688\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 176s 2s/step - loss: 0.0635 - accuracy: 0.9749 - val_loss: 0.1053 - val_accuracy: 0.9567\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 175s 2s/step - loss: 0.0780 - accuracy: 0.9718 - val_loss: 0.1339 - val_accuracy: 0.9619\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 176s 2s/step - loss: 0.0593 - accuracy: 0.9796 - val_loss: 0.1439 - val_accuracy: 0.9619\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0587 - accuracy: 0.9762 - val_loss: 0.0877 - val_accuracy: 0.9740\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.1211 - accuracy: 0.9584 - val_loss: 0.1274 - val_accuracy: 0.9636\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 177s 2s/step - loss: 0.0486 - accuracy: 0.9814 - val_loss: 0.1217 - val_accuracy: 0.9688\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 176s 2s/step - loss: 0.0967 - accuracy: 0.9697 - val_loss: 0.1264 - val_accuracy: 0.9532\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 178s 2s/step - loss: 0.0462 - accuracy: 0.9801 - val_loss: 0.1452 - val_accuracy: 0.9428\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 175s 2s/step - loss: 0.0450 - accuracy: 0.9866 - val_loss: 0.1504 - val_accuracy: 0.9584\n",
      "23/23 [==============================] - 11s 394ms/step\n",
      "23/23 [==============================] - 9s 401ms/step\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 190s 2s/step - loss: 0.3091 - accuracy: 0.8708 - val_loss: 0.7251 - val_accuracy: 0.5425\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.1447 - accuracy: 0.9450 - val_loss: 0.7324 - val_accuracy: 0.5425\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0789 - accuracy: 0.9718 - val_loss: 0.7693 - val_accuracy: 0.5425\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0820 - accuracy: 0.9714 - val_loss: 0.7328 - val_accuracy: 0.5425\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 175s 2s/step - loss: 0.0937 - accuracy: 0.9705 - val_loss: 0.6729 - val_accuracy: 0.5546\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 175s 2s/step - loss: 0.0740 - accuracy: 0.9796 - val_loss: 0.3685 - val_accuracy: 0.8527\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 176s 2s/step - loss: 0.0611 - accuracy: 0.9792 - val_loss: 0.1628 - val_accuracy: 0.9411\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0590 - accuracy: 0.9827 - val_loss: 0.0899 - val_accuracy: 0.9723\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 175s 2s/step - loss: 0.0539 - accuracy: 0.9848 - val_loss: 0.0915 - val_accuracy: 0.9740\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0490 - accuracy: 0.9827 - val_loss: 0.0704 - val_accuracy: 0.9844\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0567 - accuracy: 0.9818 - val_loss: 0.1796 - val_accuracy: 0.9601\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 176s 2s/step - loss: 0.0375 - accuracy: 0.9892 - val_loss: 0.0802 - val_accuracy: 0.9809\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0407 - accuracy: 0.9848 - val_loss: 0.2305 - val_accuracy: 0.9272\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0616 - accuracy: 0.9801 - val_loss: 0.2166 - val_accuracy: 0.9480\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0542 - accuracy: 0.9844 - val_loss: 0.2062 - val_accuracy: 0.9341\n",
      "23/23 [==============================] - 10s 388ms/step\n",
      "23/23 [==============================] - 9s 396ms/step\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 191s 2s/step - loss: 0.3230 - accuracy: 0.8617 - val_loss: 0.7696 - val_accuracy: 0.4575\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 176s 2s/step - loss: 0.1459 - accuracy: 0.9515 - val_loss: 0.9626 - val_accuracy: 0.4575\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 175s 2s/step - loss: 0.1063 - accuracy: 0.9632 - val_loss: 0.9872 - val_accuracy: 0.4575\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 175s 2s/step - loss: 0.0842 - accuracy: 0.9710 - val_loss: 0.7248 - val_accuracy: 0.4974\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 175s 2s/step - loss: 0.0821 - accuracy: 0.9749 - val_loss: 0.4801 - val_accuracy: 0.8284\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 175s 2s/step - loss: 0.0760 - accuracy: 0.9779 - val_loss: 0.3630 - val_accuracy: 0.8666\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 175s 2s/step - loss: 0.0551 - accuracy: 0.9818 - val_loss: 0.1289 - val_accuracy: 0.9515\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0564 - accuracy: 0.9801 - val_loss: 0.1535 - val_accuracy: 0.9411\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0433 - accuracy: 0.9835 - val_loss: 0.0881 - val_accuracy: 0.9601\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 175s 2s/step - loss: 0.0687 - accuracy: 0.9796 - val_loss: 0.2092 - val_accuracy: 0.9359\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 175s 2s/step - loss: 0.0474 - accuracy: 0.9866 - val_loss: 0.0614 - val_accuracy: 0.9861\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0285 - accuracy: 0.9900 - val_loss: 0.1548 - val_accuracy: 0.9601\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 175s 2s/step - loss: 0.0246 - accuracy: 0.9900 - val_loss: 0.0362 - val_accuracy: 0.9913\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 175s 2s/step - loss: 0.0395 - accuracy: 0.9870 - val_loss: 0.3716 - val_accuracy: 0.9376\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0679 - accuracy: 0.9809 - val_loss: 0.1537 - val_accuracy: 0.9619\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0343 - accuracy: 0.9870 - val_loss: 0.1636 - val_accuracy: 0.9185\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0246 - accuracy: 0.9918 - val_loss: 0.0297 - val_accuracy: 0.9896\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0191 - accuracy: 0.9918 - val_loss: 0.0361 - val_accuracy: 0.9879\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0214 - accuracy: 0.9918 - val_loss: 0.0662 - val_accuracy: 0.9809\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 0.0482 - val_accuracy: 0.9861\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0129 - accuracy: 0.9948 - val_loss: 0.0717 - val_accuracy: 0.9740\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0832 - accuracy: 0.9749 - val_loss: 0.1195 - val_accuracy: 0.9636\n",
      "23/23 [==============================] - 10s 381ms/step\n",
      "23/23 [==============================] - 9s 407ms/step\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 191s 2s/step - loss: 0.4774 - accuracy: 0.7737 - val_loss: 0.6963 - val_accuracy: 0.4575\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.3670 - accuracy: 0.8440 - val_loss: 0.7773 - val_accuracy: 0.4575\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.2170 - accuracy: 0.9163 - val_loss: 0.8379 - val_accuracy: 0.4575\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.1993 - accuracy: 0.9332 - val_loss: 1.1773 - val_accuracy: 0.4575\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.1432 - accuracy: 0.9463 - val_loss: 1.3059 - val_accuracy: 0.4575\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.1106 - accuracy: 0.9614 - val_loss: 0.6515 - val_accuracy: 0.5754\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0969 - accuracy: 0.9688 - val_loss: 0.4316 - val_accuracy: 0.7504\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.1043 - accuracy: 0.9645 - val_loss: 0.0959 - val_accuracy: 0.9636\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0685 - accuracy: 0.9766 - val_loss: 0.0831 - val_accuracy: 0.9671\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0717 - accuracy: 0.9757 - val_loss: 0.0738 - val_accuracy: 0.9775\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0729 - accuracy: 0.9727 - val_loss: 0.0800 - val_accuracy: 0.9740\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 175s 2s/step - loss: 0.0504 - accuracy: 0.9805 - val_loss: 0.0815 - val_accuracy: 0.9757\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0602 - accuracy: 0.9792 - val_loss: 0.1137 - val_accuracy: 0.9636\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0534 - accuracy: 0.9818 - val_loss: 0.0883 - val_accuracy: 0.9792\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.1043 - accuracy: 0.9679 - val_loss: 0.1233 - val_accuracy: 0.9688\n",
      "23/23 [==============================] - 10s 393ms/step\n",
      "23/23 [==============================] - 9s 388ms/step\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 190s 2s/step - loss: 0.4350 - accuracy: 0.8032 - val_loss: 0.7269 - val_accuracy: 0.4575\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.2389 - accuracy: 0.9168 - val_loss: 0.6971 - val_accuracy: 0.4575\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.1697 - accuracy: 0.9454 - val_loss: 0.6754 - val_accuracy: 0.6222\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.1393 - accuracy: 0.9597 - val_loss: 0.6444 - val_accuracy: 0.7002\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 175s 2s/step - loss: 0.1080 - accuracy: 0.9623 - val_loss: 0.6041 - val_accuracy: 0.6915\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0895 - accuracy: 0.9723 - val_loss: 0.3515 - val_accuracy: 0.9272\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0870 - accuracy: 0.9714 - val_loss: 0.4973 - val_accuracy: 0.6984\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0804 - accuracy: 0.9749 - val_loss: 0.1615 - val_accuracy: 0.9601\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0693 - accuracy: 0.9792 - val_loss: 0.0859 - val_accuracy: 0.9757\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0549 - accuracy: 0.9809 - val_loss: 0.0897 - val_accuracy: 0.9653\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0586 - accuracy: 0.9814 - val_loss: 0.0914 - val_accuracy: 0.9740\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0506 - accuracy: 0.9809 - val_loss: 0.0904 - val_accuracy: 0.9792\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0380 - accuracy: 0.9879 - val_loss: 0.0670 - val_accuracy: 0.9757\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 172s 2s/step - loss: 0.0498 - accuracy: 0.9822 - val_loss: 0.0848 - val_accuracy: 0.9671\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0972 - accuracy: 0.9705 - val_loss: 0.3155 - val_accuracy: 0.8908\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 172s 2s/step - loss: 0.0510 - accuracy: 0.9827 - val_loss: 0.0709 - val_accuracy: 0.9757\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0367 - accuracy: 0.9883 - val_loss: 0.0485 - val_accuracy: 0.9844\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0260 - accuracy: 0.9922 - val_loss: 0.0513 - val_accuracy: 0.9896\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0353 - accuracy: 0.9900 - val_loss: 0.1019 - val_accuracy: 0.9688\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0838 - accuracy: 0.9718 - val_loss: 0.8330 - val_accuracy: 0.7504\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0503 - accuracy: 0.9827 - val_loss: 0.2352 - val_accuracy: 0.9203\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0522 - accuracy: 0.9814 - val_loss: 0.0714 - val_accuracy: 0.9688\n",
      "23/23 [==============================] - 10s 381ms/step\n",
      "23/23 [==============================] - 9s 408ms/step\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 190s 2s/step - loss: 0.3700 - accuracy: 0.8375 - val_loss: 0.7531 - val_accuracy: 0.4575\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.1672 - accuracy: 0.9467 - val_loss: 0.7488 - val_accuracy: 0.4575\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.1272 - accuracy: 0.9627 - val_loss: 0.6507 - val_accuracy: 0.6898\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 172s 2s/step - loss: 0.1000 - accuracy: 0.9688 - val_loss: 0.6814 - val_accuracy: 0.5009\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0891 - accuracy: 0.9744 - val_loss: 0.4119 - val_accuracy: 0.8804\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0683 - accuracy: 0.9801 - val_loss: 0.2471 - val_accuracy: 0.9376\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0718 - accuracy: 0.9749 - val_loss: 0.3251 - val_accuracy: 0.8544\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.1027 - accuracy: 0.9636 - val_loss: 0.1325 - val_accuracy: 0.9723\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0635 - accuracy: 0.9805 - val_loss: 0.1247 - val_accuracy: 0.9619\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0535 - accuracy: 0.9822 - val_loss: 0.1043 - val_accuracy: 0.9636\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0603 - accuracy: 0.9814 - val_loss: 0.0926 - val_accuracy: 0.9723\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0462 - accuracy: 0.9857 - val_loss: 0.0638 - val_accuracy: 0.9827\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 172s 2s/step - loss: 0.0455 - accuracy: 0.9848 - val_loss: 0.1342 - val_accuracy: 0.9497\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 172s 2s/step - loss: 0.0425 - accuracy: 0.9874 - val_loss: 0.0944 - val_accuracy: 0.9792\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 172s 2s/step - loss: 0.0886 - accuracy: 0.9731 - val_loss: 0.1598 - val_accuracy: 0.9740\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0549 - accuracy: 0.9848 - val_loss: 0.0855 - val_accuracy: 0.9757\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0423 - accuracy: 0.9861 - val_loss: 0.0980 - val_accuracy: 0.9792\n",
      "23/23 [==============================] - 10s 388ms/step\n",
      "23/23 [==============================] - 9s 396ms/step\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 188s 2s/step - loss: 0.3500 - accuracy: 0.8448 - val_loss: 0.7076 - val_accuracy: 0.4575\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 172s 2s/step - loss: 0.1446 - accuracy: 0.9588 - val_loss: 0.7363 - val_accuracy: 0.4575\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.1056 - accuracy: 0.9710 - val_loss: 0.6965 - val_accuracy: 0.4766\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 172s 2s/step - loss: 0.0998 - accuracy: 0.9727 - val_loss: 0.6891 - val_accuracy: 0.5771\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 172s 2s/step - loss: 0.0918 - accuracy: 0.9718 - val_loss: 0.5983 - val_accuracy: 0.7712\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 171s 2s/step - loss: 0.0793 - accuracy: 0.9749 - val_loss: 0.2597 - val_accuracy: 0.9515\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0945 - accuracy: 0.9697 - val_loss: 0.1658 - val_accuracy: 0.9636\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 172s 2s/step - loss: 0.1015 - accuracy: 0.9684 - val_loss: 1.1960 - val_accuracy: 0.5633\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 172s 2s/step - loss: 0.0704 - accuracy: 0.9822 - val_loss: 0.1180 - val_accuracy: 0.9705\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 172s 2s/step - loss: 0.0659 - accuracy: 0.9796 - val_loss: 0.1740 - val_accuracy: 0.9705\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 172s 2s/step - loss: 0.0678 - accuracy: 0.9796 - val_loss: 0.0928 - val_accuracy: 0.9671\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 174s 2s/step - loss: 0.0521 - accuracy: 0.9844 - val_loss: 0.0984 - val_accuracy: 0.9584\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0588 - accuracy: 0.9831 - val_loss: 0.1145 - val_accuracy: 0.9671\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 172s 2s/step - loss: 0.0604 - accuracy: 0.9809 - val_loss: 0.3277 - val_accuracy: 0.9428\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 172s 2s/step - loss: 0.0763 - accuracy: 0.9753 - val_loss: 0.1151 - val_accuracy: 0.9653\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0556 - accuracy: 0.9822 - val_loss: 0.0880 - val_accuracy: 0.9705\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 172s 2s/step - loss: 0.0441 - accuracy: 0.9853 - val_loss: 0.0978 - val_accuracy: 0.9775\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0382 - accuracy: 0.9887 - val_loss: 0.1226 - val_accuracy: 0.9705\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0441 - accuracy: 0.9879 - val_loss: 0.1452 - val_accuracy: 0.9705\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 172s 2s/step - loss: 0.0349 - accuracy: 0.9874 - val_loss: 0.0916 - val_accuracy: 0.9757\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0391 - accuracy: 0.9848 - val_loss: 0.0813 - val_accuracy: 0.9723\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0953 - accuracy: 0.9688 - val_loss: 0.2015 - val_accuracy: 0.9653\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0443 - accuracy: 0.9848 - val_loss: 0.1010 - val_accuracy: 0.9671\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0395 - accuracy: 0.9866 - val_loss: 0.0837 - val_accuracy: 0.9705\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0373 - accuracy: 0.9892 - val_loss: 0.0654 - val_accuracy: 0.9757\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0560 - accuracy: 0.9788 - val_loss: 0.0778 - val_accuracy: 0.9775\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 172s 2s/step - loss: 0.0638 - accuracy: 0.9801 - val_loss: 0.0929 - val_accuracy: 0.9705\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 172s 2s/step - loss: 0.0728 - accuracy: 0.9770 - val_loss: 0.1005 - val_accuracy: 0.9757\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 172s 2s/step - loss: 0.0419 - accuracy: 0.9857 - val_loss: 0.0716 - val_accuracy: 0.9757\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0371 - accuracy: 0.9866 - val_loss: 0.0841 - val_accuracy: 0.9809\n",
      "23/23 [==============================] - 10s 386ms/step\n",
      "23/23 [==============================] - 9s 395ms/step\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 190s 2s/step - loss: 0.3256 - accuracy: 0.8578 - val_loss: 0.6958 - val_accuracy: 0.4627\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.1564 - accuracy: 0.9489 - val_loss: 0.7112 - val_accuracy: 0.4575\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 172s 2s/step - loss: 0.1079 - accuracy: 0.9666 - val_loss: 0.6902 - val_accuracy: 0.4766\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 172s 2s/step - loss: 0.1151 - accuracy: 0.9632 - val_loss: 0.6858 - val_accuracy: 0.5009\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0877 - accuracy: 0.9731 - val_loss: 0.6373 - val_accuracy: 0.6101\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 172s 2s/step - loss: 0.0905 - accuracy: 0.9688 - val_loss: 0.3004 - val_accuracy: 0.9341\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 172s 2s/step - loss: 0.0869 - accuracy: 0.9723 - val_loss: 0.2230 - val_accuracy: 0.9376\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 181s 2s/step - loss: 0.0727 - accuracy: 0.9753 - val_loss: 0.1031 - val_accuracy: 0.9705\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 182s 2s/step - loss: 0.0642 - accuracy: 0.9775 - val_loss: 0.1180 - val_accuracy: 0.9601\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0566 - accuracy: 0.9809 - val_loss: 0.1776 - val_accuracy: 0.9445\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 173s 2s/step - loss: 0.0628 - accuracy: 0.9809 - val_loss: 0.0891 - val_accuracy: 0.9688\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 171s 2s/step - loss: 0.0511 - accuracy: 0.9827 - val_loss: 0.1152 - val_accuracy: 0.9601\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 172s 2s/step - loss: 0.0545 - accuracy: 0.9783 - val_loss: 0.1060 - val_accuracy: 0.9619\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 171s 2s/step - loss: 0.0415 - accuracy: 0.9861 - val_loss: 0.1015 - val_accuracy: 0.9671\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 171s 2s/step - loss: 0.0978 - accuracy: 0.9671 - val_loss: 0.1770 - val_accuracy: 0.9636\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 170s 2s/step - loss: 0.0635 - accuracy: 0.9805 - val_loss: 0.0928 - val_accuracy: 0.9723\n",
      "23/23 [==============================] - 10s 391ms/step\n",
      "23/23 [==============================] - 9s 394ms/step\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 141s 2s/step - loss: 0.7716 - accuracy: 0.5248 - val_loss: 0.9632 - val_accuracy: 0.5594\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 124s 2s/step - loss: 0.6925 - accuracy: 0.5397 - val_loss: 0.7409 - val_accuracy: 0.5693\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 123s 2s/step - loss: 0.6954 - accuracy: 0.5403 - val_loss: 0.7637 - val_accuracy: 0.5668\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 123s 2s/step - loss: 0.7544 - accuracy: 0.5323 - val_loss: 0.7883 - val_accuracy: 0.4356\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 124s 2s/step - loss: 0.6854 - accuracy: 0.5385 - val_loss: 0.6934 - val_accuracy: 0.5693\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 123s 2s/step - loss: 0.6835 - accuracy: 0.5409 - val_loss: 0.6882 - val_accuracy: 0.5718\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 123s 2s/step - loss: 0.6794 - accuracy: 0.5434 - val_loss: 0.6868 - val_accuracy: 0.5718\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 124s 2s/step - loss: 0.6789 - accuracy: 0.5440 - val_loss: 0.6854 - val_accuracy: 0.5693\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 123s 2s/step - loss: 0.6799 - accuracy: 0.5440 - val_loss: 0.6864 - val_accuracy: 0.5693\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 123s 2s/step - loss: 0.6804 - accuracy: 0.5136 - val_loss: 0.6885 - val_accuracy: 0.5693\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 123s 2s/step - loss: 0.6791 - accuracy: 0.5440 - val_loss: 0.6878 - val_accuracy: 0.5693\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 127s 3s/step - loss: 0.6791 - accuracy: 0.5440 - val_loss: 0.6897 - val_accuracy: 0.5693\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 131s 3s/step - loss: 0.6785 - accuracy: 0.5440 - val_loss: 0.6887 - val_accuracy: 0.5693\n",
      "63/63 [==============================] - 31s 481ms/step\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 199s 3s/step - loss: 0.2958 - accuracy: 0.8743 - val_loss: 0.7166 - val_accuracy: 0.4575\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 182s 3s/step - loss: 0.0904 - accuracy: 0.9714 - val_loss: 0.6637 - val_accuracy: 0.7227\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 181s 2s/step - loss: 0.0440 - accuracy: 0.9874 - val_loss: 0.6860 - val_accuracy: 0.5425\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 181s 2s/step - loss: 0.0315 - accuracy: 0.9896 - val_loss: 0.7023 - val_accuracy: 0.5425\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 184s 3s/step - loss: 0.0280 - accuracy: 0.9909 - val_loss: 0.7290 - val_accuracy: 0.5425\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 182s 2s/step - loss: 0.0241 - accuracy: 0.9918 - val_loss: 0.9370 - val_accuracy: 0.5425\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 183s 3s/step - loss: 0.0378 - accuracy: 0.9883 - val_loss: 0.5920 - val_accuracy: 0.6984\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 185s 3s/step - loss: 0.0148 - accuracy: 0.9970 - val_loss: 0.1800 - val_accuracy: 0.9480\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 186s 3s/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.1754 - val_accuracy: 0.9428\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 185s 3s/step - loss: 0.0068 - accuracy: 0.9974 - val_loss: 0.0859 - val_accuracy: 0.9827\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 186s 3s/step - loss: 0.0088 - accuracy: 0.9978 - val_loss: 0.0201 - val_accuracy: 0.9931\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 185s 3s/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0602 - val_accuracy: 0.9896\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 185s 3s/step - loss: 8.0416e-04 - accuracy: 1.0000 - val_loss: 0.0592 - val_accuracy: 0.9879\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 186s 3s/step - loss: 0.0049 - accuracy: 0.9996 - val_loss: 0.1094 - val_accuracy: 0.9827\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 186s 3s/step - loss: 0.0873 - accuracy: 0.9749 - val_loss: 0.0444 - val_accuracy: 0.9861\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 186s 3s/step - loss: 0.0220 - accuracy: 0.9935 - val_loss: 0.0663 - val_accuracy: 0.9757\n",
      "23/23 [==============================] - 12s 436ms/step\n",
      "23/23 [==============================] - 10s 445ms/step\n",
      "Epoch 1/100\n",
      "9/9 [==============================] - 51s 4s/step - loss: 0.5755 - accuracy: 0.6771 - val_loss: 0.6722 - val_accuracy: 0.5617\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.3874 - accuracy: 0.8299 - val_loss: 0.6633 - val_accuracy: 0.7282\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.2194 - accuracy: 0.9097 - val_loss: 0.6518 - val_accuracy: 0.7226\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.1282 - accuracy: 0.9444 - val_loss: 0.6323 - val_accuracy: 0.6644\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0708 - accuracy: 0.9826 - val_loss: 0.6066 - val_accuracy: 0.7393\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0853 - accuracy: 0.9549 - val_loss: 0.5935 - val_accuracy: 0.7254\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0587 - accuracy: 0.9792 - val_loss: 0.5753 - val_accuracy: 0.7878\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0278 - accuracy: 0.9965 - val_loss: 0.5472 - val_accuracy: 0.8350\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0186 - accuracy: 0.9965 - val_loss: 0.5385 - val_accuracy: 0.8239\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.5487 - val_accuracy: 0.8350\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.5546 - val_accuracy: 0.8516\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.5378 - val_accuracy: 0.8863\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5300 - val_accuracy: 0.8627\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5248 - val_accuracy: 0.8516\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5213 - val_accuracy: 0.8530\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5137 - val_accuracy: 0.8738\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.8821\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5078 - val_accuracy: 0.8516\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5049 - val_accuracy: 0.8474\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 7.3214e-04 - accuracy: 1.0000 - val_loss: 0.4994 - val_accuracy: 0.8488\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4926 - val_accuracy: 0.8488\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 6.3617e-04 - accuracy: 1.0000 - val_loss: 0.4858 - val_accuracy: 0.8502\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4767 - val_accuracy: 0.8544\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 5.9714e-04 - accuracy: 1.0000 - val_loss: 0.4798 - val_accuracy: 0.8225\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4549 - val_accuracy: 0.8530\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 9.3917e-04 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.8710\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4315 - val_accuracy: 0.8766\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 5.7906e-04 - accuracy: 1.0000 - val_loss: 0.4450 - val_accuracy: 0.8350\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4344 - val_accuracy: 0.8266\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 4.2356e-04 - accuracy: 1.0000 - val_loss: 0.4113 - val_accuracy: 0.8571\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 3.3986e-04 - accuracy: 1.0000 - val_loss: 0.4009 - val_accuracy: 0.8613\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 2.0499e-04 - accuracy: 1.0000 - val_loss: 0.3904 - val_accuracy: 0.8696\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 3.8537e-04 - accuracy: 1.0000 - val_loss: 0.3772 - val_accuracy: 0.8738\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 3.4932e-04 - accuracy: 1.0000 - val_loss: 0.3639 - val_accuracy: 0.8807\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 3.5935e-04 - accuracy: 1.0000 - val_loss: 0.3478 - val_accuracy: 0.8849\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 2.2120e-04 - accuracy: 1.0000 - val_loss: 0.3307 - val_accuracy: 0.8988\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 1.8521e-04 - accuracy: 1.0000 - val_loss: 0.3147 - val_accuracy: 0.9001\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 4.5155e-04 - accuracy: 1.0000 - val_loss: 0.2954 - val_accuracy: 0.9057\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 1.6826e-04 - accuracy: 1.0000 - val_loss: 0.2761 - val_accuracy: 0.9112\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 1.5480e-04 - accuracy: 1.0000 - val_loss: 0.2575 - val_accuracy: 0.9126\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 1.0698e-04 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9182\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 1.5664e-04 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9223\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 1.2889e-04 - accuracy: 1.0000 - val_loss: 0.2097 - val_accuracy: 0.9307\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 1.8773e-04 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9320\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 7.9838e-05 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9362\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 5.3685e-05 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9390\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 9.7240e-05 - accuracy: 1.0000 - val_loss: 0.1641 - val_accuracy: 0.9390\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 7.6566e-05 - accuracy: 1.0000 - val_loss: 0.1548 - val_accuracy: 0.9431\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 6.8071e-05 - accuracy: 1.0000 - val_loss: 0.1470 - val_accuracy: 0.9501\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 1.0875e-04 - accuracy: 1.0000 - val_loss: 0.1406 - val_accuracy: 0.9528\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 1.5113e-04 - accuracy: 1.0000 - val_loss: 0.1360 - val_accuracy: 0.9556\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 1.2224e-04 - accuracy: 1.0000 - val_loss: 0.1323 - val_accuracy: 0.9570\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 2.6008e-04 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9570\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 1.0619e-04 - accuracy: 1.0000 - val_loss: 0.1269 - val_accuracy: 0.9570\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 1.1326e-04 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9584\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 5.4827e-05 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9584\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 5.1795e-05 - accuracy: 1.0000 - val_loss: 0.1165 - val_accuracy: 0.9584\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 6.4361e-05 - accuracy: 1.0000 - val_loss: 0.1134 - val_accuracy: 0.9584\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 4.7883e-05 - accuracy: 1.0000 - val_loss: 0.1109 - val_accuracy: 0.9598\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 1.3246e-04 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9612\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 1.0445e-04 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9653\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 8.9408e-05 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9653\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 4.0481e-04 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9639\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 5.7830e-05 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9653\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 7.8161e-05 - accuracy: 1.0000 - val_loss: 0.1065 - val_accuracy: 0.9681\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 9.3956e-05 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9764\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 6.2395e-05 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9778\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 2.1974e-05 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9792\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 7.2817e-05 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9792\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 3.9894e-05 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9792\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 2.4978e-05 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9792\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 4.9724e-05 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 0.9806\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 1.4366e-05 - accuracy: 1.0000 - val_loss: 0.0947 - val_accuracy: 0.9806\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 3.0265e-05 - accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 0.9806\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 3.5203e-05 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 0.9820\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 2.7624e-05 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9820\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 4.5820e-05 - accuracy: 1.0000 - val_loss: 0.0916 - val_accuracy: 0.9820\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 4.3042e-05 - accuracy: 1.0000 - val_loss: 0.0905 - val_accuracy: 0.9820\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 1.7595e-05 - accuracy: 1.0000 - val_loss: 0.0896 - val_accuracy: 0.9820\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 2.7543e-05 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9820\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 1.7768e-05 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9820\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 4.5676e-05 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9834\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 8.5377e-05 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9834\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 1.7472e-05 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9834\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 2.8605e-05 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9834\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 31s 4s/step - loss: 1.8518e-05 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9834\n",
      "23/23 [==============================] - 11s 406ms/step\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 88s 3s/step - loss: 0.4907 - accuracy: 0.7656 - val_loss: 0.7106 - val_accuracy: 0.4854\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.2597 - accuracy: 0.8918 - val_loss: 0.6210 - val_accuracy: 0.6144\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0863 - accuracy: 0.9764 - val_loss: 0.6360 - val_accuracy: 0.5243\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0562 - accuracy: 0.9820 - val_loss: 0.6371 - val_accuracy: 0.5035\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0372 - accuracy: 0.9903 - val_loss: 0.5951 - val_accuracy: 0.5576\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0208 - accuracy: 0.9945 - val_loss: 0.4318 - val_accuracy: 0.9223\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0211 - accuracy: 0.9958 - val_loss: 0.4419 - val_accuracy: 0.9126\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 65s 3s/step - loss: 0.0237 - accuracy: 0.9958 - val_loss: 0.4601 - val_accuracy: 0.8502\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 65s 3s/step - loss: 0.0283 - accuracy: 0.9931 - val_loss: 0.5514 - val_accuracy: 0.6297\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0209 - accuracy: 0.9931 - val_loss: 0.3713 - val_accuracy: 0.9223\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0106 - accuracy: 0.9986 - val_loss: 0.3289 - val_accuracy: 0.9307\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9556\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2195 - val_accuracy: 0.9431\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1919 - val_accuracy: 0.9584\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 64s 3s/step - loss: 8.0447e-04 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 0.9626\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 65s 3s/step - loss: 0.0048 - accuracy: 0.9972 - val_loss: 0.1541 - val_accuracy: 0.9542\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0402 - accuracy: 0.9945 - val_loss: 0.1412 - val_accuracy: 0.9612\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 65s 3s/step - loss: 0.0078 - accuracy: 0.9986 - val_loss: 0.0618 - val_accuracy: 0.9889\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.0740 - val_accuracy: 0.9792\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 65s 3s/step - loss: 0.0203 - accuracy: 0.9972 - val_loss: 0.2737 - val_accuracy: 0.8946\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0156 - accuracy: 0.9931 - val_loss: 0.0855 - val_accuracy: 0.9806\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0201 - accuracy: 0.9986 - val_loss: 0.0844 - val_accuracy: 0.9903\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 64s 3s/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2979 - val_accuracy: 0.8932\n",
      "23/23 [==============================] - 11s 414ms/step\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 140s 3s/step - loss: 0.3723 - accuracy: 0.8419 - val_loss: 0.6738 - val_accuracy: 0.4882\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 119s 3s/step - loss: 0.0958 - accuracy: 0.9702 - val_loss: 0.5856 - val_accuracy: 0.5506\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 118s 3s/step - loss: 0.0549 - accuracy: 0.9861 - val_loss: 0.6240 - val_accuracy: 0.5215\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 119s 3s/step - loss: 0.0338 - accuracy: 0.9910 - val_loss: 0.5023 - val_accuracy: 0.7018\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 118s 3s/step - loss: 0.0217 - accuracy: 0.9972 - val_loss: 0.4447 - val_accuracy: 0.9445\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 119s 3s/step - loss: 0.0483 - accuracy: 0.9854 - val_loss: 0.4439 - val_accuracy: 0.7060\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 118s 3s/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 0.3597 - val_accuracy: 0.8169\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 118s 3s/step - loss: 0.0326 - accuracy: 0.9875 - val_loss: 0.1427 - val_accuracy: 0.9639\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 119s 3s/step - loss: 0.0756 - accuracy: 0.9743 - val_loss: 0.1936 - val_accuracy: 0.9126\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 118s 3s/step - loss: 0.0230 - accuracy: 0.9931 - val_loss: 0.2272 - val_accuracy: 0.8918\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 119s 3s/step - loss: 0.0437 - accuracy: 0.9903 - val_loss: 1.7447 - val_accuracy: 0.5326\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 119s 3s/step - loss: 0.0338 - accuracy: 0.9896 - val_loss: 0.0708 - val_accuracy: 0.9931\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 119s 3s/step - loss: 0.0575 - accuracy: 0.9875 - val_loss: 0.0837 - val_accuracy: 0.9917\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 120s 3s/step - loss: 0.0128 - accuracy: 0.9979 - val_loss: 0.0680 - val_accuracy: 0.9917\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 119s 3s/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.0478 - val_accuracy: 0.9917\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 119s 3s/step - loss: 0.0075 - accuracy: 0.9993 - val_loss: 0.0484 - val_accuracy: 0.9917\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 119s 3s/step - loss: 0.0509 - accuracy: 0.9834 - val_loss: 0.0754 - val_accuracy: 0.9792\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 119s 3s/step - loss: 0.0128 - accuracy: 0.9965 - val_loss: 0.1160 - val_accuracy: 0.9584\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 119s 3s/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.0449 - val_accuracy: 0.9903\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 119s 3s/step - loss: 0.0045 - accuracy: 0.9993 - val_loss: 0.0538 - val_accuracy: 0.9861\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 119s 3s/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0605 - val_accuracy: 0.9875\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 120s 3s/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0732 - val_accuracy: 0.9917\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 119s 3s/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0463 - val_accuracy: 0.9889\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 120s 3s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0613 - val_accuracy: 0.9917\n",
      "23/23 [==============================] - 11s 408ms/step\n",
      "Epoch 1/100\n",
      "68/68 [==============================] - 196s 3s/step - loss: 0.2698 - accuracy: 0.8770 - val_loss: 0.5448 - val_accuracy: 0.8793\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 172s 3s/step - loss: 0.0820 - accuracy: 0.9727 - val_loss: 0.5244 - val_accuracy: 0.7254\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 175s 3s/step - loss: 0.0407 - accuracy: 0.9861 - val_loss: 0.4622 - val_accuracy: 0.8946\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - 173s 3s/step - loss: 0.0299 - accuracy: 0.9917 - val_loss: 0.4791 - val_accuracy: 0.7226\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - 175s 3s/step - loss: 0.0233 - accuracy: 0.9935 - val_loss: 0.1963 - val_accuracy: 0.9667\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - 174s 3s/step - loss: 0.0256 - accuracy: 0.9926 - val_loss: 0.0818 - val_accuracy: 0.9861\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 174s 3s/step - loss: 0.0174 - accuracy: 0.9949 - val_loss: 0.0537 - val_accuracy: 0.9917\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - 175s 3s/step - loss: 0.0185 - accuracy: 0.9935 - val_loss: 0.0590 - val_accuracy: 0.9917\n",
      "Epoch 9/100\n",
      "68/68 [==============================] - 176s 3s/step - loss: 0.0303 - accuracy: 0.9908 - val_loss: 0.8187 - val_accuracy: 0.8530\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 177s 3s/step - loss: 0.0184 - accuracy: 0.9949 - val_loss: 0.0392 - val_accuracy: 0.9945\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 176s 3s/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.0498 - val_accuracy: 0.9931\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - 177s 3s/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0427 - val_accuracy: 0.9917\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - 176s 3s/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.0562 - val_accuracy: 0.9917\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - 175s 3s/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.1743 - val_accuracy: 0.9431\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - 176s 3s/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 0.0923 - val_accuracy: 0.9958\n",
      "23/23 [==============================] - 11s 417ms/step\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 254s 3s/step - loss: 0.2258 - accuracy: 0.9060 - val_loss: 0.5293 - val_accuracy: 0.8017\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 235s 3s/step - loss: 0.0626 - accuracy: 0.9834 - val_loss: 0.4086 - val_accuracy: 0.9528\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 234s 3s/step - loss: 0.0364 - accuracy: 0.9910 - val_loss: 0.1819 - val_accuracy: 0.9792\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 233s 3s/step - loss: 0.0275 - accuracy: 0.9910 - val_loss: 0.1350 - val_accuracy: 0.9931\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 234s 3s/step - loss: 0.0467 - accuracy: 0.9889 - val_loss: 0.3124 - val_accuracy: 0.8419\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 235s 3s/step - loss: 0.0306 - accuracy: 0.9899 - val_loss: 0.0219 - val_accuracy: 0.9958\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 235s 3s/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.0592 - val_accuracy: 0.9806\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 234s 3s/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.0314 - val_accuracy: 0.9945\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 234s 3s/step - loss: 0.0165 - accuracy: 0.9955 - val_loss: 0.0479 - val_accuracy: 0.9861\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 233s 3s/step - loss: 0.0302 - accuracy: 0.9913 - val_loss: 0.0317 - val_accuracy: 0.9945\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 234s 3s/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.0254 - val_accuracy: 0.9986\n",
      "23/23 [==============================] - 11s 415ms/step\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 67s 3s/step - loss: 0.4499 - accuracy: 0.7969 - val_loss: 0.6795 - val_accuracy: 0.5379\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.2161 - accuracy: 0.9253 - val_loss: 0.6410 - val_accuracy: 0.5517\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0959 - accuracy: 0.9740 - val_loss: 0.6567 - val_accuracy: 0.5379\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0451 - accuracy: 0.9913 - val_loss: 0.6289 - val_accuracy: 0.5448\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0383 - accuracy: 0.9878 - val_loss: 0.5920 - val_accuracy: 0.6069\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0330 - accuracy: 0.9931 - val_loss: 0.7307 - val_accuracy: 0.5379\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0168 - accuracy: 0.9965 - val_loss: 0.6306 - val_accuracy: 0.5379\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0085 - accuracy: 0.9983 - val_loss: 0.5776 - val_accuracy: 0.6000\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.6283 - val_accuracy: 0.5379\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 45s 3s/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.5874 - val_accuracy: 0.6000\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5574 - val_accuracy: 0.6414\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5139 - val_accuracy: 0.7310\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 9.9753e-04 - accuracy: 1.0000 - val_loss: 0.5170 - val_accuracy: 0.6621\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 45s 3s/step - loss: 8.9714e-04 - accuracy: 1.0000 - val_loss: 0.4928 - val_accuracy: 0.6828\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 5.3617e-04 - accuracy: 1.0000 - val_loss: 0.4802 - val_accuracy: 0.7034\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 7.9899e-04 - accuracy: 1.0000 - val_loss: 0.4503 - val_accuracy: 0.7586\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 5.7526e-04 - accuracy: 1.0000 - val_loss: 0.4266 - val_accuracy: 0.7931\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 3.4391e-04 - accuracy: 1.0000 - val_loss: 0.4111 - val_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 2.8311e-04 - accuracy: 1.0000 - val_loss: 0.3604 - val_accuracy: 0.8414\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 2.1541e-04 - accuracy: 1.0000 - val_loss: 0.3025 - val_accuracy: 0.8759\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 2.9461e-04 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.8897\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 1.6088e-04 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 0.9172\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 6.4438e-04 - accuracy: 1.0000 - val_loss: 0.2407 - val_accuracy: 0.9103\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 1.2048e-04 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9241\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 1.7860e-04 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 0.9310\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0419 - accuracy: 0.9878 - val_loss: 7.9648 - val_accuracy: 0.5379\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0427 - accuracy: 0.9878 - val_loss: 0.3015 - val_accuracy: 0.9793\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0217 - accuracy: 0.9948 - val_loss: 4.4089 - val_accuracy: 0.7103\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0345 - accuracy: 0.9896 - val_loss: 0.6990 - val_accuracy: 0.9034\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0188 - accuracy: 0.9948 - val_loss: 0.4583 - val_accuracy: 0.9724\n",
      "5/5 [==============================] - 3s 378ms/step\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 65s 3s/step - loss: 0.4879 - accuracy: 0.7587 - val_loss: 0.6572 - val_accuracy: 0.5310\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.2378 - accuracy: 0.9132 - val_loss: 0.6732 - val_accuracy: 0.5310\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0873 - accuracy: 0.9792 - val_loss: 0.5238 - val_accuracy: 0.8483\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0348 - accuracy: 0.9931 - val_loss: 0.6116 - val_accuracy: 0.5448\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0377 - accuracy: 0.9878 - val_loss: 0.4972 - val_accuracy: 0.7862\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0217 - accuracy: 0.9948 - val_loss: 0.4808 - val_accuracy: 0.9655\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0200 - accuracy: 0.9965 - val_loss: 0.5293 - val_accuracy: 0.6207\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.4403 - val_accuracy: 0.9655\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4853 - val_accuracy: 0.8207\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0071 - accuracy: 0.9965 - val_loss: 0.4479 - val_accuracy: 0.8483\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4729 - val_accuracy: 0.7517\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4095 - val_accuracy: 0.9586\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3951 - val_accuracy: 0.9655\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.3482 - val_accuracy: 0.9793\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3238 - val_accuracy: 0.8897\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9517\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 0.9724\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 8.0325e-04 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9724\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 2.8368e-04 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9793\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 2.6576e-04 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9862\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 4.1960e-04 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 0.9931\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 2.1474e-04 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9931\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 9.7768e-04 - accuracy: 1.0000 - val_loss: 0.0822 - val_accuracy: 0.9931\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 6.0197e-04 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 0.9793\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 1.3052e-04 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 0.9793\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 1.6593e-04 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9862\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 1.5051e-04 - accuracy: 1.0000 - val_loss: 0.0669 - val_accuracy: 0.9931\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 1.7327e-04 - accuracy: 1.0000 - val_loss: 0.0613 - val_accuracy: 0.9931\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 1.7770e-04 - accuracy: 1.0000 - val_loss: 0.0653 - val_accuracy: 0.9862\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 4.6771e-05 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9862\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 7.3485e-05 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9862\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 3.1324e-04 - accuracy: 1.0000 - val_loss: 0.0947 - val_accuracy: 0.9793\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 5.7807e-05 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9724\n",
      "5/5 [==============================] - 4s 404ms/step\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 66s 3s/step - loss: 0.5108 - accuracy: 0.7483 - val_loss: 0.6658 - val_accuracy: 0.5034\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.3037 - accuracy: 0.8733 - val_loss: 0.6386 - val_accuracy: 0.5862\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.1667 - accuracy: 0.9410 - val_loss: 0.6070 - val_accuracy: 0.6552\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0777 - accuracy: 0.9740 - val_loss: 0.5672 - val_accuracy: 0.8621\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0352 - accuracy: 0.9931 - val_loss: 0.5372 - val_accuracy: 0.7586\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0699 - accuracy: 0.9757 - val_loss: 0.5441 - val_accuracy: 0.7034\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0244 - accuracy: 0.9948 - val_loss: 0.5006 - val_accuracy: 0.8966\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.5007 - val_accuracy: 0.8621\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 0.4841 - val_accuracy: 0.8828\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 0.4717 - val_accuracy: 0.8690\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.4396 - val_accuracy: 0.9379\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4495 - val_accuracy: 0.9517\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.4249 - val_accuracy: 0.9310\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0077 - accuracy: 0.9965 - val_loss: 0.3531 - val_accuracy: 0.9172\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4727 - val_accuracy: 0.7103\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3415 - val_accuracy: 0.8966\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3130 - val_accuracy: 0.9379\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 9.5134e-04 - accuracy: 1.0000 - val_loss: 0.2858 - val_accuracy: 0.9310\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 3.9199e-04 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 0.9586\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 3.2909e-04 - accuracy: 1.0000 - val_loss: 0.1825 - val_accuracy: 0.9724\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 3.5674e-04 - accuracy: 1.0000 - val_loss: 0.1411 - val_accuracy: 0.9724\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 3.0827e-04 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 0.9793\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 2.7357e-04 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9793\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 3.3832e-04 - accuracy: 1.0000 - val_loss: 0.0669 - val_accuracy: 0.9793\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 3.5342e-04 - accuracy: 1.0000 - val_loss: 0.0544 - val_accuracy: 0.9793\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 3.0114e-04 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9862\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 3.2925e-04 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9862\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 1.6993e-04 - accuracy: 1.0000 - val_loss: 0.0342 - val_accuracy: 0.9862\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 48s 3s/step - loss: 3.1535e-04 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 0.9862\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 1.6543e-04 - accuracy: 1.0000 - val_loss: 0.0292 - val_accuracy: 0.9862\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 1.7412e-04 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 0.9862\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 48s 3s/step - loss: 1.6491e-04 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 0.9862\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 9.3722e-05 - accuracy: 1.0000 - val_loss: 0.0283 - val_accuracy: 0.9862\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 3.1036e-04 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9862\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 1.1470e-04 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 0.9862\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 4.6995e-04 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9931\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 1.0639e-04 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9931\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 1.4968e-04 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 0.9862\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 7.6630e-05 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9862\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 9.2742e-05 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9862\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 5.8523e-05 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9862\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 3.9488e-05 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 0.9862\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 1.1675e-04 - accuracy: 1.0000 - val_loss: 0.0323 - val_accuracy: 0.9862\n",
      "5/5 [==============================] - 4s 394ms/step\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 66s 3s/step - loss: 0.6293 - accuracy: 0.6753 - val_loss: 0.6709 - val_accuracy: 0.6897\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.3609 - accuracy: 0.8438 - val_loss: 0.6478 - val_accuracy: 0.6828\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.2202 - accuracy: 0.9219 - val_loss: 0.6614 - val_accuracy: 0.5241\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0938 - accuracy: 0.9705 - val_loss: 0.5994 - val_accuracy: 0.7586\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0461 - accuracy: 0.9896 - val_loss: 0.5908 - val_accuracy: 0.7172\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0361 - accuracy: 0.9896 - val_loss: 0.5778 - val_accuracy: 0.7586\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0253 - accuracy: 0.9931 - val_loss: 0.5564 - val_accuracy: 0.7586\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.6571 - val_accuracy: 0.4897\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.5181 - val_accuracy: 0.8966\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0190 - accuracy: 0.9948 - val_loss: 0.5454 - val_accuracy: 0.7034\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 0.5529 - val_accuracy: 0.6897\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.4783 - val_accuracy: 0.7793\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0133 - accuracy: 0.9965 - val_loss: 0.4984 - val_accuracy: 0.8069\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0236 - accuracy: 0.9913 - val_loss: 0.3865 - val_accuracy: 0.8828\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0098 - accuracy: 0.9983 - val_loss: 0.3046 - val_accuracy: 0.8828\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 48s 3s/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4617 - val_accuracy: 0.7517\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2511 - val_accuracy: 0.9172\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0081 - accuracy: 0.9965 - val_loss: 0.2883 - val_accuracy: 0.8897\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9310\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1692 - val_accuracy: 0.9517\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.9724\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9724\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 6.9065e-04 - accuracy: 1.0000 - val_loss: 0.1248 - val_accuracy: 0.9655\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 9.7621e-04 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9724\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9724\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 4.5331e-04 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 0.9586\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 3.5279e-04 - accuracy: 1.0000 - val_loss: 0.1265 - val_accuracy: 0.9517\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 3.0688e-04 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9724\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 1.8649e-04 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9793\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 1.9799e-04 - accuracy: 1.0000 - val_loss: 0.1029 - val_accuracy: 0.9793\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 1.5036e-04 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 0.9793\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 2.0528e-04 - accuracy: 1.0000 - val_loss: 0.0909 - val_accuracy: 0.9793\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 1.0932e-04 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9793\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 2.1948e-04 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9793\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 1.9821e-04 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9793\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 1.3983e-04 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 0.9793\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 2.0086e-04 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9793\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 1.7143e-04 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9793\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 9.6179e-05 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9724\n",
      "5/5 [==============================] - 4s 380ms/step\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 66s 3s/step - loss: 0.4815 - accuracy: 0.7622 - val_loss: 0.7297 - val_accuracy: 0.4069\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.2689 - accuracy: 0.8837 - val_loss: 0.6782 - val_accuracy: 0.4414\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.1001 - accuracy: 0.9688 - val_loss: 0.6882 - val_accuracy: 0.4276\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0592 - accuracy: 0.9792 - val_loss: 0.7238 - val_accuracy: 0.4138\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0283 - accuracy: 0.9913 - val_loss: 0.6690 - val_accuracy: 0.4414\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0131 - accuracy: 0.9983 - val_loss: 0.6495 - val_accuracy: 0.5241\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0150 - accuracy: 0.9965 - val_loss: 0.6900 - val_accuracy: 0.4345\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0251 - accuracy: 0.9878 - val_loss: 0.6229 - val_accuracy: 0.6552\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0357 - accuracy: 0.9861 - val_loss: 0.6000 - val_accuracy: 0.6345\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0331 - accuracy: 0.9878 - val_loss: 0.5523 - val_accuracy: 0.9103\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0288 - accuracy: 0.9931 - val_loss: 0.5408 - val_accuracy: 0.8897\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0085 - accuracy: 0.9983 - val_loss: 0.5696 - val_accuracy: 0.7793\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5554 - val_accuracy: 0.7862\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0072 - accuracy: 0.9965 - val_loss: 0.4971 - val_accuracy: 0.8552\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.5610 - val_accuracy: 0.7448\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0258 - accuracy: 0.9878 - val_loss: 0.3998 - val_accuracy: 0.9448\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 45s 3s/step - loss: 0.0277 - accuracy: 0.9913 - val_loss: 0.1629 - val_accuracy: 0.9517\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0253 - accuracy: 0.9896 - val_loss: 0.1778 - val_accuracy: 0.9517\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0151 - accuracy: 0.9948 - val_loss: 0.1014 - val_accuracy: 0.9448\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0203 - accuracy: 0.9948 - val_loss: 0.0972 - val_accuracy: 0.9862\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0745 - val_accuracy: 0.9793\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.9724\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9793\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0632 - val_accuracy: 0.9724\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 5.5169e-04 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 0.9724\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 5.9067e-04 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9724\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9862\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 5.8453e-04 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 0.9862\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 2.1577e-04 - accuracy: 1.0000 - val_loss: 0.0293 - val_accuracy: 0.9862\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 6.4391e-04 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9862\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 2.8460e-04 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 0.9931\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 2.7077e-04 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.9862\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 47s 3s/step - loss: 3.1192e-04 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 0.9862\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 46s 3s/step - loss: 2.6755e-04 - accuracy: 1.0000 - val_loss: 0.0318 - val_accuracy: 0.9862\n",
      "5/5 [==============================] - 4s 375ms/step\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 252s 3s/step - loss: 0.2660 - accuracy: 0.8845 - val_loss: 0.4925 - val_accuracy: 0.8863\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 239s 3s/step - loss: 0.0813 - accuracy: 0.9778 - val_loss: 0.4248 - val_accuracy: 0.8793\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 239s 3s/step - loss: 0.0438 - accuracy: 0.9906 - val_loss: 0.1898 - val_accuracy: 0.9778\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 238s 3s/step - loss: 0.0339 - accuracy: 0.9906 - val_loss: 0.0758 - val_accuracy: 0.9917\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 239s 3s/step - loss: 0.0479 - accuracy: 0.9854 - val_loss: 0.2386 - val_accuracy: 0.8877\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 239s 3s/step - loss: 0.0226 - accuracy: 0.9945 - val_loss: 0.0309 - val_accuracy: 0.9931\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 238s 3s/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.0243 - val_accuracy: 0.9958\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 238s 3s/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 0.0259 - val_accuracy: 0.9945\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 238s 3s/step - loss: 0.0112 - accuracy: 0.9976 - val_loss: 0.0202 - val_accuracy: 0.9945\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 239s 3s/step - loss: 0.0488 - accuracy: 0.9827 - val_loss: 0.1612 - val_accuracy: 0.9362\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 237s 3s/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.0295 - val_accuracy: 0.9917\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 239s 3s/step - loss: 0.0352 - accuracy: 0.9899 - val_loss: 0.0457 - val_accuracy: 0.9917\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 238s 3s/step - loss: 0.0148 - accuracy: 0.9948 - val_loss: 0.0217 - val_accuracy: 0.9958\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 240s 3s/step - loss: 0.0082 - accuracy: 0.9983 - val_loss: 0.0844 - val_accuracy: 0.9847\n",
      "23/23 [==============================] - 12s 434ms/step\n",
      "Epoch 1/100\n",
      "113/113 [==============================] - 343s 3s/step - loss: 0.1871 - accuracy: 0.9240 - val_loss: 154.3334 - val_accuracy: 0.4554\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - 314s 3s/step - loss: 0.0383 - accuracy: 0.9895 - val_loss: 179.7811 - val_accuracy: 0.4554\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - 320s 3s/step - loss: 0.0303 - accuracy: 0.9914 - val_loss: 398.2300 - val_accuracy: 0.4554\n",
      "Epoch 4/100\n",
      "113/113 [==============================] - 319s 3s/step - loss: 0.0288 - accuracy: 0.9914 - val_loss: 366.9816 - val_accuracy: 0.4554\n",
      "Epoch 5/100\n",
      "113/113 [==============================] - 318s 3s/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 759.2795 - val_accuracy: 0.4554\n",
      "Epoch 6/100\n",
      "113/113 [==============================] - 319s 3s/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 841.7510 - val_accuracy: 0.4554\n",
      "63/63 [==============================] - 35s 527ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "91/91 [==============================] - 250s 3s/step - loss: 0.2333 - accuracy: 0.9064 - val_loss: 0.5895 - val_accuracy: 0.8738\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 236s 3s/step - loss: 0.0678 - accuracy: 0.9799 - val_loss: 0.5671 - val_accuracy: 0.8502\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 236s 3s/step - loss: 0.0415 - accuracy: 0.9899 - val_loss: 0.4036 - val_accuracy: 0.9556\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 236s 3s/step - loss: 0.0290 - accuracy: 0.9917 - val_loss: 0.2253 - val_accuracy: 0.9875\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 236s 3s/step - loss: 0.0332 - accuracy: 0.9906 - val_loss: 0.0330 - val_accuracy: 0.9931\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 236s 3s/step - loss: 0.0350 - accuracy: 0.9886 - val_loss: 0.0378 - val_accuracy: 0.9958\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 239s 3s/step - loss: 0.0192 - accuracy: 0.9931 - val_loss: 0.1370 - val_accuracy: 0.9390\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 234s 3s/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.0609 - val_accuracy: 0.9889\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 228s 3s/step - loss: 0.0190 - accuracy: 0.9951 - val_loss: 0.1800 - val_accuracy: 0.9196\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 252s 3s/step - loss: 0.0499 - accuracy: 0.9813 - val_loss: 0.0146 - val_accuracy: 0.9972\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 251s 3s/step - loss: 0.0126 - accuracy: 0.9955 - val_loss: 0.0396 - val_accuracy: 0.9903\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 249s 3s/step - loss: 0.0140 - accuracy: 0.9962 - val_loss: 0.0447 - val_accuracy: 0.9931\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 242s 3s/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.0320 - val_accuracy: 0.9958\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 253s 3s/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.0447 - val_accuracy: 0.9945\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 248s 3s/step - loss: 0.0294 - accuracy: 0.9886 - val_loss: 0.0190 - val_accuracy: 0.9972\n",
      "23/23 [==============================] - 12s 433ms/step\n",
      "23/23 [==============================] - 10s 448ms/step\n",
      "23/23 [==============================] - 11s 484ms/step\n",
      "23/23 [==============================] - 11s 457ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-23 17:37:10,757 - INFO - Processing dataset: CSPC18-SR-AF with filters: [32, 64, 128]\n",
      "2024-08-23 17:37:12,571 - INFO - Truncated CSPC18-SR-AF data to shape (2016, 5000, 12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 130s 3s/step - loss: 0.7713 - accuracy: 0.5345 - val_loss: 0.6871 - val_accuracy: 0.5418\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 106s 3s/step - loss: 0.7136 - accuracy: 0.5407 - val_loss: 0.6744 - val_accuracy: 0.5418\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 108s 3s/step - loss: 0.6903 - accuracy: 0.5423 - val_loss: 0.6792 - val_accuracy: 0.5449\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 107s 3s/step - loss: 0.6828 - accuracy: 0.5438 - val_loss: 0.6839 - val_accuracy: 0.5418\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 110s 3s/step - loss: 0.7114 - accuracy: 0.5438 - val_loss: 0.6808 - val_accuracy: 0.5449\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 114s 3s/step - loss: 0.6790 - accuracy: 0.5431 - val_loss: 0.6741 - val_accuracy: 0.5449\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 120s 3s/step - loss: 0.6796 - accuracy: 0.5462 - val_loss: 0.6815 - val_accuracy: 0.5480\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 109s 3s/step - loss: 0.6801 - accuracy: 0.5128 - val_loss: 0.6754 - val_accuracy: 0.5418\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 104s 3s/step - loss: 0.6801 - accuracy: 0.5462 - val_loss: 0.6828 - val_accuracy: 0.5449\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.6789 - accuracy: 0.5462 - val_loss: 0.6762 - val_accuracy: 0.5449\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 111s 3s/step - loss: 0.6789 - accuracy: 0.5462 - val_loss: 0.6753 - val_accuracy: 0.5418\n",
      "13/13 [==============================] - 7s 402ms/step\n",
      "13/13 [==============================] - 6s 425ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-23 17:57:54,982 - INFO - Truncated CSPC18-SR-AF data to shape (2016, 5000, 12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "162/162 [==============================] - 480s 3s/step - loss: 0.7212 - accuracy: 0.5227 - val_loss: 0.6777 - val_accuracy: 0.5418\n",
      "Epoch 2/100\n",
      "162/162 [==============================] - 449s 3s/step - loss: 0.7017 - accuracy: 0.5353 - val_loss: 0.6845 - val_accuracy: 0.5418\n",
      "Epoch 3/100\n",
      "162/162 [==============================] - 470s 3s/step - loss: 0.6977 - accuracy: 0.5295 - val_loss: 0.6782 - val_accuracy: 0.5449\n",
      "Epoch 4/100\n",
      "162/162 [==============================] - 465s 3s/step - loss: 0.6811 - accuracy: 0.5359 - val_loss: 0.6759 - val_accuracy: 0.5418\n",
      "Epoch 5/100\n",
      "162/162 [==============================] - 455s 3s/step - loss: 0.6798 - accuracy: 0.5438 - val_loss: 0.6760 - val_accuracy: 0.5418\n",
      "Epoch 6/100\n",
      "162/162 [==============================] - 464s 3s/step - loss: 0.6803 - accuracy: 0.5409 - val_loss: 0.6769 - val_accuracy: 0.5418\n",
      "Epoch 7/100\n",
      "162/162 [==============================] - 453s 3s/step - loss: 0.6797 - accuracy: 0.5440 - val_loss: 0.6747 - val_accuracy: 0.5480\n",
      "Epoch 8/100\n",
      "162/162 [==============================] - 493s 3s/step - loss: 0.6793 - accuracy: 0.5431 - val_loss: 0.6743 - val_accuracy: 0.5480\n",
      "Epoch 9/100\n",
      "162/162 [==============================] - 438s 3s/step - loss: 0.6795 - accuracy: 0.5423 - val_loss: 0.6745 - val_accuracy: 0.5480\n",
      "Epoch 10/100\n",
      "162/162 [==============================] - 431s 3s/step - loss: 0.6785 - accuracy: 0.5465 - val_loss: 0.6774 - val_accuracy: 0.5449\n",
      "Epoch 11/100\n",
      "162/162 [==============================] - 472s 3s/step - loss: 0.6791 - accuracy: 0.5444 - val_loss: 0.6768 - val_accuracy: 0.5449\n",
      "Epoch 12/100\n",
      "162/162 [==============================] - 442s 3s/step - loss: 0.6789 - accuracy: 0.5417 - val_loss: 0.6744 - val_accuracy: 0.5480\n",
      "Epoch 13/100\n",
      "162/162 [==============================] - 476s 3s/step - loss: 0.6791 - accuracy: 0.5438 - val_loss: 0.6734 - val_accuracy: 0.5480\n",
      "Epoch 14/100\n",
      "162/162 [==============================] - 506s 3s/step - loss: 0.6786 - accuracy: 0.5454 - val_loss: 0.6736 - val_accuracy: 0.5480\n",
      "Epoch 15/100\n",
      "162/162 [==============================] - 486s 3s/step - loss: 0.6787 - accuracy: 0.5462 - val_loss: 0.6734 - val_accuracy: 0.5480\n",
      "Epoch 16/100\n",
      "162/162 [==============================] - 447s 3s/step - loss: 0.6788 - accuracy: 0.5429 - val_loss: 0.6791 - val_accuracy: 0.5449\n",
      "Epoch 17/100\n",
      "162/162 [==============================] - 406s 3s/step - loss: 0.6785 - accuracy: 0.5452 - val_loss: 0.6739 - val_accuracy: 0.5480\n",
      "Epoch 18/100\n",
      "162/162 [==============================] - 406s 3s/step - loss: 0.6783 - accuracy: 0.5427 - val_loss: 0.6740 - val_accuracy: 0.5449\n",
      "Epoch 19/100\n",
      "162/162 [==============================] - 420s 3s/step - loss: 0.6786 - accuracy: 0.5462 - val_loss: 0.6805 - val_accuracy: 0.5449\n",
      "Epoch 20/100\n",
      "162/162 [==============================] - 425s 3s/step - loss: 0.6786 - accuracy: 0.5380 - val_loss: 0.6803 - val_accuracy: 0.5449\n",
      "13/13 [==============================] - 8s 430ms/step\n",
      "13/13 [==============================] - 6s 437ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-23 20:29:54,453 - INFO - Truncated CSPC18-SR-AF data to shape (2016, 5000, 12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 138s 3s/step - loss: 0.7107 - accuracy: 0.5213 - val_loss: 0.6798 - val_accuracy: 0.5418\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 119s 3s/step - loss: 0.6943 - accuracy: 0.5384 - val_loss: 0.6794 - val_accuracy: 0.5418\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 126s 3s/step - loss: 0.6988 - accuracy: 0.5400 - val_loss: 0.6807 - val_accuracy: 0.5418\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 122s 3s/step - loss: 0.6909 - accuracy: 0.5407 - val_loss: 0.6799 - val_accuracy: 0.5418\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 119s 3s/step - loss: 0.6960 - accuracy: 0.5400 - val_loss: 0.6825 - val_accuracy: 0.5418\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 136s 3s/step - loss: 0.6893 - accuracy: 0.5415 - val_loss: 0.6807 - val_accuracy: 0.5418\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 113s 3s/step - loss: 0.6868 - accuracy: 0.5438 - val_loss: 0.6830 - val_accuracy: 0.5418\n",
      "13/13 [==============================] - 6s 379ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 5s 396ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024-08-23 20:44:43,646 - INFO - Truncated CSPC18-SR-AF data to shape (2016, 5000, 12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 125s 3s/step - loss: 0.7040 - accuracy: 0.5190 - val_loss: 0.6803 - val_accuracy: 0.5418\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 116s 3s/step - loss: 0.6886 - accuracy: 0.5431 - val_loss: 0.6800 - val_accuracy: 0.5418\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 116s 3s/step - loss: 0.7141 - accuracy: 0.5415 - val_loss: 0.6852 - val_accuracy: 0.5387\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 112s 3s/step - loss: 0.6893 - accuracy: 0.5431 - val_loss: 0.6823 - val_accuracy: 0.5418\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 122s 3s/step - loss: 0.7044 - accuracy: 0.5423 - val_loss: 0.6831 - val_accuracy: 0.5387\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 131s 3s/step - loss: 0.6850 - accuracy: 0.5400 - val_loss: 0.6802 - val_accuracy: 0.5418\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 137s 3s/step - loss: 0.6832 - accuracy: 0.5438 - val_loss: 0.6797 - val_accuracy: 0.5418\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 126s 3s/step - loss: 0.6877 - accuracy: 0.5089 - val_loss: 0.6792 - val_accuracy: 0.5418\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 123s 3s/step - loss: 0.6864 - accuracy: 0.5446 - val_loss: 0.6812 - val_accuracy: 0.5418\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 131s 3s/step - loss: 0.6823 - accuracy: 0.5454 - val_loss: 0.6794 - val_accuracy: 0.5418\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 134s 3s/step - loss: 0.6854 - accuracy: 0.5438 - val_loss: 0.6803 - val_accuracy: 0.5449\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 116s 3s/step - loss: 0.6854 - accuracy: 0.5446 - val_loss: 0.6863 - val_accuracy: 0.5418\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 111s 3s/step - loss: 0.6916 - accuracy: 0.5438 - val_loss: 0.6887 - val_accuracy: 0.5418\n",
      "13/13 [==============================] - 9s 486ms/step\n",
      "13/13 [==============================] - 8s 583ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024-08-23 21:11:43,937 - INFO - Truncated CSPC18-SR-AF data to shape (2016, 5000, 12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 151s 3s/step - loss: 0.7251 - accuracy: 0.5136 - val_loss: 0.6783 - val_accuracy: 0.5418\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 120s 3s/step - loss: 0.6947 - accuracy: 0.5392 - val_loss: 0.6777 - val_accuracy: 0.5418\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 113s 3s/step - loss: 0.7176 - accuracy: 0.5407 - val_loss: 0.6808 - val_accuracy: 0.5449\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 109s 3s/step - loss: 0.6876 - accuracy: 0.5423 - val_loss: 0.6776 - val_accuracy: 0.5418\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 113s 3s/step - loss: 0.6978 - accuracy: 0.5415 - val_loss: 0.6830 - val_accuracy: 0.5356\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 132s 3s/step - loss: 0.6856 - accuracy: 0.5353 - val_loss: 0.6868 - val_accuracy: 0.5325\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 140s 3s/step - loss: 0.6853 - accuracy: 0.5438 - val_loss: 0.6896 - val_accuracy: 0.5325\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 146s 4s/step - loss: 0.6855 - accuracy: 0.5182 - val_loss: 0.6821 - val_accuracy: 0.5356\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 125s 3s/step - loss: 0.6894 - accuracy: 0.5423 - val_loss: 0.6843 - val_accuracy: 0.5356\n",
      "13/13 [==============================] - 7s 419ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 5s 412ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024-08-23 21:31:11,103 - INFO - Truncated CSPC18-SR-AF data to shape (2016, 5000, 12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 142s 3s/step - loss: 0.6985 - accuracy: 0.5291 - val_loss: 0.6803 - val_accuracy: 0.5418\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 126s 3s/step - loss: 0.6956 - accuracy: 0.5392 - val_loss: 0.6793 - val_accuracy: 0.5418\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 115s 3s/step - loss: 0.6969 - accuracy: 0.5407 - val_loss: 0.6810 - val_accuracy: 0.5418\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 113s 3s/step - loss: 0.6899 - accuracy: 0.5407 - val_loss: 0.6799 - val_accuracy: 0.5418\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 110s 3s/step - loss: 0.6919 - accuracy: 0.5407 - val_loss: 0.6815 - val_accuracy: 0.5418\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 109s 3s/step - loss: 0.6899 - accuracy: 0.5345 - val_loss: 0.6818 - val_accuracy: 0.5418\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 109s 3s/step - loss: 0.6867 - accuracy: 0.5431 - val_loss: 0.6799 - val_accuracy: 0.5418\n",
      "13/13 [==============================] - 7s 419ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 6s 429ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024-08-23 21:45:12,368 - INFO - Truncated CSPC18-SR-AF data to shape (2016, 5000, 12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 131s 3s/step - loss: 0.7095 - accuracy: 0.5120 - val_loss: 0.6830 - val_accuracy: 0.5418\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 108s 3s/step - loss: 0.6973 - accuracy: 0.5392 - val_loss: 0.6787 - val_accuracy: 0.5418\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 108s 3s/step - loss: 0.7038 - accuracy: 0.5407 - val_loss: 0.6802 - val_accuracy: 0.5418\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 102s 2s/step - loss: 0.6897 - accuracy: 0.5407 - val_loss: 0.6786 - val_accuracy: 0.5418\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 101s 2s/step - loss: 0.6923 - accuracy: 0.5423 - val_loss: 0.6808 - val_accuracy: 0.5418\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 101s 2s/step - loss: 0.6905 - accuracy: 0.5330 - val_loss: 0.6809 - val_accuracy: 0.5418\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 101s 2s/step - loss: 0.6885 - accuracy: 0.5423 - val_loss: 0.7070 - val_accuracy: 0.5294\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 101s 2s/step - loss: 0.6877 - accuracy: 0.5423 - val_loss: 0.6880 - val_accuracy: 0.5387\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 102s 2s/step - loss: 0.6882 - accuracy: 0.5438 - val_loss: 0.7365 - val_accuracy: 0.5232\n",
      "13/13 [==============================] - 7s 398ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 5s 410ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024-08-23 22:01:23,005 - INFO - Truncated CSPC18-SR-AF data to shape (2016, 5000, 12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 123s 3s/step - loss: 0.7181 - accuracy: 0.5361 - val_loss: 0.6785 - val_accuracy: 0.5418\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 99s 2s/step - loss: 0.6969 - accuracy: 0.5384 - val_loss: 0.6787 - val_accuracy: 0.5418\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 101s 2s/step - loss: 0.7098 - accuracy: 0.5415 - val_loss: 0.6818 - val_accuracy: 0.5418\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 99s 2s/step - loss: 0.6879 - accuracy: 0.5423 - val_loss: 0.6791 - val_accuracy: 0.5418\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 101s 2s/step - loss: 0.6965 - accuracy: 0.5431 - val_loss: 0.6818 - val_accuracy: 0.5418\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.6844 - accuracy: 0.5376 - val_loss: 0.6832 - val_accuracy: 0.5387\n",
      "13/13 [==============================] - 7s 401ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 5s 402ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024-08-23 22:12:02,544 - INFO - Truncated CSPC18-SR-AF data to shape (2016, 5000, 12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 121s 2s/step - loss: 0.7241 - accuracy: 0.5229 - val_loss: 0.6792 - val_accuracy: 0.5418\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 101s 2s/step - loss: 0.6922 - accuracy: 0.5407 - val_loss: 0.6788 - val_accuracy: 0.5418\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 101s 2s/step - loss: 0.7031 - accuracy: 0.5384 - val_loss: 0.6814 - val_accuracy: 0.5418\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.6903 - accuracy: 0.5415 - val_loss: 0.6789 - val_accuracy: 0.5418\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.6975 - accuracy: 0.5415 - val_loss: 0.6796 - val_accuracy: 0.5418\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 99s 2s/step - loss: 0.6918 - accuracy: 0.5361 - val_loss: 0.6799 - val_accuracy: 0.5418\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 99s 2s/step - loss: 0.6871 - accuracy: 0.5415 - val_loss: 0.6833 - val_accuracy: 0.5387\n",
      "13/13 [==============================] - 7s 404ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 5s 403ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024-08-23 22:24:18,599 - INFO - Truncated CSPC18-SR-AF data to shape (2016, 5000, 12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 121s 2s/step - loss: 0.7270 - accuracy: 0.5400 - val_loss: 0.6774 - val_accuracy: 0.5418\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 101s 2s/step - loss: 0.6960 - accuracy: 0.5415 - val_loss: 0.6787 - val_accuracy: 0.5418\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.7344 - accuracy: 0.5407 - val_loss: 0.6812 - val_accuracy: 0.5418\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 102s 2s/step - loss: 0.6904 - accuracy: 0.5407 - val_loss: 0.6778 - val_accuracy: 0.5418\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 101s 2s/step - loss: 0.6893 - accuracy: 0.5415 - val_loss: 0.6775 - val_accuracy: 0.5418\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 102s 2s/step - loss: 0.6963 - accuracy: 0.5345 - val_loss: 0.6773 - val_accuracy: 0.5418\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 102s 2s/step - loss: 0.6967 - accuracy: 0.5384 - val_loss: 0.6792 - val_accuracy: 0.5418\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.6866 - accuracy: 0.5291 - val_loss: 0.6769 - val_accuracy: 0.5418\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 98s 2s/step - loss: 0.6915 - accuracy: 0.5407 - val_loss: 0.6771 - val_accuracy: 0.5418\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.6864 - accuracy: 0.5407 - val_loss: 0.6767 - val_accuracy: 0.5418\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.6919 - accuracy: 0.5423 - val_loss: 0.6762 - val_accuracy: 0.5418\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 99s 2s/step - loss: 0.6938 - accuracy: 0.5415 - val_loss: 0.6801 - val_accuracy: 0.5418\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.6907 - accuracy: 0.5438 - val_loss: 0.6786 - val_accuracy: 0.5387\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.6897 - accuracy: 0.5407 - val_loss: 0.6772 - val_accuracy: 0.5387\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 105s 3s/step - loss: 0.6840 - accuracy: 0.5438 - val_loss: 0.6789 - val_accuracy: 0.5418\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 101s 2s/step - loss: 0.6844 - accuracy: 0.5446 - val_loss: 0.6778 - val_accuracy: 0.5418\n",
      "13/13 [==============================] - 7s 394ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 5s 405ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024-08-23 22:51:45,859 - INFO - Truncated CSPC18-SR-AF data to shape (2016, 5000, 12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 121s 2s/step - loss: 0.7380 - accuracy: 0.5268 - val_loss: 0.6779 - val_accuracy: 0.5418\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.7188 - accuracy: 0.5229 - val_loss: 0.6768 - val_accuracy: 0.5418\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 103s 3s/step - loss: 0.7302 - accuracy: 0.5384 - val_loss: 0.6760 - val_accuracy: 0.5418\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 99s 2s/step - loss: 0.7040 - accuracy: 0.5407 - val_loss: 0.6771 - val_accuracy: 0.5418\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.6880 - accuracy: 0.5400 - val_loss: 0.6762 - val_accuracy: 0.5418\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 101s 2s/step - loss: 0.6988 - accuracy: 0.5369 - val_loss: 0.6771 - val_accuracy: 0.5418\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.7022 - accuracy: 0.5376 - val_loss: 0.6773 - val_accuracy: 0.5418\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 101s 2s/step - loss: 0.6981 - accuracy: 0.5050 - val_loss: 0.6755 - val_accuracy: 0.5418\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.6932 - accuracy: 0.5423 - val_loss: 0.6769 - val_accuracy: 0.5418\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.6874 - accuracy: 0.5407 - val_loss: 0.6750 - val_accuracy: 0.5418\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 102s 2s/step - loss: 0.6962 - accuracy: 0.5392 - val_loss: 0.6784 - val_accuracy: 0.5418\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 101s 2s/step - loss: 0.6902 - accuracy: 0.5415 - val_loss: 0.6755 - val_accuracy: 0.5418\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.6927 - accuracy: 0.5407 - val_loss: 0.7302 - val_accuracy: 0.5263\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 101s 2s/step - loss: 0.7025 - accuracy: 0.5384 - val_loss: 0.7040 - val_accuracy: 0.5356\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 101s 2s/step - loss: 0.6873 - accuracy: 0.5415 - val_loss: 0.6755 - val_accuracy: 0.5418\n",
      "13/13 [==============================] - 8s 401ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 5s 402ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024-08-23 23:17:33,173 - INFO - Truncated CSPC18-SR-AF data to shape (2016, 5000, 12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 120s 2s/step - loss: 0.7418 - accuracy: 0.5105 - val_loss: 0.6773 - val_accuracy: 0.5418\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 101s 2s/step - loss: 0.7108 - accuracy: 0.5400 - val_loss: 0.6768 - val_accuracy: 0.5418\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 99s 2s/step - loss: 0.7262 - accuracy: 0.5400 - val_loss: 0.6769 - val_accuracy: 0.5418\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 99s 2s/step - loss: 0.6982 - accuracy: 0.5407 - val_loss: 0.6759 - val_accuracy: 0.5418\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 99s 2s/step - loss: 0.7074 - accuracy: 0.5400 - val_loss: 0.6769 - val_accuracy: 0.5418\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 99s 2s/step - loss: 0.7011 - accuracy: 0.5376 - val_loss: 0.6773 - val_accuracy: 0.5418\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 101s 2s/step - loss: 0.6868 - accuracy: 0.5415 - val_loss: 0.6774 - val_accuracy: 0.5418\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.6926 - accuracy: 0.5361 - val_loss: 0.6761 - val_accuracy: 0.5418\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 99s 2s/step - loss: 0.6920 - accuracy: 0.5431 - val_loss: 0.6772 - val_accuracy: 0.5418\n",
      "13/13 [==============================] - 7s 397ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 5s 396ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024-08-23 23:33:06,198 - INFO - Truncated CSPC18-SR-AF data to shape (2016, 5000, 12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 120s 2s/step - loss: 0.7708 - accuracy: 0.5400 - val_loss: 0.6772 - val_accuracy: 0.5418\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.7094 - accuracy: 0.5407 - val_loss: 0.6942 - val_accuracy: 0.5356\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.7117 - accuracy: 0.5407 - val_loss: 0.6767 - val_accuracy: 0.5418\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 99s 2s/step - loss: 0.6974 - accuracy: 0.5392 - val_loss: 0.6778 - val_accuracy: 0.5418\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.6967 - accuracy: 0.5392 - val_loss: 0.6771 - val_accuracy: 0.5418\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 99s 2s/step - loss: 0.7080 - accuracy: 0.5345 - val_loss: 0.6781 - val_accuracy: 0.5418\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.6948 - accuracy: 0.5392 - val_loss: 0.6814 - val_accuracy: 0.5387\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.7007 - accuracy: 0.5105 - val_loss: 0.6765 - val_accuracy: 0.5418\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.6964 - accuracy: 0.5423 - val_loss: 0.6826 - val_accuracy: 0.5387\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.6876 - accuracy: 0.5431 - val_loss: 0.6762 - val_accuracy: 0.5418\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 99s 2s/step - loss: 0.6992 - accuracy: 0.5392 - val_loss: 0.6904 - val_accuracy: 0.5325\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.6979 - accuracy: 0.5384 - val_loss: 0.6775 - val_accuracy: 0.5418\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 99s 2s/step - loss: 0.7055 - accuracy: 0.5415 - val_loss: 0.7957 - val_accuracy: 0.5232\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 99s 2s/step - loss: 0.6950 - accuracy: 0.5392 - val_loss: 0.7459 - val_accuracy: 0.5263\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 100s 2s/step - loss: 0.6875 - accuracy: 0.5415 - val_loss: 0.6855 - val_accuracy: 0.5387\n",
      "13/13 [==============================] - 7s 403ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 5s 397ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024-08-23 23:58:39,874 - INFO - Truncated CSPC18-SR-AF data to shape (2016, 5000, 12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 123s 3s/step - loss: 0.7283 - accuracy: 0.5244 - val_loss: 0.6795 - val_accuracy: 0.5418\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 99s 2s/step - loss: 0.6963 - accuracy: 0.5392 - val_loss: 0.6771 - val_accuracy: 0.5418\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 99s 2s/step - loss: 0.7062 - accuracy: 0.5407 - val_loss: 0.6772 - val_accuracy: 0.5418\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 99s 2s/step - loss: 0.6928 - accuracy: 0.5400 - val_loss: 0.6776 - val_accuracy: 0.5418\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 99s 2s/step - loss: 0.6994 - accuracy: 0.5415 - val_loss: 0.6780 - val_accuracy: 0.5418\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 99s 2s/step - loss: 0.6919 - accuracy: 0.5353 - val_loss: 0.6796 - val_accuracy: 0.5418\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 98s 2s/step - loss: 0.6886 - accuracy: 0.5400 - val_loss: 0.6803 - val_accuracy: 0.5418\n",
      "13/13 [==============================] - 7s 394ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 5s 392ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024-08-24 00:10:50,480 - INFO - Truncated CSPC18-SR-AF data to shape (2016, 5000, 12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "91/91 [==============================] - 253s 3s/step - loss: 0.2391 - accuracy: 0.8981 - val_loss: 0.4619 - val_accuracy: 0.9154\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 234s 3s/step - loss: 0.0604 - accuracy: 0.9799 - val_loss: 0.5764 - val_accuracy: 0.6117\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 231s 3s/step - loss: 0.0467 - accuracy: 0.9858 - val_loss: 0.2681 - val_accuracy: 0.9279\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 231s 3s/step - loss: 0.0382 - accuracy: 0.9886 - val_loss: 0.1322 - val_accuracy: 0.9764\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 231s 3s/step - loss: 0.0248 - accuracy: 0.9924 - val_loss: 0.1157 - val_accuracy: 0.9709\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 230s 3s/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 0.0581 - val_accuracy: 0.9778\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 229s 3s/step - loss: 0.0126 - accuracy: 0.9972 - val_loss: 0.0558 - val_accuracy: 0.9820\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 231s 3s/step - loss: 0.0347 - accuracy: 0.9889 - val_loss: 0.0510 - val_accuracy: 0.9903\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 230s 3s/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.1076 - val_accuracy: 0.9681\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 230s 3s/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0343 - val_accuracy: 0.9917\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 231s 3s/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.0311 - val_accuracy: 0.9931\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 233s 3s/step - loss: 0.0076 - accuracy: 0.9972 - val_loss: 0.0304 - val_accuracy: 0.9945\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 230s 3s/step - loss: 0.0254 - accuracy: 0.9931 - val_loss: 0.0535 - val_accuracy: 0.9889\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 230s 3s/step - loss: 0.0399 - accuracy: 0.9865 - val_loss: 0.1180 - val_accuracy: 0.9889\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 231s 3s/step - loss: 0.0530 - accuracy: 0.9875 - val_loss: 0.5654 - val_accuracy: 0.7434\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 231s 3s/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 0.0498 - val_accuracy: 0.9875\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 231s 3s/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.0349 - val_accuracy: 0.9903\n",
      "113/113 [==============================] - 51s 440ms/step\n",
      "Epoch 1/100\n",
      "41/41 [==============================] - 125s 3s/step - loss: 0.7592 - accuracy: 0.5275 - val_loss: 0.7065 - val_accuracy: 0.5418\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 104s 3s/step - loss: 0.6870 - accuracy: 0.5438 - val_loss: 0.6921 - val_accuracy: 0.5418\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 104s 3s/step - loss: 0.6934 - accuracy: 0.5431 - val_loss: 0.6909 - val_accuracy: 0.5418\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 103s 3s/step - loss: 0.6912 - accuracy: 0.5446 - val_loss: 0.6815 - val_accuracy: 0.5418\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 104s 3s/step - loss: 0.6880 - accuracy: 0.5446 - val_loss: 0.6763 - val_accuracy: 0.5418\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 103s 3s/step - loss: 0.6998 - accuracy: 0.5400 - val_loss: 0.7406 - val_accuracy: 0.5449\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 104s 3s/step - loss: 0.6835 - accuracy: 0.5438 - val_loss: 0.6701 - val_accuracy: 0.5480\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 104s 3s/step - loss: 0.6800 - accuracy: 0.5190 - val_loss: 0.6736 - val_accuracy: 0.5449\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 103s 3s/step - loss: 0.7203 - accuracy: 0.5415 - val_loss: 0.6828 - val_accuracy: 0.5418\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 103s 3s/step - loss: 0.7258 - accuracy: 0.5144 - val_loss: 0.6883 - val_accuracy: 0.5418\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 103s 3s/step - loss: 0.7076 - accuracy: 0.5431 - val_loss: 0.6892 - val_accuracy: 0.5449\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 103s 3s/step - loss: 0.6817 - accuracy: 0.5454 - val_loss: 0.6737 - val_accuracy: 0.5480\n",
      "13/13 [==============================] - 7s 427ms/step\n",
      "13/13 [==============================] - 6s 434ms/step\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 69s 9s/step - loss: 1.7757 - accuracy: 0.6398 - val_loss: 1.1454 - val_accuracy: 0.6064\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 50s 9s/step - loss: 1.4615 - accuracy: 0.6149 - val_loss: 0.6894 - val_accuracy: 0.7599\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 49s 8s/step - loss: 1.5864 - accuracy: 0.5776 - val_loss: 1.0294 - val_accuracy: 0.7129\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 49s 8s/step - loss: 0.7724 - accuracy: 0.7516 - val_loss: 1.6031 - val_accuracy: 0.5891\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 48s 8s/step - loss: 1.0270 - accuracy: 0.6770 - val_loss: 0.7318 - val_accuracy: 0.8144\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 48s 8s/step - loss: 0.4884 - accuracy: 0.8509 - val_loss: 0.6921 - val_accuracy: 0.7921\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 49s 9s/step - loss: 0.5526 - accuracy: 0.8199 - val_loss: 0.6232 - val_accuracy: 0.8243\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 49s 8s/step - loss: 0.4354 - accuracy: 0.8634 - val_loss: 0.7600 - val_accuracy: 0.7995\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 49s 9s/step - loss: 0.4122 - accuracy: 0.8820 - val_loss: 0.5763 - val_accuracy: 0.8391\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 48s 8s/step - loss: 0.3969 - accuracy: 0.8882 - val_loss: 0.5706 - val_accuracy: 0.8441\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 49s 8s/step - loss: 0.3698 - accuracy: 0.8882 - val_loss: 0.5711 - val_accuracy: 0.8366\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 48s 8s/step - loss: 0.3361 - accuracy: 0.8944 - val_loss: 0.5898 - val_accuracy: 0.8342\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 49s 8s/step - loss: 0.3288 - accuracy: 0.9006 - val_loss: 0.5564 - val_accuracy: 0.8391\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 48s 8s/step - loss: 0.3171 - accuracy: 0.8944 - val_loss: 0.5727 - val_accuracy: 0.8366\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 48s 8s/step - loss: 0.2904 - accuracy: 0.9006 - val_loss: 0.5425 - val_accuracy: 0.8416\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 49s 8s/step - loss: 0.3112 - accuracy: 0.8944 - val_loss: 0.5123 - val_accuracy: 0.8490\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 49s 8s/step - loss: 0.2908 - accuracy: 0.8944 - val_loss: 0.6211 - val_accuracy: 0.8218\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 48s 8s/step - loss: 0.2789 - accuracy: 0.8882 - val_loss: 0.5681 - val_accuracy: 0.8391\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 49s 8s/step - loss: 0.2353 - accuracy: 0.9317 - val_loss: 0.5974 - val_accuracy: 0.8292\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 49s 8s/step - loss: 0.2851 - accuracy: 0.8758 - val_loss: 0.6873 - val_accuracy: 0.8045\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 49s 8s/step - loss: 0.2032 - accuracy: 0.9317 - val_loss: 0.5012 - val_accuracy: 0.8589\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 48s 8s/step - loss: 0.2247 - accuracy: 0.9130 - val_loss: 0.6388 - val_accuracy: 0.8168\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 49s 8s/step - loss: 0.3470 - accuracy: 0.8447 - val_loss: 0.6381 - val_accuracy: 0.8045\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 49s 8s/step - loss: 0.1994 - accuracy: 0.9068 - val_loss: 0.4864 - val_accuracy: 0.8465\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 49s 8s/step - loss: 0.2178 - accuracy: 0.9255 - val_loss: 0.5831 - val_accuracy: 0.8391\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 49s 9s/step - loss: 0.1946 - accuracy: 0.9130 - val_loss: 0.6230 - val_accuracy: 0.8317\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 49s 8s/step - loss: 0.1676 - accuracy: 0.9317 - val_loss: 0.5095 - val_accuracy: 0.8515\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 48s 8s/step - loss: 0.1722 - accuracy: 0.9317 - val_loss: 0.5549 - val_accuracy: 0.8490\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 49s 8s/step - loss: 0.1723 - accuracy: 0.9255 - val_loss: 0.6168 - val_accuracy: 0.8391\n",
      "13/13 [==============================] - 17s 1s/step\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 119s 8s/step - loss: 2.7384 - accuracy: 0.5707 - val_loss: 2.1810 - val_accuracy: 0.5619\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 98s 8s/step - loss: 0.7907 - accuracy: 0.7022 - val_loss: 0.5355 - val_accuracy: 0.7946\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 97s 8s/step - loss: 0.4478 - accuracy: 0.8511 - val_loss: 0.4860 - val_accuracy: 0.8292\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 98s 8s/step - loss: 0.3168 - accuracy: 0.8859 - val_loss: 0.5331 - val_accuracy: 0.7649\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 97s 8s/step - loss: 0.2715 - accuracy: 0.9082 - val_loss: 0.5450 - val_accuracy: 0.7847\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 97s 8s/step - loss: 0.2569 - accuracy: 0.8958 - val_loss: 0.4487 - val_accuracy: 0.8366\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 97s 8s/step - loss: 0.2180 - accuracy: 0.9181 - val_loss: 0.3899 - val_accuracy: 0.8614\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 97s 8s/step - loss: 0.2079 - accuracy: 0.9132 - val_loss: 0.5415 - val_accuracy: 0.8020\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 97s 8s/step - loss: 0.1982 - accuracy: 0.9206 - val_loss: 0.4058 - val_accuracy: 0.8713\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 97s 8s/step - loss: 0.1904 - accuracy: 0.9231 - val_loss: 0.3808 - val_accuracy: 0.8738\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 97s 8s/step - loss: 0.1777 - accuracy: 0.9305 - val_loss: 0.3963 - val_accuracy: 0.8688\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 98s 8s/step - loss: 0.1794 - accuracy: 0.9380 - val_loss: 0.5640 - val_accuracy: 0.8020\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 98s 8s/step - loss: 0.1570 - accuracy: 0.9404 - val_loss: 0.4517 - val_accuracy: 0.8564\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 98s 8s/step - loss: 0.1807 - accuracy: 0.9355 - val_loss: 0.4380 - val_accuracy: 0.8663\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 97s 8s/step - loss: 0.1445 - accuracy: 0.9578 - val_loss: 0.4153 - val_accuracy: 0.8762\n",
      "13/13 [==============================] - 17s 1s/step\n",
      "Epoch 1/100\n",
      "26/26 [==============================] - 202s 7s/step - loss: 1.3784 - accuracy: 0.7109 - val_loss: 1.2122 - val_accuracy: 0.6436\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 181s 7s/step - loss: 0.4469 - accuracy: 0.8548 - val_loss: 0.4161 - val_accuracy: 0.8441\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 180s 7s/step - loss: 0.3579 - accuracy: 0.8710 - val_loss: 0.4207 - val_accuracy: 0.8441\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 181s 7s/step - loss: 0.3149 - accuracy: 0.8747 - val_loss: 0.4431 - val_accuracy: 0.8218\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 179s 7s/step - loss: 0.2812 - accuracy: 0.8871 - val_loss: 0.4829 - val_accuracy: 0.7995\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 179s 7s/step - loss: 0.2733 - accuracy: 0.8883 - val_loss: 0.5514 - val_accuracy: 0.7871\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 180s 7s/step - loss: 0.2770 - accuracy: 0.8921 - val_loss: 0.3602 - val_accuracy: 0.9035\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 177s 7s/step - loss: 0.2087 - accuracy: 0.9206 - val_loss: 0.4161 - val_accuracy: 0.8985\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 177s 7s/step - loss: 0.1890 - accuracy: 0.9268 - val_loss: 0.4115 - val_accuracy: 0.8490\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 177s 7s/step - loss: 0.2590 - accuracy: 0.8933 - val_loss: 0.2933 - val_accuracy: 0.9084\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 176s 7s/step - loss: 0.2643 - accuracy: 0.9107 - val_loss: 0.3045 - val_accuracy: 0.9035\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 177s 7s/step - loss: 0.1913 - accuracy: 0.9305 - val_loss: 0.3667 - val_accuracy: 0.9183\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 178s 7s/step - loss: 0.1593 - accuracy: 0.9454 - val_loss: 0.3630 - val_accuracy: 0.9183\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 177s 7s/step - loss: 0.1539 - accuracy: 0.9454 - val_loss: 0.4238 - val_accuracy: 0.9134\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 177s 7s/step - loss: 0.1298 - accuracy: 0.9640 - val_loss: 0.3601 - val_accuracy: 0.9134\n",
      "13/13 [==============================] - 17s 1s/step\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 282s 7s/step - loss: 1.1392 - accuracy: 0.6741 - val_loss: 0.5245 - val_accuracy: 0.8020\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 260s 7s/step - loss: 0.3361 - accuracy: 0.8668 - val_loss: 0.3644 - val_accuracy: 0.8762\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 260s 7s/step - loss: 0.2751 - accuracy: 0.8908 - val_loss: 0.4125 - val_accuracy: 0.8391\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 260s 7s/step - loss: 0.2485 - accuracy: 0.8941 - val_loss: 0.3454 - val_accuracy: 0.8861\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 261s 7s/step - loss: 0.2334 - accuracy: 0.9132 - val_loss: 0.4266 - val_accuracy: 0.8540\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 260s 7s/step - loss: 0.2036 - accuracy: 0.9256 - val_loss: 0.2943 - val_accuracy: 0.9035\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 259s 7s/step - loss: 0.1944 - accuracy: 0.9305 - val_loss: 0.4697 - val_accuracy: 0.8490\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 259s 7s/step - loss: 0.2521 - accuracy: 0.8991 - val_loss: 0.3820 - val_accuracy: 0.8911\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 258s 7s/step - loss: 0.2226 - accuracy: 0.9214 - val_loss: 0.3837 - val_accuracy: 0.8564\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 259s 7s/step - loss: 0.1709 - accuracy: 0.9421 - val_loss: 0.2770 - val_accuracy: 0.8960\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 259s 7s/step - loss: 0.1223 - accuracy: 0.9586 - val_loss: 0.3517 - val_accuracy: 0.8639\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 259s 7s/step - loss: 0.1161 - accuracy: 0.9661 - val_loss: 0.2090 - val_accuracy: 0.9233\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 260s 7s/step - loss: 0.0944 - accuracy: 0.9719 - val_loss: 0.2288 - val_accuracy: 0.9307\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 260s 7s/step - loss: 0.0950 - accuracy: 0.9719 - val_loss: 0.1780 - val_accuracy: 0.9356\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 260s 7s/step - loss: 0.0720 - accuracy: 0.9793 - val_loss: 0.1881 - val_accuracy: 0.9530\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 260s 7s/step - loss: 0.0650 - accuracy: 0.9826 - val_loss: 0.1719 - val_accuracy: 0.9554\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 259s 7s/step - loss: 0.0617 - accuracy: 0.9843 - val_loss: 0.7586 - val_accuracy: 0.8540\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 259s 7s/step - loss: 0.0979 - accuracy: 0.9677 - val_loss: 0.3237 - val_accuracy: 0.9307\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 259s 7s/step - loss: 0.0768 - accuracy: 0.9752 - val_loss: 0.2629 - val_accuracy: 0.9356\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 260s 7s/step - loss: 0.0512 - accuracy: 0.9851 - val_loss: 0.1749 - val_accuracy: 0.9332\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 259s 7s/step - loss: 0.0342 - accuracy: 0.9917 - val_loss: 0.2056 - val_accuracy: 0.9505\n",
      "13/13 [==============================] - 17s 1s/step\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 365s 7s/step - loss: 1.6408 - accuracy: 0.6867 - val_loss: 0.6925 - val_accuracy: 0.7228\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 342s 7s/step - loss: 0.3346 - accuracy: 0.8753 - val_loss: 0.3686 - val_accuracy: 0.8762\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 340s 7s/step - loss: 0.3028 - accuracy: 0.8778 - val_loss: 0.3208 - val_accuracy: 0.8861\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 339s 7s/step - loss: 0.2887 - accuracy: 0.8883 - val_loss: 0.2738 - val_accuracy: 0.9035\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 340s 7s/step - loss: 0.2564 - accuracy: 0.9014 - val_loss: 0.2614 - val_accuracy: 0.9208\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 339s 7s/step - loss: 0.2441 - accuracy: 0.9094 - val_loss: 0.2479 - val_accuracy: 0.9208\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 339s 7s/step - loss: 0.2045 - accuracy: 0.9249 - val_loss: 0.3164 - val_accuracy: 0.8589\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 339s 7s/step - loss: 0.1909 - accuracy: 0.9280 - val_loss: 0.3721 - val_accuracy: 0.8762\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 340s 7s/step - loss: 0.1844 - accuracy: 0.9206 - val_loss: 0.2617 - val_accuracy: 0.9183\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 339s 7s/step - loss: 0.1431 - accuracy: 0.9448 - val_loss: 0.2700 - val_accuracy: 0.9183\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 339s 7s/step - loss: 0.1580 - accuracy: 0.9361 - val_loss: 0.2008 - val_accuracy: 0.9406\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 340s 7s/step - loss: 0.1340 - accuracy: 0.9510 - val_loss: 0.1950 - val_accuracy: 0.9381\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 341s 7s/step - loss: 0.1048 - accuracy: 0.9640 - val_loss: 0.3178 - val_accuracy: 0.8639\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 338s 7s/step - loss: 0.0949 - accuracy: 0.9677 - val_loss: 0.2219 - val_accuracy: 0.9356\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 337s 7s/step - loss: 0.0868 - accuracy: 0.9696 - val_loss: 0.2190 - val_accuracy: 0.9356\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 336s 7s/step - loss: 0.0860 - accuracy: 0.9702 - val_loss: 0.2412 - val_accuracy: 0.9480\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 337s 7s/step - loss: 0.0689 - accuracy: 0.9764 - val_loss: 0.1468 - val_accuracy: 0.9505\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 336s 7s/step - loss: 0.0839 - accuracy: 0.9702 - val_loss: 0.2061 - val_accuracy: 0.9431\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 336s 7s/step - loss: 0.0707 - accuracy: 0.9770 - val_loss: 0.1339 - val_accuracy: 0.9678\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 337s 7s/step - loss: 0.0471 - accuracy: 0.9882 - val_loss: 0.1316 - val_accuracy: 0.9653\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 335s 7s/step - loss: 0.0532 - accuracy: 0.9870 - val_loss: 0.5088 - val_accuracy: 0.8614\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 337s 7s/step - loss: 0.0536 - accuracy: 0.9808 - val_loss: 0.0991 - val_accuracy: 0.9678\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 338s 7s/step - loss: 0.0401 - accuracy: 0.9895 - val_loss: 0.2346 - val_accuracy: 0.9282\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 336s 7s/step - loss: 0.0474 - accuracy: 0.9857 - val_loss: 0.1437 - val_accuracy: 0.9530\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 336s 7s/step - loss: 0.0517 - accuracy: 0.9820 - val_loss: 0.1076 - val_accuracy: 0.9728\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 336s 7s/step - loss: 0.0449 - accuracy: 0.9876 - val_loss: 0.1709 - val_accuracy: 0.9455\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 336s 7s/step - loss: 0.0302 - accuracy: 0.9913 - val_loss: 0.1638 - val_accuracy: 0.9629\n",
      "13/13 [==============================] - 17s 1s/step\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 86s 6s/step - loss: 7.8851 - accuracy: 0.5373 - val_loss: 12.0670 - val_accuracy: 0.4938\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 67s 6s/step - loss: 3.4730 - accuracy: 0.6118 - val_loss: 0.5903 - val_accuracy: 0.8025\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 66s 6s/step - loss: 1.3156 - accuracy: 0.6025 - val_loss: 3.0423 - val_accuracy: 0.4938\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 66s 6s/step - loss: 1.0986 - accuracy: 0.6366 - val_loss: 0.4197 - val_accuracy: 0.8272\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 66s 6s/step - loss: 0.9327 - accuracy: 0.6615 - val_loss: 1.5792 - val_accuracy: 0.5062\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 66s 6s/step - loss: 0.7868 - accuracy: 0.7081 - val_loss: 0.3994 - val_accuracy: 0.8272\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 66s 6s/step - loss: 0.4574 - accuracy: 0.8075 - val_loss: 0.5714 - val_accuracy: 0.7407\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 66s 6s/step - loss: 0.3284 - accuracy: 0.8820 - val_loss: 0.3781 - val_accuracy: 0.8272\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 66s 6s/step - loss: 0.3116 - accuracy: 0.8882 - val_loss: 0.5798 - val_accuracy: 0.7160\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 66s 6s/step - loss: 0.3066 - accuracy: 0.8727 - val_loss: 0.3335 - val_accuracy: 0.8272\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 66s 6s/step - loss: 0.2846 - accuracy: 0.8820 - val_loss: 0.4838 - val_accuracy: 0.7531\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 66s 6s/step - loss: 0.2484 - accuracy: 0.9161 - val_loss: 0.4515 - val_accuracy: 0.7778\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 66s 6s/step - loss: 0.2376 - accuracy: 0.9161 - val_loss: 0.3020 - val_accuracy: 0.8889\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 66s 6s/step - loss: 0.2550 - accuracy: 0.8975 - val_loss: 0.4828 - val_accuracy: 0.7901\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 66s 6s/step - loss: 0.2315 - accuracy: 0.9068 - val_loss: 0.2948 - val_accuracy: 0.9136\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 66s 6s/step - loss: 0.2411 - accuracy: 0.9006 - val_loss: 0.5499 - val_accuracy: 0.7654\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 66s 6s/step - loss: 0.1920 - accuracy: 0.9317 - val_loss: 0.3435 - val_accuracy: 0.8519\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 67s 6s/step - loss: 0.1775 - accuracy: 0.9255 - val_loss: 0.3533 - val_accuracy: 0.8519\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 69s 6s/step - loss: 0.1637 - accuracy: 0.9410 - val_loss: 0.5048 - val_accuracy: 0.7778\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 77s 7s/step - loss: 0.2207 - accuracy: 0.9255 - val_loss: 0.2686 - val_accuracy: 0.9012\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 79s 7s/step - loss: 0.2626 - accuracy: 0.9068 - val_loss: 1.0120 - val_accuracy: 0.6914\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 76s 7s/step - loss: 0.2299 - accuracy: 0.9193 - val_loss: 0.3285 - val_accuracy: 0.8642\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 79s 7s/step - loss: 0.2394 - accuracy: 0.9006 - val_loss: 0.2891 - val_accuracy: 0.8889\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 929s 92s/step - loss: 0.2213 - accuracy: 0.9130 - val_loss: 0.9523 - val_accuracy: 0.6296\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 81s 7s/step - loss: 0.2503 - accuracy: 0.8882 - val_loss: 0.2496 - val_accuracy: 0.8765\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 82s 7s/step - loss: 0.1671 - accuracy: 0.9317 - val_loss: 0.3124 - val_accuracy: 0.8889\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 93s 8s/step - loss: 0.1405 - accuracy: 0.9472 - val_loss: 0.3252 - val_accuracy: 0.9012\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 81s 7s/step - loss: 0.1295 - accuracy: 0.9472 - val_loss: 0.2726 - val_accuracy: 0.9136\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 83s 8s/step - loss: 0.1194 - accuracy: 0.9565 - val_loss: 0.3059 - val_accuracy: 0.8765\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 80s 7s/step - loss: 0.1206 - accuracy: 0.9627 - val_loss: 0.2461 - val_accuracy: 0.9259\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 80s 7s/step - loss: 0.1407 - accuracy: 0.9503 - val_loss: 0.3676 - val_accuracy: 0.8642\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 80s 7s/step - loss: 0.1194 - accuracy: 0.9565 - val_loss: 0.4192 - val_accuracy: 0.8519\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 89s 8s/step - loss: 0.1151 - accuracy: 0.9658 - val_loss: 0.2626 - val_accuracy: 0.9012\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 84s 8s/step - loss: 0.1068 - accuracy: 0.9658 - val_loss: 0.6518 - val_accuracy: 0.7531\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 86s 8s/step - loss: 0.1143 - accuracy: 0.9658 - val_loss: 0.2514 - val_accuracy: 0.9136\n",
      "3/3 [==============================] - 7s 1s/step\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 136s 9s/step - loss: 2.1144 - accuracy: 0.5062 - val_loss: 1.6932 - val_accuracy: 0.5679\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 97s 9s/step - loss: 0.4806 - accuracy: 0.7919 - val_loss: 1.5072 - val_accuracy: 0.6543\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 101s 9s/step - loss: 0.3448 - accuracy: 0.8758 - val_loss: 1.3739 - val_accuracy: 0.6914\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 93s 9s/step - loss: 0.3323 - accuracy: 0.8820 - val_loss: 0.9809 - val_accuracy: 0.7407\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 96s 9s/step - loss: 0.2671 - accuracy: 0.8913 - val_loss: 0.7254 - val_accuracy: 0.7901\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 87s 8s/step - loss: 0.3041 - accuracy: 0.8758 - val_loss: 0.6056 - val_accuracy: 0.8519\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 96s 9s/step - loss: 0.2944 - accuracy: 0.9006 - val_loss: 0.6180 - val_accuracy: 0.8519\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 88s 8s/step - loss: 0.2473 - accuracy: 0.9006 - val_loss: 0.7577 - val_accuracy: 0.8272\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 88s 8s/step - loss: 0.2155 - accuracy: 0.9068 - val_loss: 0.9378 - val_accuracy: 0.7778\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 83s 7s/step - loss: 0.1842 - accuracy: 0.9317 - val_loss: 0.7699 - val_accuracy: 0.8272\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 98s 9s/step - loss: 0.1668 - accuracy: 0.9348 - val_loss: 0.7633 - val_accuracy: 0.8272\n",
      "3/3 [==============================] - 6s 1s/step\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 125s 8s/step - loss: 2.1027 - accuracy: 0.5776 - val_loss: 1.0768 - val_accuracy: 0.5802\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 105s 10s/step - loss: 0.6551 - accuracy: 0.7391 - val_loss: 0.5362 - val_accuracy: 0.7654\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 87s 8s/step - loss: 0.3818 - accuracy: 0.8416 - val_loss: 0.7977 - val_accuracy: 0.6173\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 86s 8s/step - loss: 0.3014 - accuracy: 0.8882 - val_loss: 0.3495 - val_accuracy: 0.8025\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 99s 9s/step - loss: 0.2658 - accuracy: 0.9068 - val_loss: 0.3680 - val_accuracy: 0.8148\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 89s 8s/step - loss: 0.2360 - accuracy: 0.9130 - val_loss: 0.3055 - val_accuracy: 0.8395\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 84s 8s/step - loss: 0.2311 - accuracy: 0.9224 - val_loss: 0.3359 - val_accuracy: 0.8395\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 174s 17s/step - loss: 0.2676 - accuracy: 0.8820 - val_loss: 0.4537 - val_accuracy: 0.7901\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 114s 10s/step - loss: 0.2131 - accuracy: 0.9193 - val_loss: 0.3068 - val_accuracy: 0.8642\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 112s 10s/step - loss: 0.1951 - accuracy: 0.9317 - val_loss: 0.3007 - val_accuracy: 0.8642\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 100s 9s/step - loss: 0.1817 - accuracy: 0.9410 - val_loss: 0.3038 - val_accuracy: 0.8519\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 116s 11s/step - loss: 0.1694 - accuracy: 0.9348 - val_loss: 0.3040 - val_accuracy: 0.8765\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 112s 10s/step - loss: 0.1896 - accuracy: 0.9161 - val_loss: 0.3611 - val_accuracy: 0.8519\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 109s 10s/step - loss: 0.1621 - accuracy: 0.9286 - val_loss: 0.2904 - val_accuracy: 0.8395\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 113s 10s/step - loss: 0.1765 - accuracy: 0.9348 - val_loss: 0.3292 - val_accuracy: 0.8395\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 108s 10s/step - loss: 0.1427 - accuracy: 0.9472 - val_loss: 0.5125 - val_accuracy: 0.7901\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 98s 9s/step - loss: 0.1564 - accuracy: 0.9441 - val_loss: 0.4485 - val_accuracy: 0.8765\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 91s 8s/step - loss: 0.1510 - accuracy: 0.9503 - val_loss: 0.4179 - val_accuracy: 0.8272\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 107s 9s/step - loss: 0.1459 - accuracy: 0.9410 - val_loss: 0.4037 - val_accuracy: 0.8148\n",
      "3/3 [==============================] - 9s 1s/step\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 129s 9s/step - loss: 0.9089 - accuracy: 0.6025 - val_loss: 1.0834 - val_accuracy: 0.6420\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 108s 10s/step - loss: 0.5702 - accuracy: 0.7826 - val_loss: 1.2446 - val_accuracy: 0.6049\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 91s 8s/step - loss: 0.4211 - accuracy: 0.8137 - val_loss: 0.6462 - val_accuracy: 0.7654\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 93s 8s/step - loss: 0.3502 - accuracy: 0.8199 - val_loss: 0.8644 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 92s 8s/step - loss: 0.3605 - accuracy: 0.8447 - val_loss: 0.8911 - val_accuracy: 0.6790\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 91s 8s/step - loss: 0.3002 - accuracy: 0.8634 - val_loss: 0.4768 - val_accuracy: 0.8148\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 95s 8s/step - loss: 0.2633 - accuracy: 0.8820 - val_loss: 0.5774 - val_accuracy: 0.8272\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 84s 7s/step - loss: 0.2437 - accuracy: 0.8913 - val_loss: 0.4552 - val_accuracy: 0.8025\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 89s 8s/step - loss: 0.2238 - accuracy: 0.9068 - val_loss: 0.3277 - val_accuracy: 0.8889\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 98s 9s/step - loss: 0.2385 - accuracy: 0.8944 - val_loss: 0.3914 - val_accuracy: 0.8519\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 85s 7s/step - loss: 0.2062 - accuracy: 0.9161 - val_loss: 0.4236 - val_accuracy: 0.8395\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 78s 7s/step - loss: 0.1956 - accuracy: 0.9317 - val_loss: 1.0410 - val_accuracy: 0.6790\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 76s 7s/step - loss: 0.2252 - accuracy: 0.9099 - val_loss: 0.9540 - val_accuracy: 0.7037\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 74s 7s/step - loss: 0.2303 - accuracy: 0.9161 - val_loss: 0.4330 - val_accuracy: 0.8889\n",
      "WARNING:tensorflow:5 out of the last 23 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe0aa8c3dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-24 09:29:11,771 - WARNING - 5 out of the last 23 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe0aa8c3dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 6s 982ms/step\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 87s 7s/step - loss: 1.4948 - accuracy: 0.5404 - val_loss: 1.3783 - val_accuracy: 0.5802\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 69s 6s/step - loss: 0.6413 - accuracy: 0.7609 - val_loss: 1.1021 - val_accuracy: 0.7037\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 69s 6s/step - loss: 0.5148 - accuracy: 0.8012 - val_loss: 0.7486 - val_accuracy: 0.7901\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 69s 6s/step - loss: 0.5429 - accuracy: 0.7733 - val_loss: 0.8749 - val_accuracy: 0.7531\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 70s 6s/step - loss: 0.4289 - accuracy: 0.8416 - val_loss: 0.6997 - val_accuracy: 0.8025\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 69s 6s/step - loss: 0.3447 - accuracy: 0.8509 - val_loss: 0.4880 - val_accuracy: 0.8642\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 69s 6s/step - loss: 0.3202 - accuracy: 0.8665 - val_loss: 0.6827 - val_accuracy: 0.8148\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 68s 6s/step - loss: 0.3200 - accuracy: 0.8758 - val_loss: 0.5423 - val_accuracy: 0.8765\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 69s 6s/step - loss: 0.3451 - accuracy: 0.8634 - val_loss: 0.5514 - val_accuracy: 0.8642\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 68s 6s/step - loss: 0.2847 - accuracy: 0.8851 - val_loss: 0.6420 - val_accuracy: 0.8519\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 76s 7s/step - loss: 0.2791 - accuracy: 0.8882 - val_loss: 0.7731 - val_accuracy: 0.7901\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe2b91805e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-24 09:42:29,453 - WARNING - 5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe2b91805e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 6s 1s/step\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 412s 8s/step - loss: 0.4809 - accuracy: 0.8133 - val_loss: 0.4132 - val_accuracy: 0.8713\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 427s 8s/step - loss: 0.3674 - accuracy: 0.8524 - val_loss: 0.4805 - val_accuracy: 0.8292\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 371s 7s/step - loss: 0.2968 - accuracy: 0.8809 - val_loss: 0.5297 - val_accuracy: 0.8292\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 381s 7s/step - loss: 0.2517 - accuracy: 0.9032 - val_loss: 0.2880 - val_accuracy: 0.9208\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 370s 7s/step - loss: 0.2173 - accuracy: 0.9156 - val_loss: 0.2811 - val_accuracy: 0.9257\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 367s 7s/step - loss: 0.1833 - accuracy: 0.9324 - val_loss: 0.2435 - val_accuracy: 0.9282\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 362s 7s/step - loss: 0.1533 - accuracy: 0.9491 - val_loss: 0.3118 - val_accuracy: 0.8936\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 376s 7s/step - loss: 0.1489 - accuracy: 0.9473 - val_loss: 0.4079 - val_accuracy: 0.8515\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 430s 8s/step - loss: 0.1682 - accuracy: 0.9442 - val_loss: 0.2251 - val_accuracy: 0.9505\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 397s 8s/step - loss: 0.1069 - accuracy: 0.9659 - val_loss: 0.1926 - val_accuracy: 0.9480\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 352s 7s/step - loss: 0.1044 - accuracy: 0.9653 - val_loss: 0.1445 - val_accuracy: 0.9455\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 348s 7s/step - loss: 0.0880 - accuracy: 0.9715 - val_loss: 0.1843 - val_accuracy: 0.9530\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 341s 7s/step - loss: 0.0753 - accuracy: 0.9758 - val_loss: 0.2286 - val_accuracy: 0.9257\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 341s 7s/step - loss: 0.0642 - accuracy: 0.9814 - val_loss: 0.1234 - val_accuracy: 0.9629\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 339s 7s/step - loss: 0.0566 - accuracy: 0.9857 - val_loss: 0.1447 - val_accuracy: 0.9530\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 346s 7s/step - loss: 0.0792 - accuracy: 0.9739 - val_loss: 0.4644 - val_accuracy: 0.9059\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 345s 7s/step - loss: 0.0617 - accuracy: 0.9833 - val_loss: 0.1354 - val_accuracy: 0.9604\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 342s 7s/step - loss: 0.0530 - accuracy: 0.9857 - val_loss: 0.5199 - val_accuracy: 0.8515\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 343s 7s/step - loss: 0.0612 - accuracy: 0.9845 - val_loss: 0.0936 - val_accuracy: 0.9653\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 345s 7s/step - loss: 0.0439 - accuracy: 0.9870 - val_loss: 0.1000 - val_accuracy: 0.9629\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 347s 7s/step - loss: 0.0399 - accuracy: 0.9907 - val_loss: 0.0991 - val_accuracy: 0.9678\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 434s 9s/step - loss: 0.0372 - accuracy: 0.9882 - val_loss: 0.0929 - val_accuracy: 0.9653\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 428s 8s/step - loss: 0.0277 - accuracy: 0.9913 - val_loss: 0.0947 - val_accuracy: 0.9653\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 389s 8s/step - loss: 0.0277 - accuracy: 0.9919 - val_loss: 0.3787 - val_accuracy: 0.8837\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 376s 7s/step - loss: 0.0997 - accuracy: 0.9702 - val_loss: 0.0954 - val_accuracy: 0.9703\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 339s 7s/step - loss: 0.0594 - accuracy: 0.9851 - val_loss: 0.0966 - val_accuracy: 0.9678\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 365s 7s/step - loss: 0.0445 - accuracy: 0.9870 - val_loss: 0.1713 - val_accuracy: 0.9629\n",
      "13/13 [==============================] - 19s 1s/step\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 710s 11s/step - loss: 1.3164 - accuracy: 0.7143 - val_loss: 0.6883 - val_accuracy: 0.4938\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 690s 11s/step - loss: 0.3302 - accuracy: 0.8750 - val_loss: 0.6885 - val_accuracy: 0.4938\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 645s 10s/step - loss: 0.2912 - accuracy: 0.8849 - val_loss: 0.6869 - val_accuracy: 0.5470\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 642s 10s/step - loss: 0.2671 - accuracy: 0.8953 - val_loss: 0.6844 - val_accuracy: 0.6133\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 632s 10s/step - loss: 0.2581 - accuracy: 0.8993 - val_loss: 0.6856 - val_accuracy: 0.5490\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 649s 10s/step - loss: 0.2507 - accuracy: 0.9082 - val_loss: 0.6898 - val_accuracy: 0.5062\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 649s 10s/step - loss: 0.1958 - accuracy: 0.9296 - val_loss: 0.6855 - val_accuracy: 0.5082\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 682s 11s/step - loss: 0.1868 - accuracy: 0.9425 - val_loss: 0.7347 - val_accuracy: 0.5062\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 712s 11s/step - loss: 0.1456 - accuracy: 0.9479 - val_loss: 0.7138 - val_accuracy: 0.5062\n",
      "113/113 [==============================] - 181s 2s/step\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 467s 9s/step - loss: 3.0327 - accuracy: 0.5986 - val_loss: 0.5778 - val_accuracy: 0.7550\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 406s 8s/step - loss: 0.3967 - accuracy: 0.8269 - val_loss: 0.4001 - val_accuracy: 0.8490\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 444s 9s/step - loss: 0.3422 - accuracy: 0.8629 - val_loss: 0.3517 - val_accuracy: 0.8688\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 394s 8s/step - loss: 0.3223 - accuracy: 0.8635 - val_loss: 0.3394 - val_accuracy: 0.8762\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 389s 8s/step - loss: 0.2968 - accuracy: 0.8790 - val_loss: 0.3165 - val_accuracy: 0.8762\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 394s 8s/step - loss: 0.2852 - accuracy: 0.8852 - val_loss: 0.2983 - val_accuracy: 0.8861\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 391s 8s/step - loss: 0.2583 - accuracy: 0.9026 - val_loss: 0.3208 - val_accuracy: 0.8812\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 387s 8s/step - loss: 0.2458 - accuracy: 0.9045 - val_loss: 0.2920 - val_accuracy: 0.8936\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 386s 8s/step - loss: 0.2514 - accuracy: 0.8896 - val_loss: 0.2696 - val_accuracy: 0.8960\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 386s 8s/step - loss: 0.2194 - accuracy: 0.9169 - val_loss: 0.3051 - val_accuracy: 0.9010\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 374s 7s/step - loss: 0.2357 - accuracy: 0.8995 - val_loss: 0.2607 - val_accuracy: 0.9183\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 377s 7s/step - loss: 0.2265 - accuracy: 0.9150 - val_loss: 0.2525 - val_accuracy: 0.9183\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 382s 8s/step - loss: 0.2432 - accuracy: 0.9088 - val_loss: 0.2500 - val_accuracy: 0.9233\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 377s 7s/step - loss: 0.1726 - accuracy: 0.9305 - val_loss: 0.2167 - val_accuracy: 0.9332\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 402s 8s/step - loss: 0.1489 - accuracy: 0.9460 - val_loss: 0.2543 - val_accuracy: 0.9084\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 408s 8s/step - loss: 0.1306 - accuracy: 0.9516 - val_loss: 0.2079 - val_accuracy: 0.9332\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 406s 8s/step - loss: 0.1124 - accuracy: 0.9578 - val_loss: 0.2211 - val_accuracy: 0.8936\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 374s 7s/step - loss: 0.1113 - accuracy: 0.9634 - val_loss: 0.1927 - val_accuracy: 0.9307\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 370s 7s/step - loss: 0.1127 - accuracy: 0.9553 - val_loss: 0.1907 - val_accuracy: 0.9406\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 369s 7s/step - loss: 0.0842 - accuracy: 0.9733 - val_loss: 0.1860 - val_accuracy: 0.9307\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 364s 7s/step - loss: 0.0678 - accuracy: 0.9801 - val_loss: 0.1956 - val_accuracy: 0.9134\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 336s 7s/step - loss: 0.0875 - accuracy: 0.9758 - val_loss: 0.1175 - val_accuracy: 0.9703\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 326s 6s/step - loss: 0.0636 - accuracy: 0.9820 - val_loss: 0.2951 - val_accuracy: 0.8936\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 322s 6s/step - loss: 0.0706 - accuracy: 0.9752 - val_loss: 0.7210 - val_accuracy: 0.7871\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 324s 6s/step - loss: 0.0452 - accuracy: 0.9882 - val_loss: 0.1249 - val_accuracy: 0.9629\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 324s 6s/step - loss: 0.0624 - accuracy: 0.9820 - val_loss: 0.1058 - val_accuracy: 0.9728\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 324s 6s/step - loss: 0.0438 - accuracy: 0.9851 - val_loss: 0.1390 - val_accuracy: 0.9579\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 328s 6s/step - loss: 0.0413 - accuracy: 0.9845 - val_loss: 0.1206 - val_accuracy: 0.9728\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 346s 7s/step - loss: 0.0265 - accuracy: 0.9907 - val_loss: 0.1196 - val_accuracy: 0.9653\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 403s 8s/step - loss: 0.0559 - accuracy: 0.9770 - val_loss: 0.5977 - val_accuracy: 0.8218\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 408s 8s/step - loss: 0.0612 - accuracy: 0.9833 - val_loss: 0.1223 - val_accuracy: 0.9678\n",
      "13/13 [==============================] - 18s 1s/step\n",
      "13/13 [==============================] - 16s 1s/step\n",
      "13/13 [==============================] - 16s 1s/step\n",
      "13/13 [==============================] - 16s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-24 17:31:15,171 - INFO - All experiments and analyses completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import json\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import time\n",
    "from scipy.signal import resample\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Dataset definitions\n",
    "datasets = [\n",
    "    {\"name\": \"CUSPH-SR-AF\", \"data\": \"data/data_2class_normal.npy\", \"labels\": \"data/labels_2class_normal.npy\", \"num_classes\": 2, \"input_shape\": (5000, 12)},\n",
    "    {\"name\": \"CSPC18-SR-AF\", \"data\": \"data/data_2class_cpsc18.npy\", \"labels\": \"data/labels_2class_cpsc18.npy\", \"num_classes\": 2, \"input_shape\": (15000, 12)},\n",
    "]\n",
    "\n",
    "filter_combinations = [[32, 64, 128]]\n",
    "\n",
    "def save_results(results, dataset_name, experiment_type, train_condition, test_condition):\n",
    "    filename = f\"robustness/results/{dataset_name}_{experiment_type}_train_{train_condition}_test_{test_condition}.json\"\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "def save_confusion_matrix(cm, dataset_name, experiment_name):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {dataset_name} - {experiment_name}')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"robustness/results/{dataset_name}_{experiment_name}_confusion_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "def calculate_dataset_stats(data, labels):\n",
    "    stats = {\n",
    "        'overall': {\n",
    "            'mean': float(np.mean(data)),\n",
    "            'std': float(np.std(data)),\n",
    "            'min': float(np.min(data)),\n",
    "            'max': float(np.max(data)),\n",
    "        },\n",
    "        'channel_wise': [],\n",
    "        'label_distribution': np.bincount(labels.astype(int)).tolist()\n",
    "    }\n",
    "    \n",
    "    for i in range(data.shape[-1]):\n",
    "        channel_data = data[:, :, i]\n",
    "        channel_stats = {\n",
    "            'mean': float(np.mean(channel_data)),\n",
    "            'std': float(np.std(channel_data)),\n",
    "            'min': float(np.min(channel_data)),\n",
    "            'max': float(np.max(channel_data)),\n",
    "        }\n",
    "        stats['channel_wise'].append(channel_stats)\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def downsample_block(x, filters):\n",
    "    x = layers.Conv1D(filters // 2, 1, strides=1, padding='same')(x)\n",
    "    x = mixed_pool_operator(x)\n",
    "    return x\n",
    "\n",
    "def branched_nodal_operator(x, filters, kernel_size=5, activation='relu'):\n",
    "    y1 = layers.Conv1D(filters // 2, kernel_size, dilation_rate=2, padding='same')(x)\n",
    "    y1 = layers.BatchNormalization()(y1)\n",
    "    y1 = layers.Activation(activation)(y1)\n",
    "\n",
    "    y2 = layers.SeparableConv1D(filters // 2, kernel_size, padding='same')(x)\n",
    "    y2 = layers.BatchNormalization()(y2)\n",
    "    y2 = layers.Activation(activation)(y2)\n",
    "\n",
    "    y = layers.Concatenate()([y1, y2])\n",
    "    return y\n",
    "\n",
    "def mixed_pool_operator(x, pool_size=2, strides=1):\n",
    "    y1 = layers.AveragePooling1D(pool_size, strides, padding='same')(x)\n",
    "    y2 = layers.MaxPooling1D(pool_size, strides, padding='same')(x)\n",
    "    y = layers.Concatenate()([y1, y2])\n",
    "    return y\n",
    "\n",
    "def squeeze_and_excitation_block(x, ratio=16):\n",
    "    num_channels = x.shape[-1]\n",
    "    squeeze = layers.GlobalAveragePooling1D()(x)\n",
    "    excitation = layers.Dense(num_channels // ratio, activation='relu')(squeeze)\n",
    "    excitation = layers.Dense(num_channels, activation='sigmoid')(excitation)\n",
    "    excitation = layers.Reshape((1, num_channels))(excitation)\n",
    "    scale = layers.Multiply()([x, excitation])\n",
    "    return scale\n",
    "\n",
    "def residual_block_SERN_AwGOP(x, filters, kernel_size=5, downsample=False):\n",
    "    y = branched_nodal_operator(x, filters, kernel_size)\n",
    "    y = branched_nodal_operator(y, filters, kernel_size)\n",
    "\n",
    "    if downsample:\n",
    "        x = downsample_block(x, filters)\n",
    "\n",
    "    y = squeeze_and_excitation_block(y)\n",
    "\n",
    "    attention_weights = layers.Dense(1, activation='sigmoid')(x)\n",
    "    gop_out = layers.Multiply()([attention_weights, y])\n",
    "    gop_out = layers.Add()([gop_out, x])\n",
    "    gop_out = layers.Activation('relu')(gop_out)\n",
    "    return gop_out\n",
    "\n",
    "def create_SERN_AwGOP(input_shape, num_classes, filters):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv1D(filters[0], 5, strides=2, padding='same', activation='relu')(inputs)\n",
    "    x = layers.MaxPooling1D(pool_size=3, strides=2, padding='same')(x)\n",
    "\n",
    "    for f in filters[1:]:\n",
    "        x = residual_block_SERN_AwGOP(x, f, downsample=True)\n",
    "        x = residual_block_SERN_AwGOP(x, f)\n",
    "        x = residual_block_SERN_AwGOP(x, f)\n",
    "        x = residual_block_SERN_AwGOP(x, f)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    if num_classes == 2:\n",
    "        outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    else:\n",
    "        outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    if num_classes == 2:\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    else:\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val):\n",
    "    try:\n",
    "        history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        return history\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in train_model: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, num_classes):\n",
    "    try:\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1) if num_classes > 2 else (y_pred > 0.5).astype(int).flatten()\n",
    "\n",
    "        results = {\n",
    "            'accuracy': float(accuracy_score(y_test, y_pred_classes)),\n",
    "            'precision_weighted': float(precision_score(y_test, y_pred_classes, average='weighted')),\n",
    "            'recall_weighted': float(recall_score(y_test, y_pred_classes, average='weighted')),\n",
    "            'f1_weighted': float(f1_score(y_test, y_pred_classes, average='weighted')),\n",
    "        }\n",
    "\n",
    "        # Add unweighted sensitivity and specificity\n",
    "        cm = confusion_matrix(y_test, y_pred_classes)\n",
    "        sensitivity = cm[1,1] / (cm[1,1] + cm[1,0])\n",
    "        specificity = cm[0,0] / (cm[0,0] + cm[0,1])\n",
    "        results['sensitivity_unweighted'] = float(sensitivity)\n",
    "        results['specificity_unweighted'] = float(specificity)\n",
    "\n",
    "        if num_classes == 2:\n",
    "            results['auc_roc'] = float(roc_auc_score(y_test, y_pred))\n",
    "            results['average_precision'] = float(average_precision_score(y_test, y_pred))\n",
    "\n",
    "        return results, cm\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in evaluate_model: {str(e)}\")\n",
    "        return {}, None\n",
    "\n",
    "def add_gaussian_noise(data, noise_factor=0.05):\n",
    "    noise = np.random.normal(loc=0, scale=1, size=data.shape)\n",
    "    return data + noise_factor * noise\n",
    "\n",
    "def data_efficiency_analysis(dataset, model_fn, filters, fractions=[0.1, 0.25, 0.5, 0.75, 1.0]):\n",
    "    try:\n",
    "        data = np.load(dataset['data'])\n",
    "        labels = np.load(dataset['labels'])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "        results = {}\n",
    "        for fraction in fractions:\n",
    "            n_samples = int(len(X_train) * fraction)\n",
    "            X_train_subset = X_train[:n_samples]\n",
    "            y_train_subset = y_train[:n_samples]\n",
    "\n",
    "            model = model_fn(dataset['input_shape'], dataset['num_classes'], filters)\n",
    "            history = train_model(model, X_train_subset, y_train_subset, X_test, y_test)\n",
    "            test_results, _ = evaluate_model(model, X_test, y_test, dataset['num_classes'])\n",
    "            results[fraction] = test_results\n",
    "\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in data_efficiency_analysis: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "def longitudinal_analysis(dataset, model_fn, filters, num_time_points=5):\n",
    "    try:\n",
    "        data = np.load(dataset['data'])\n",
    "        labels = np.load(dataset['labels'])\n",
    "\n",
    "        # Assume data is sorted chronologically\n",
    "        time_point_size = len(data) // num_time_points\n",
    "        results = []\n",
    "\n",
    "        for i in range(num_time_points):\n",
    "            start_idx = i * time_point_size\n",
    "            end_idx = (i + 1) * time_point_size\n",
    "            X_train, X_test, y_train, y_test = train_test_split(data[start_idx:end_idx], labels[start_idx:end_idx], test_size=0.2, random_state=42)\n",
    "\n",
    "            model = model_fn(dataset['input_shape'], dataset['num_classes'], filters)\n",
    "            history = train_model(model, X_train, y_train, X_test, y_test)\n",
    "            test_results, _ = evaluate_model(model, X_test, y_test, dataset['num_classes'])\n",
    "            results.append(test_results)\n",
    "\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in longitudinal_analysis: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def time_efficiency_analysis(dataset, model_fn, filters):\n",
    "    try:\n",
    "        data = np.load(dataset['data'])\n",
    "        labels = np.load(dataset['labels'])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "        model = model_fn(dataset['input_shape'], dataset['num_classes'], filters)\n",
    "\n",
    "        start_time = time.time()\n",
    "        history = train_model(model, X_train, y_train, X_test, y_test)\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        start_time = time.time()\n",
    "        _ = model.predict(X_test)\n",
    "        inference_time = (time.time() - start_time) / len(X_test)\n",
    "\n",
    "        return {\"training_time\": float(training_time), \"inference_time\": float(inference_time)}\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in time_efficiency_analysis: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "def cross_dataset_validation(train_dataset, test_dataset, model_fn, filters):\n",
    "    try:\n",
    "        train_data = np.load(train_dataset['data'])\n",
    "        train_labels = np.load(train_dataset['labels'])\n",
    "        test_data = np.load(test_dataset['data'])\n",
    "        test_labels = np.load(test_dataset['labels'])\n",
    "\n",
    "        # Ensure compatible shapes\n",
    "        if train_data.shape[1:] != test_data.shape[1:]:\n",
    "            test_data = resample(test_data, train_data.shape[1], axis=1)\n",
    "\n",
    "        model = model_fn(train_dataset['input_shape'], train_dataset['num_classes'], filters)\n",
    "        history = train_model(model, train_data, train_labels, test_data, test_labels)\n",
    "        test_results, _ = evaluate_model(model, test_data, test_labels, test_dataset['num_classes'])\n",
    "\n",
    "        return test_results\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in cross_dataset_validation: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "def add_powerline_interference(data, frequency=50, amplitude=0.1):\n",
    "    t = np.arange(data.shape[1]) / 1000  # Assume 1000 Hz sampling rate\n",
    "    noise = amplitude * np.sin(2 * np.pi * frequency * t)\n",
    "    return data + noise.reshape(1, -1, 1)\n",
    "\n",
    "def add_electrode_motion_artifact(data, artifact_duration=100, amplitude=0.5):\n",
    "    artifact = np.zeros(data.shape)\n",
    "    for i in range(data.shape[0]):\n",
    "        start = np.random.randint(0, data.shape[1] - artifact_duration)\n",
    "        artifact[i, start:start+artifact_duration, :] = amplitude * np.random.randn(artifact_duration, data.shape[2])\n",
    "    return data + artifact\n",
    "\n",
    "def robustness_testing(dataset, model_fn, filters):\n",
    "    try:\n",
    "        data = np.load(dataset['data'])\n",
    "        labels = np.load(dataset['labels'])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "        model = model_fn(dataset['input_shape'], dataset['num_classes'], filters)\n",
    "        history = train_model(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        # Test on clean data\n",
    "        clean_results, _ = evaluate_model(model, X_test, y_test, dataset['num_classes'])\n",
    "        results['clean'] = clean_results\n",
    "\n",
    "        # Test with Gaussian noise\n",
    "        noisy_data = add_gaussian_noise(X_test)\n",
    "        noise_results, _ = evaluate_model(model, noisy_data, y_test, dataset['num_classes'])\n",
    "        results['gaussian_noise'] = noise_results\n",
    "\n",
    "        # Test with powerline interference\n",
    "        powerline_data = add_powerline_interference(X_test)\n",
    "        powerline_results, _ = evaluate_model(model, powerline_data, y_test, dataset['num_classes'])\n",
    "        results['powerline_interference'] = powerline_results\n",
    "\n",
    "        # Test with electrode motion artifact\n",
    "        motion_data = add_electrode_motion_artifact(X_test)\n",
    "        motion_results, _ = evaluate_model(model, motion_data, y_test, dataset['num_classes'])\n",
    "        results['electrode_motion'] = motion_results\n",
    "\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in robustness_testing: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "def add_random_baseline_wander(data, max_amplitude=0.1):\n",
    "    t = np.linspace(0, 1, data.shape[1])\n",
    "    baseline = max_amplitude * np.sin(2 * np.pi * np.random.rand() * t)\n",
    "    return data + baseline.reshape(1, -1, 1)\n",
    "\n",
    "def time_warp(data, sigma=0.2, knot=4):\n",
    "    orig_steps = np.arange(data.shape[1])\n",
    "    warp_steps = np.linspace(0, data.shape[1]-1, num=knot+2)\n",
    "    warper = np.zeros_like(data)\n",
    "    \n",
    "    for i in range(data.shape[0]):  # iterate over samples\n",
    "        for j in range(data.shape[2]):  # iterate over channels\n",
    "            random_warps = np.random.normal(loc=1.0, scale=sigma, size=(knot+2,))\n",
    "            warper[i, :, j] = np.interp(orig_steps, warp_steps, random_warps)\n",
    "    \n",
    "    return data * warper\n",
    "\n",
    "def apply_augmentations(data, labels):\n",
    "    augmented_data = []\n",
    "    augmented_labels = []\n",
    "\n",
    "    # Original data\n",
    "    augmented_data.append(data)\n",
    "    augmented_labels.append(labels)\n",
    "\n",
    "    # Gaussian noise\n",
    "    augmented_data.append(add_gaussian_noise(data))\n",
    "    augmented_labels.append(labels)\n",
    "\n",
    "    # Baseline wander\n",
    "    augmented_data.append(add_random_baseline_wander(data))\n",
    "    augmented_labels.append(labels)\n",
    "\n",
    "    # Time warping\n",
    "    augmented_data.append(time_warp(data))\n",
    "    augmented_labels.append(labels)\n",
    "\n",
    "    return np.concatenate(augmented_data, axis=0), np.concatenate(augmented_labels, axis=0)\n",
    "\n",
    "def simulate_hardware_issues(data, corruption_rate=0.1):\n",
    "    corrupted_data = data.copy()\n",
    "    mask = np.random.choice([0, 1], size=data.shape, p=[1-corruption_rate, corruption_rate])\n",
    "    corrupted_data[mask.astype(bool)] = np.random.normal(loc=0, scale=1, size=corrupted_data[mask.astype(bool)].shape)\n",
    "    return corrupted_data\n",
    "\n",
    "def run_experiment(dataset, model_fn, filters, experiment_type, use_augmentation=False, single_electrode=None, pretrain_dataset=None):\n",
    "    try:\n",
    "        data = np.load(dataset['data'])\n",
    "        labels = np.load(dataset['labels'])\n",
    "\n",
    "        # Truncate data to (5000, 12) if it's larger\n",
    "        if data.shape[1] > 5000:\n",
    "            data = data[:, :5000, :]\n",
    "            logging.info(f\"Truncated {dataset['name']} data to shape {data.shape}\")\n",
    "\n",
    "        if single_electrode is not None:\n",
    "            data = data[:, :, single_electrode:single_electrode+1]\n",
    "            input_shape = (5000, 1)\n",
    "            experiment_type = f\"single_electrode_{single_electrode}\"\n",
    "            train_condition = \"original\"\n",
    "        elif use_augmentation:\n",
    "            train_condition = \"aug_combined\"\n",
    "        elif pretrain_dataset is not None:\n",
    "            train_condition = f\"pretrained_{pretrain_dataset['name']}\"\n",
    "        else:\n",
    "            train_condition = \"original\"\n",
    "        \n",
    "        input_shape = (5000, 12) if single_electrode is None else input_shape\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "        if use_augmentation:\n",
    "            X_train, y_train = apply_augmentations(X_train, y_train)\n",
    "\n",
    "        if pretrain_dataset is not None:\n",
    "            pretrain_data = np.load(pretrain_dataset['data'])\n",
    "            pretrain_labels = np.load(pretrain_dataset['labels'])\n",
    "            if pretrain_data.shape[1] > 5000:\n",
    "                pretrain_data = pretrain_data[:, :5000, :]\n",
    "            pretrain_model = model_fn(input_shape, pretrain_dataset['num_classes'], filters)\n",
    "            \n",
    "            pretrain_model.fit(pretrain_data, pretrain_labels, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "            \n",
    "            # Evaluate pretrained model\n",
    "            pretrain_results, pretrain_cm = evaluate_model(pretrain_model, pretrain_data, pretrain_labels, pretrain_dataset['num_classes'])\n",
    "            save_results(pretrain_results, pretrain_dataset['name'], \"pretrain\", \"original\", \"clean\")\n",
    "            save_confusion_matrix(pretrain_cm, pretrain_dataset['name'], \"pretrain_original_clean\")\n",
    "            \n",
    "            # Transfer learned weights to the new model\n",
    "            model = model_fn(input_shape, dataset['num_classes'], filters)\n",
    "            for i, layer in enumerate(pretrain_model.layers[:-1]):  # Exclude the last layer\n",
    "                model.layers[i].set_weights(layer.get_weights())\n",
    "        else:\n",
    "            model = model_fn(input_shape, dataset['num_classes'], filters)\n",
    "\n",
    "        history = train_model(model, X_train, y_train, X_val, y_val)\n",
    "\n",
    "        # Evaluate on normal test set\n",
    "        normal_results, normal_cm = evaluate_model(model, X_test, y_test, dataset['num_classes'])\n",
    "        save_results(normal_results, dataset['name'], experiment_type, train_condition, \"clean\")\n",
    "        save_confusion_matrix(normal_cm, dataset['name'], f\"{experiment_type}_train_{train_condition}_test_clean\")\n",
    "\n",
    "        # Evaluate on corrupted test set\n",
    "        X_test_corrupted = simulate_hardware_issues(X_test)\n",
    "        corrupted_results, corrupted_cm = evaluate_model(model, X_test_corrupted, y_test, dataset['num_classes'])\n",
    "        save_results(corrupted_results, dataset['name'], experiment_type, train_condition, \"hw_corrupted\")\n",
    "        save_confusion_matrix(corrupted_cm, dataset['name'], f\"{experiment_type}_train_{train_condition}_test_hw_corrupted\")\n",
    "\n",
    "        # Ensure all required metrics are present\n",
    "        for metric in ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'sensitivity_unweighted', 'specificity_unweighted']:\n",
    "            if metric not in normal_results:\n",
    "                normal_results[metric] = None\n",
    "                logging.warning(f\"Metric {metric} not found in normal results for {dataset['name']} {experiment_type}\")\n",
    "            if metric not in corrupted_results:\n",
    "                corrupted_results[metric] = None\n",
    "                logging.warning(f\"Metric {metric} not found in corrupted results for {dataset['name']} {experiment_type}\")\n",
    "\n",
    "        return {\"normal\": normal_results, \"corrupted\": corrupted_results}\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in run_experiment for {dataset['name']} {experiment_type}: {str(e)}\")\n",
    "        return {\"normal\": {}, \"corrupted\": {}}\n",
    "\n",
    "def main():\n",
    "    results_dict = {}\n",
    "    for dataset in datasets:\n",
    "        results_dict[dataset['name']] = {}\n",
    "        for filters in filter_combinations:\n",
    "            logging.info(f\"Processing dataset: {dataset['name']} with filters: {filters}\")\n",
    "\n",
    "            try:\n",
    "                # Base experiment\n",
    "                base_results, _ = run_experiment(dataset, create_SERN_AwGOP, filters, \"base\")\n",
    "                results_dict[dataset['name']][\"base\"] = base_results\n",
    "\n",
    "                # Augmented data experiment\n",
    "                aug_results, _ = run_experiment(dataset, create_SERN_AwGOP, filters, \"augmented\", use_augmentation=True)\n",
    "                results_dict[dataset['name']][\"augmented\"] = aug_results\n",
    "\n",
    "                # Single electrode experiments\n",
    "                for i in range(12):\n",
    "                    single_results, _ = run_experiment(dataset, create_SERN_AwGOP, filters, f\"single_electrode_{i}\", single_electrode=i)\n",
    "                    results_dict[dataset['name']][f\"single_electrode_{i}\"] = single_results\n",
    "\n",
    "                # Pretrained model experiments\n",
    "                for pretrain_dataset in datasets:\n",
    "                    if pretrain_dataset['name'] != dataset['name']:\n",
    "                        pretrain_results, _ = run_experiment(dataset, create_SERN_AwGOP, filters, f\"pretrained_{pretrain_dataset['name']}\", pretrain_dataset=pretrain_dataset)\n",
    "                        results_dict[dataset['name']][f\"pretrained_{pretrain_dataset['name']}\"] = pretrain_results\n",
    "\n",
    "                # 2. Data Efficiency Analysis\n",
    "                efficiency_results = data_efficiency_analysis(dataset, create_SERN_AwGOP, filters)\n",
    "                results_dict[dataset['name']]['data_efficiency'] = efficiency_results\n",
    "\n",
    "                # 3. Longitudinal Analysis\n",
    "                longitudinal_results = longitudinal_analysis(dataset, create_SERN_AwGOP, filters)\n",
    "                results_dict[dataset['name']]['longitudinal'] = longitudinal_results\n",
    "\n",
    "                # 4. Time Efficiency Analysis\n",
    "                time_results = time_efficiency_analysis(dataset, create_SERN_AwGOP, filters)\n",
    "                results_dict[dataset['name']]['time_efficiency'] = time_results\n",
    "\n",
    "                # 5. Cross-dataset Validation\n",
    "                for test_dataset in datasets:\n",
    "                    if test_dataset['name'] != dataset['name']:\n",
    "                        cross_results = cross_dataset_validation(dataset, test_dataset, create_SERN_AwGOP, filters)\n",
    "                        results_dict[dataset['name']][f'cross_validation_{test_dataset[\"name\"]}'] = cross_results\n",
    "\n",
    "                # 6. Robustness Testing\n",
    "                robustness_results = robustness_testing(dataset, create_SERN_AwGOP, filters)\n",
    "                results_dict[dataset['name']]['robustness'] = robustness_results\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing {dataset['name']}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "            # Save results after each dataset\n",
    "            save_results(results_dict[dataset['name']], dataset['name'], \"all_experiments\", \"various\", \"various\")\n",
    "\n",
    "    logging.info(\"All experiments and analyses completed successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 01:06:25.057510: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-25 01:06:30,206 - INFO - Processing dataset: CUSPH-SR-AF with filters: [32, 64, 128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 67s 5s/step - loss: 0.5186 - accuracy: 0.7118 - val_loss: 0.6754 - val_accuracy: 0.4993\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 32s 4s/step - loss: 0.2931 - accuracy: 0.8681 - val_loss: 0.6538 - val_accuracy: 0.7004\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 30s 3s/step - loss: 0.1899 - accuracy: 0.9097 - val_loss: 0.6417 - val_accuracy: 0.7545\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 34s 4s/step - loss: 0.0925 - accuracy: 0.9618 - val_loss: 0.6200 - val_accuracy: 0.7226\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 39s 5s/step - loss: 0.0650 - accuracy: 0.9792 - val_loss: 0.6208 - val_accuracy: 0.5742\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0752 - accuracy: 0.9688 - val_loss: 0.6429 - val_accuracy: 0.5187\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0832 - accuracy: 0.9618 - val_loss: 0.6449 - val_accuracy: 0.5201\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0350 - accuracy: 0.9861 - val_loss: 0.6492 - val_accuracy: 0.5146\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 33s 4s/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.6826 - val_accuracy: 0.4910\n",
      "23/23 [==============================] - 12s 461ms/step\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 107s 4s/step - loss: 0.4940 - accuracy: 0.7684 - val_loss: 0.7059 - val_accuracy: 0.4854\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 86s 4s/step - loss: 0.2826 - accuracy: 0.8752 - val_loss: 0.6066 - val_accuracy: 0.7809\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 85s 4s/step - loss: 0.1210 - accuracy: 0.9626 - val_loss: 0.5640 - val_accuracy: 0.8377\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 78s 3s/step - loss: 0.0905 - accuracy: 0.9639 - val_loss: 0.5699 - val_accuracy: 0.7712\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 85s 4s/step - loss: 0.0468 - accuracy: 0.9861 - val_loss: 0.5386 - val_accuracy: 0.8821\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 78s 3s/step - loss: 0.0283 - accuracy: 0.9945 - val_loss: 0.4798 - val_accuracy: 0.9140\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 90s 4s/step - loss: 0.0213 - accuracy: 0.9958 - val_loss: 0.4534 - val_accuracy: 0.9348\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 80s 3s/step - loss: 0.0280 - accuracy: 0.9889 - val_loss: 0.4797 - val_accuracy: 0.7531\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 83s 4s/step - loss: 0.0331 - accuracy: 0.9875 - val_loss: 0.5075 - val_accuracy: 0.7268\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 78s 3s/step - loss: 0.0111 - accuracy: 0.9958 - val_loss: 0.4289 - val_accuracy: 0.8988\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 84s 4s/step - loss: 0.0157 - accuracy: 0.9931 - val_loss: 0.4946 - val_accuracy: 0.7822\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 83s 4s/step - loss: 0.0119 - accuracy: 0.9972 - val_loss: 0.4049 - val_accuracy: 0.9320\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 81s 4s/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.3734 - val_accuracy: 0.9404\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 76s 3s/step - loss: 0.0206 - accuracy: 0.9972 - val_loss: 0.5425 - val_accuracy: 0.7517\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 80s 4s/step - loss: 0.0102 - accuracy: 0.9986 - val_loss: 0.1540 - val_accuracy: 0.9626\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 80s 3s/step - loss: 0.0451 - accuracy: 0.9806 - val_loss: 0.6476 - val_accuracy: 0.7046\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 80s 4s/step - loss: 0.0495 - accuracy: 0.9875 - val_loss: 0.4248 - val_accuracy: 0.7864\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 81s 4s/step - loss: 0.0119 - accuracy: 0.9972 - val_loss: 0.1814 - val_accuracy: 0.9307\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 76s 3s/step - loss: 0.0106 - accuracy: 0.9972 - val_loss: 0.0824 - val_accuracy: 0.9778\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 76s 3s/step - loss: 0.0058 - accuracy: 0.9972 - val_loss: 0.0758 - val_accuracy: 0.9750\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 78s 3s/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0594 - val_accuracy: 0.9820\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 76s 3s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0792 - val_accuracy: 0.9736\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 76s 3s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9875\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 77s 3s/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9861\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 77s 3s/step - loss: 7.3415e-04 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9889\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 82s 4s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9903\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 77s 3s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9931\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 80s 4s/step - loss: 4.9827e-04 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9917\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 78s 3s/step - loss: 3.0975e-04 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9917\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 76s 3s/step - loss: 5.5334e-04 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 0.9903\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 79s 3s/step - loss: 3.6221e-04 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9903\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 76s 3s/step - loss: 5.1139e-04 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9903\n",
      "23/23 [==============================] - 13s 469ms/step\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 173s 3s/step - loss: 0.3472 - accuracy: 0.8412 - val_loss: 0.6299 - val_accuracy: 0.6130\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 153s 3s/step - loss: 0.0966 - accuracy: 0.9709 - val_loss: 0.4707 - val_accuracy: 0.9196\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 150s 3s/step - loss: 0.0587 - accuracy: 0.9840 - val_loss: 0.4898 - val_accuracy: 0.7698\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 147s 3s/step - loss: 0.0380 - accuracy: 0.9896 - val_loss: 0.4092 - val_accuracy: 0.9237\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 145s 3s/step - loss: 0.0236 - accuracy: 0.9938 - val_loss: 0.4813 - val_accuracy: 0.7531\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 144s 3s/step - loss: 0.0606 - accuracy: 0.9806 - val_loss: 0.3425 - val_accuracy: 0.8669\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 140s 3s/step - loss: 0.0222 - accuracy: 0.9945 - val_loss: 0.1263 - val_accuracy: 0.9695\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 145s 3s/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 0.2022 - val_accuracy: 0.9348\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 161s 4s/step - loss: 0.0601 - accuracy: 0.9813 - val_loss: 3.8363 - val_accuracy: 0.5076\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 160s 3s/step - loss: 0.0282 - accuracy: 0.9924 - val_loss: 0.0553 - val_accuracy: 0.9847\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 148s 3s/step - loss: 0.0785 - accuracy: 0.9723 - val_loss: 1.6393 - val_accuracy: 0.6006\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 144s 3s/step - loss: 0.0472 - accuracy: 0.9840 - val_loss: 0.0841 - val_accuracy: 0.9875\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 138s 3s/step - loss: 0.0687 - accuracy: 0.9778 - val_loss: 0.0559 - val_accuracy: 0.9875\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 149s 3s/step - loss: 0.0188 - accuracy: 0.9965 - val_loss: 0.0375 - val_accuracy: 0.9861\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 173s 4s/step - loss: 0.0103 - accuracy: 0.9979 - val_loss: 0.0478 - val_accuracy: 0.9847\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 152s 3s/step - loss: 0.0084 - accuracy: 0.9993 - val_loss: 0.0435 - val_accuracy: 0.9889\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 144s 3s/step - loss: 0.0398 - accuracy: 0.9889 - val_loss: 0.0580 - val_accuracy: 0.9917\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 142s 3s/step - loss: 0.0102 - accuracy: 0.9986 - val_loss: 0.0597 - val_accuracy: 0.9917\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 141s 3s/step - loss: 0.0057 - accuracy: 0.9993 - val_loss: 0.0650 - val_accuracy: 0.9917\n",
      "23/23 [==============================] - 13s 484ms/step\n",
      "Epoch 1/100\n",
      "68/68 [==============================] - 239s 3s/step - loss: 0.2385 - accuracy: 0.9015 - val_loss: 0.5942 - val_accuracy: 0.7143\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 217s 3s/step - loss: 0.0659 - accuracy: 0.9834 - val_loss: 0.4967 - val_accuracy: 0.9015\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 208s 3s/step - loss: 0.0370 - accuracy: 0.9884 - val_loss: 0.4164 - val_accuracy: 0.9404\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - 210s 3s/step - loss: 0.0274 - accuracy: 0.9926 - val_loss: 0.3860 - val_accuracy: 0.8724\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - 211s 3s/step - loss: 0.0181 - accuracy: 0.9949 - val_loss: 0.0994 - val_accuracy: 0.9875\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - 198s 3s/step - loss: 0.0214 - accuracy: 0.9931 - val_loss: 0.1364 - val_accuracy: 0.9390\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 208s 3s/step - loss: 0.0271 - accuracy: 0.9926 - val_loss: 0.0512 - val_accuracy: 0.9834\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - 209s 3s/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.0255 - val_accuracy: 0.9931\n",
      "Epoch 9/100\n",
      "68/68 [==============================] - 205s 3s/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 0.0337 - val_accuracy: 0.9931\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 210s 3s/step - loss: 0.0115 - accuracy: 0.9954 - val_loss: 0.3021 - val_accuracy: 0.8932\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 206s 3s/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.2096 - val_accuracy: 0.9182\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - 201s 3s/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.0283 - val_accuracy: 0.9945\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - 233s 3s/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0713 - val_accuracy: 0.9875\n",
      "23/23 [==============================] - 13s 475ms/step\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 278s 3s/step - loss: 0.2580 - accuracy: 0.8918 - val_loss: 0.5553 - val_accuracy: 0.6519\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 214s 2s/step - loss: 0.0801 - accuracy: 0.9771 - val_loss: 0.5223 - val_accuracy: 0.7670\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 209s 2s/step - loss: 0.0428 - accuracy: 0.9903 - val_loss: 0.3432 - val_accuracy: 0.9598\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 210s 2s/step - loss: 0.0386 - accuracy: 0.9882 - val_loss: 0.1773 - val_accuracy: 0.9709\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 209s 2s/step - loss: 0.0494 - accuracy: 0.9879 - val_loss: 0.2919 - val_accuracy: 0.8571\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 210s 2s/step - loss: 0.0351 - accuracy: 0.9896 - val_loss: 0.0437 - val_accuracy: 0.9903\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 210s 2s/step - loss: 0.0450 - accuracy: 0.9847 - val_loss: 0.0202 - val_accuracy: 0.9958\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 209s 2s/step - loss: 0.0202 - accuracy: 0.9948 - val_loss: 0.0457 - val_accuracy: 0.9889\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 211s 2s/step - loss: 0.0141 - accuracy: 0.9962 - val_loss: 0.0292 - val_accuracy: 0.9931\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 211s 2s/step - loss: 0.0559 - accuracy: 0.9813 - val_loss: 0.0292 - val_accuracy: 0.9945\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 211s 2s/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 0.0297 - val_accuracy: 0.9972\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 212s 2s/step - loss: 0.0442 - accuracy: 0.9875 - val_loss: 0.0438 - val_accuracy: 0.9945\n",
      "23/23 [==============================] - 10s 392ms/step\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 57s 2s/step - loss: 0.4951 - accuracy: 0.7396 - val_loss: 0.6824 - val_accuracy: 0.4690\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.2793 - accuracy: 0.8941 - val_loss: 0.7091 - val_accuracy: 0.4621\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.1571 - accuracy: 0.9444 - val_loss: 0.8515 - val_accuracy: 0.4621\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0999 - accuracy: 0.9670 - val_loss: 0.5928 - val_accuracy: 0.5862\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0773 - accuracy: 0.9740 - val_loss: 0.5447 - val_accuracy: 0.6828\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 40s 2s/step - loss: 0.0399 - accuracy: 0.9896 - val_loss: 0.4666 - val_accuracy: 0.8690\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0242 - accuracy: 0.9965 - val_loss: 0.5139 - val_accuracy: 0.7793\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 40s 2s/step - loss: 0.0158 - accuracy: 0.9983 - val_loss: 0.5115 - val_accuracy: 0.7793\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 40s 2s/step - loss: 0.0092 - accuracy: 0.9983 - val_loss: 0.4566 - val_accuracy: 0.9172\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.4465 - val_accuracy: 0.9172\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4301 - val_accuracy: 0.9034\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4195 - val_accuracy: 0.9241\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4001 - val_accuracy: 0.9172\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3810 - val_accuracy: 0.9103\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 7.7492e-04 - accuracy: 1.0000 - val_loss: 0.3383 - val_accuracy: 0.9310\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 9.8139e-04 - accuracy: 1.0000 - val_loss: 0.3057 - val_accuracy: 0.9310\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 8.4159e-04 - accuracy: 1.0000 - val_loss: 0.2972 - val_accuracy: 0.9172\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 4.9398e-04 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9379\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 3.2244e-04 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9586\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 2.8605e-04 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9586\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 4.0463e-04 - accuracy: 1.0000 - val_loss: 0.1548 - val_accuracy: 0.9586\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 3.5209e-04 - accuracy: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9586\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9655\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 1.9553e-04 - accuracy: 1.0000 - val_loss: 0.1154 - val_accuracy: 0.9655\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 2.7456e-04 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9724\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 0.9724\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 1.5059e-04 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9724\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 40s 2s/step - loss: 2.6806e-04 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 0.9724\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0160 - accuracy: 0.9983 - val_loss: 0.1205 - val_accuracy: 0.9724\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0295 - accuracy: 0.9896 - val_loss: 0.3804 - val_accuracy: 0.9448\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0658 - accuracy: 0.9878 - val_loss: 37.1795 - val_accuracy: 0.5379\n",
      "5/5 [==============================] - 3s 368ms/step\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 57s 2s/step - loss: 0.5158 - accuracy: 0.7448 - val_loss: 0.6585 - val_accuracy: 0.5586\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.2145 - accuracy: 0.9340 - val_loss: 0.6267 - val_accuracy: 0.7931\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0782 - accuracy: 0.9792 - val_loss: 0.5939 - val_accuracy: 0.5862\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0445 - accuracy: 0.9913 - val_loss: 0.5884 - val_accuracy: 0.8414\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0294 - accuracy: 0.9913 - val_loss: 0.5644 - val_accuracy: 0.7931\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0293 - accuracy: 0.9931 - val_loss: 0.5792 - val_accuracy: 0.7586\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0195 - accuracy: 0.9965 - val_loss: 0.5736 - val_accuracy: 0.8207\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.5581 - val_accuracy: 0.7517\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5518 - val_accuracy: 0.7448\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5566 - val_accuracy: 0.7034\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5426 - val_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5218 - val_accuracy: 0.8552\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 7.9776e-04 - accuracy: 1.0000 - val_loss: 0.4985 - val_accuracy: 0.8897\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4713 - val_accuracy: 0.8966\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 4.5827e-04 - accuracy: 1.0000 - val_loss: 0.4434 - val_accuracy: 0.9103\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4329 - val_accuracy: 0.9172\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0263 - accuracy: 0.9931 - val_loss: 0.4046 - val_accuracy: 0.7379\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0201 - accuracy: 0.9896 - val_loss: 0.3512 - val_accuracy: 0.8414\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0192 - accuracy: 0.9948 - val_loss: 0.2321 - val_accuracy: 0.9103\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.1874 - val_accuracy: 0.9241\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9517\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 0.9655\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9724\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0830 - val_accuracy: 0.9931\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 6.5964e-04 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9793\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 5.2638e-04 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9793\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 5.9573e-04 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 0.9793\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 3.0841e-04 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 0.9793\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 3.1574e-04 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9793\n",
      "5/5 [==============================] - 3s 340ms/step\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 57s 2s/step - loss: 0.5273 - accuracy: 0.7500 - val_loss: 0.6712 - val_accuracy: 0.5172\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.2992 - accuracy: 0.8681 - val_loss: 0.6424 - val_accuracy: 0.6138\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.1843 - accuracy: 0.9288 - val_loss: 0.5611 - val_accuracy: 0.8414\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0952 - accuracy: 0.9740 - val_loss: 0.5494 - val_accuracy: 0.8207\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0623 - accuracy: 0.9774 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0877 - accuracy: 0.9740 - val_loss: 0.5853 - val_accuracy: 0.7448\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0374 - accuracy: 0.9878 - val_loss: 0.5212 - val_accuracy: 0.9310\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0237 - accuracy: 0.9948 - val_loss: 0.5178 - val_accuracy: 0.8552\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0253 - accuracy: 0.9931 - val_loss: 0.5123 - val_accuracy: 0.8621\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0109 - accuracy: 0.9983 - val_loss: 0.5189 - val_accuracy: 0.8276\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.5037 - val_accuracy: 0.8621\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4727 - val_accuracy: 0.8828\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.8897\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.4119 - val_accuracy: 0.9103\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0036 - accuracy: 0.9983 - val_loss: 0.3516 - val_accuracy: 0.9586\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.3724 - val_accuracy: 0.9172\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2760 - val_accuracy: 0.9655\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2472 - val_accuracy: 0.9724\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 6.3734e-04 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9034\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 6.7295e-04 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9310\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 5.8506e-04 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9379\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 3.8500e-04 - accuracy: 1.0000 - val_loss: 0.1738 - val_accuracy: 0.9655\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 4.7180e-04 - accuracy: 1.0000 - val_loss: 0.1486 - val_accuracy: 0.9724\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 3.5491e-04 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9724\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 5.1997e-04 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9724\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 4.2488e-04 - accuracy: 1.0000 - val_loss: 0.0813 - val_accuracy: 0.9724\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 4.0162e-04 - accuracy: 1.0000 - val_loss: 0.0642 - val_accuracy: 0.9793\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 2.0533e-04 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 0.9793\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 3.9837e-04 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 0.9793\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 2.0305e-04 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9862\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 2.2719e-04 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9931\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 2.2233e-04 - accuracy: 1.0000 - val_loss: 0.0364 - val_accuracy: 0.9931\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 1.0765e-04 - accuracy: 1.0000 - val_loss: 0.0364 - val_accuracy: 0.9931\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 5.5075e-04 - accuracy: 1.0000 - val_loss: 0.0652 - val_accuracy: 0.9793\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 3.9652e-04 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 0.9793\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 5.4905e-04 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 0.9931\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 2.0159e-04 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 0.9931\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 2.6903e-04 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9931\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 8.7331e-05 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.9931\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 1.0084e-04 - accuracy: 1.0000 - val_loss: 0.0323 - val_accuracy: 0.9931\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 8.6226e-05 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9931\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 4.7885e-05 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.9931\n",
      "5/5 [==============================] - 3s 345ms/step\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 58s 2s/step - loss: 0.5274 - accuracy: 0.7274 - val_loss: 0.6630 - val_accuracy: 0.5655\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.2623 - accuracy: 0.8872 - val_loss: 0.6084 - val_accuracy: 0.7034\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.1531 - accuracy: 0.9410 - val_loss: 0.5629 - val_accuracy: 0.6828\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0881 - accuracy: 0.9774 - val_loss: 0.4764 - val_accuracy: 0.8276\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0464 - accuracy: 0.9878 - val_loss: 0.6187 - val_accuracy: 0.5586\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0259 - accuracy: 0.9983 - val_loss: 0.5154 - val_accuracy: 0.7793\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0213 - accuracy: 0.9948 - val_loss: 0.4984 - val_accuracy: 0.7310\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 43s 2s/step - loss: 0.0511 - accuracy: 0.9809 - val_loss: 0.5131 - val_accuracy: 0.6966\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0490 - accuracy: 0.9826 - val_loss: 0.4729 - val_accuracy: 0.7586\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0476 - accuracy: 0.9826 - val_loss: 0.4450 - val_accuracy: 0.7034\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0135 - accuracy: 0.9983 - val_loss: 0.5210 - val_accuracy: 0.6138\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 0.4898 - val_accuracy: 0.6828\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 0.3553 - val_accuracy: 0.8345\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0092 - accuracy: 0.9983 - val_loss: 0.7482 - val_accuracy: 0.5379\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.8577 - val_accuracy: 0.5379\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7229 - val_accuracy: 0.5793\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6909 - val_accuracy: 0.6138\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 9.3129e-04 - accuracy: 1.0000 - val_loss: 0.6456 - val_accuracy: 0.6483\n",
      "5/5 [==============================] - 3s 356ms/step\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 57s 2s/step - loss: 0.5023 - accuracy: 0.7535 - val_loss: 0.6333 - val_accuracy: 0.7862\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.3035 - accuracy: 0.8837 - val_loss: 0.6176 - val_accuracy: 0.7241\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 43s 2s/step - loss: 0.1416 - accuracy: 0.9514 - val_loss: 0.6441 - val_accuracy: 0.4897\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0673 - accuracy: 0.9774 - val_loss: 0.5531 - val_accuracy: 0.7241\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0428 - accuracy: 0.9896 - val_loss: 0.5162 - val_accuracy: 0.8552\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 41s 2s/step - loss: 0.0332 - accuracy: 0.9931 - val_loss: 0.6056 - val_accuracy: 0.6138\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0441 - accuracy: 0.9861 - val_loss: 0.7118 - val_accuracy: 0.4276\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0339 - accuracy: 0.9878 - val_loss: 0.4236 - val_accuracy: 0.9586\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0197 - accuracy: 0.9948 - val_loss: 0.4572 - val_accuracy: 0.7310\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.3509 - val_accuracy: 0.9172\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0085 - accuracy: 0.9983 - val_loss: 0.3992 - val_accuracy: 0.8759\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.3894 - val_accuracy: 0.8966\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.8897\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.3822 - val_accuracy: 0.8345\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 42s 2s/step - loss: 0.0186 - accuracy: 0.9948 - val_loss: 0.6113 - val_accuracy: 0.6414\n",
      "5/5 [==============================] - 4s 349ms/step\n",
      "Epoch 1/100\n",
      "91/91 [==============================] - 229s 2s/step - loss: 0.2369 - accuracy: 0.9001 - val_loss: 0.5645 - val_accuracy: 0.6019\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 219s 2s/step - loss: 0.0626 - accuracy: 0.9827 - val_loss: 0.4586 - val_accuracy: 0.9681\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 210s 2s/step - loss: 0.0403 - accuracy: 0.9910 - val_loss: 0.3507 - val_accuracy: 0.9653\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 210s 2s/step - loss: 0.0290 - accuracy: 0.9899 - val_loss: 0.1637 - val_accuracy: 0.9792\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 209s 2s/step - loss: 0.0469 - accuracy: 0.9875 - val_loss: 0.1093 - val_accuracy: 0.9626\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 211s 2s/step - loss: 0.0339 - accuracy: 0.9903 - val_loss: 0.0393 - val_accuracy: 0.9917\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 209s 2s/step - loss: 0.0290 - accuracy: 0.9906 - val_loss: 0.1082 - val_accuracy: 0.9626\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 209s 2s/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0178 - val_accuracy: 0.9972\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 211s 2s/step - loss: 0.0092 - accuracy: 0.9965 - val_loss: 0.0156 - val_accuracy: 0.9972\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 210s 2s/step - loss: 0.0443 - accuracy: 0.9875 - val_loss: 0.0176 - val_accuracy: 0.9958\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 209s 2s/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 0.0326 - val_accuracy: 0.9917\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 209s 2s/step - loss: 0.0176 - accuracy: 0.9948 - val_loss: 0.0261 - val_accuracy: 0.9945\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 208s 2s/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.0116 - val_accuracy: 0.9986\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 211s 2s/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.0195 - val_accuracy: 0.9972\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 208s 2s/step - loss: 0.0452 - accuracy: 0.9851 - val_loss: 0.0526 - val_accuracy: 0.9917\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 209s 2s/step - loss: 0.0158 - accuracy: 0.9965 - val_loss: 0.0196 - val_accuracy: 0.9986\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 210s 2s/step - loss: 0.0064 - accuracy: 0.9972 - val_loss: 0.0191 - val_accuracy: 0.9986\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 209s 2s/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.0236 - val_accuracy: 0.9986\n",
      "23/23 [==============================] - 10s 386ms/step\n",
      "23/23 [==============================] - 9s 385ms/step\n",
      "23/23 [==============================] - 9s 405ms/step\n",
      "23/23 [==============================] - 10s 418ms/step\n",
      "Epoch 1/100\n",
      "113/113 [==============================] - 298s 3s/step - loss: 0.1997 - accuracy: 0.9257 - val_loss: 40.2738 - val_accuracy: 0.4554\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - 278s 2s/step - loss: 0.0470 - accuracy: 0.9859 - val_loss: 244.6888 - val_accuracy: 0.4554\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - 279s 2s/step - loss: 0.0348 - accuracy: 0.9895 - val_loss: 211.4927 - val_accuracy: 0.4554\n",
      "Epoch 4/100\n",
      "113/113 [==============================] - 281s 2s/step - loss: 0.0283 - accuracy: 0.9914 - val_loss: 195.7098 - val_accuracy: 0.3700\n",
      "Epoch 5/100\n",
      "113/113 [==============================] - 281s 2s/step - loss: 0.0268 - accuracy: 0.9914 - val_loss: 505.2855 - val_accuracy: 0.4554\n",
      "Epoch 6/100\n",
      "113/113 [==============================] - 280s 2s/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 279.4505 - val_accuracy: 0.4489\n",
      "63/63 [==============================] - 31s 471ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2024-08-25 07:21:30,300 - INFO - Processing dataset: CSPC18-SR-AF with filters: [32, 64, 128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 61s 8s/step - loss: 3.4248 - accuracy: 0.5901 - val_loss: 1.0645 - val_accuracy: 0.6163\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 44s 8s/step - loss: 1.1024 - accuracy: 0.6398 - val_loss: 1.1809 - val_accuracy: 0.5916\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 44s 8s/step - loss: 1.0097 - accuracy: 0.6584 - val_loss: 0.5785 - val_accuracy: 0.7475\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 45s 8s/step - loss: 0.5363 - accuracy: 0.7578 - val_loss: 1.7300 - val_accuracy: 0.5594\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 45s 8s/step - loss: 0.7644 - accuracy: 0.7019 - val_loss: 0.7434 - val_accuracy: 0.7129\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 44s 8s/step - loss: 0.3967 - accuracy: 0.8261 - val_loss: 0.5516 - val_accuracy: 0.7698\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 44s 8s/step - loss: 0.3657 - accuracy: 0.8571 - val_loss: 0.6861 - val_accuracy: 0.7624\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 45s 8s/step - loss: 0.3676 - accuracy: 0.8385 - val_loss: 0.7819 - val_accuracy: 0.7277\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 44s 8s/step - loss: 0.2767 - accuracy: 0.8882 - val_loss: 0.5524 - val_accuracy: 0.8243\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 44s 8s/step - loss: 0.2931 - accuracy: 0.9006 - val_loss: 0.5736 - val_accuracy: 0.8193\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 44s 8s/step - loss: 0.2540 - accuracy: 0.9130 - val_loss: 0.6281 - val_accuracy: 0.7921\n",
      "13/13 [==============================] - 16s 1s/step\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 105s 7s/step - loss: 2.9562 - accuracy: 0.5658 - val_loss: 1.0524 - val_accuracy: 0.6757\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 89s 7s/step - loss: 0.9370 - accuracy: 0.7072 - val_loss: 0.5767 - val_accuracy: 0.8020\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 89s 7s/step - loss: 0.4343 - accuracy: 0.8313 - val_loss: 0.6838 - val_accuracy: 0.7698\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 89s 7s/step - loss: 0.3259 - accuracy: 0.8983 - val_loss: 0.4700 - val_accuracy: 0.8317\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 89s 7s/step - loss: 0.2880 - accuracy: 0.8809 - val_loss: 0.5085 - val_accuracy: 0.8144\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 88s 7s/step - loss: 0.2624 - accuracy: 0.8958 - val_loss: 0.4568 - val_accuracy: 0.8515\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 90s 7s/step - loss: 0.2276 - accuracy: 0.9082 - val_loss: 0.4522 - val_accuracy: 0.8342\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 90s 7s/step - loss: 0.2229 - accuracy: 0.9107 - val_loss: 0.5205 - val_accuracy: 0.8317\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 89s 7s/step - loss: 0.2168 - accuracy: 0.9057 - val_loss: 0.4429 - val_accuracy: 0.8490\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 89s 7s/step - loss: 0.2167 - accuracy: 0.9057 - val_loss: 0.4954 - val_accuracy: 0.8366\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 89s 7s/step - loss: 0.2166 - accuracy: 0.9256 - val_loss: 0.4705 - val_accuracy: 0.8416\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 89s 7s/step - loss: 0.1873 - accuracy: 0.9256 - val_loss: 0.4759 - val_accuracy: 0.8515\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 89s 7s/step - loss: 0.1737 - accuracy: 0.9231 - val_loss: 0.5438 - val_accuracy: 0.8465\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 89s 7s/step - loss: 0.1650 - accuracy: 0.9330 - val_loss: 0.5167 - val_accuracy: 0.8564\n",
      "13/13 [==============================] - 15s 1s/step\n",
      "Epoch 1/100\n",
      "26/26 [==============================] - 181s 6s/step - loss: 0.7561 - accuracy: 0.7233 - val_loss: 0.6978 - val_accuracy: 0.7178\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 165s 6s/step - loss: 0.3493 - accuracy: 0.8685 - val_loss: 0.3637 - val_accuracy: 0.8639\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 164s 6s/step - loss: 0.2933 - accuracy: 0.8797 - val_loss: 0.3329 - val_accuracy: 0.8738\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 165s 6s/step - loss: 0.2708 - accuracy: 0.8834 - val_loss: 0.3528 - val_accuracy: 0.8688\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 164s 6s/step - loss: 0.2314 - accuracy: 0.9082 - val_loss: 0.4789 - val_accuracy: 0.8267\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 164s 6s/step - loss: 0.2420 - accuracy: 0.9082 - val_loss: 0.4819 - val_accuracy: 0.8589\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 166s 6s/step - loss: 0.2644 - accuracy: 0.8883 - val_loss: 0.2944 - val_accuracy: 0.8960\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 164s 6s/step - loss: 0.1982 - accuracy: 0.9231 - val_loss: 0.3348 - val_accuracy: 0.9035\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 166s 6s/step - loss: 0.1460 - accuracy: 0.9516 - val_loss: 0.4599 - val_accuracy: 0.8540\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 163s 6s/step - loss: 0.2443 - accuracy: 0.8983 - val_loss: 0.3536 - val_accuracy: 0.9109\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 164s 6s/step - loss: 0.1748 - accuracy: 0.9256 - val_loss: 0.4627 - val_accuracy: 0.8515\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 165s 6s/step - loss: 0.1320 - accuracy: 0.9541 - val_loss: 0.3077 - val_accuracy: 0.9183\n",
      "13/13 [==============================] - 16s 1s/step\n",
      "Epoch 1/100\n",
      "38/38 [==============================] - 255s 6s/step - loss: 1.1936 - accuracy: 0.7262 - val_loss: 0.6367 - val_accuracy: 0.7847\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 240s 6s/step - loss: 0.3449 - accuracy: 0.8519 - val_loss: 0.3673 - val_accuracy: 0.8738\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 240s 6s/step - loss: 0.3009 - accuracy: 0.8801 - val_loss: 0.4832 - val_accuracy: 0.8168\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 238s 6s/step - loss: 0.2634 - accuracy: 0.8925 - val_loss: 0.3481 - val_accuracy: 0.8911\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 238s 6s/step - loss: 0.2575 - accuracy: 0.8925 - val_loss: 0.3371 - val_accuracy: 0.8837\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 237s 6s/step - loss: 0.2320 - accuracy: 0.9098 - val_loss: 0.2858 - val_accuracy: 0.9158\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 241s 6s/step - loss: 0.2110 - accuracy: 0.9123 - val_loss: 0.5292 - val_accuracy: 0.8292\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 257s 7s/step - loss: 0.2539 - accuracy: 0.9032 - val_loss: 0.2713 - val_accuracy: 0.9257\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 257s 7s/step - loss: 0.2044 - accuracy: 0.9239 - val_loss: 0.3557 - val_accuracy: 0.8837\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 262s 7s/step - loss: 0.1866 - accuracy: 0.9338 - val_loss: 0.2962 - val_accuracy: 0.9134\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 263s 7s/step - loss: 0.1496 - accuracy: 0.9471 - val_loss: 0.3841 - val_accuracy: 0.8688\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 311s 8s/step - loss: 0.2489 - accuracy: 0.9057 - val_loss: 0.2664 - val_accuracy: 0.9208\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 249s 7s/step - loss: 0.1716 - accuracy: 0.9355 - val_loss: 0.2176 - val_accuracy: 0.9406\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 247s 7s/step - loss: 0.1324 - accuracy: 0.9545 - val_loss: 0.2417 - val_accuracy: 0.9208\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 244s 6s/step - loss: 0.1113 - accuracy: 0.9628 - val_loss: 0.2400 - val_accuracy: 0.9282\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 257s 7s/step - loss: 0.1107 - accuracy: 0.9686 - val_loss: 0.3203 - val_accuracy: 0.8911\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 270s 7s/step - loss: 0.0976 - accuracy: 0.9677 - val_loss: 0.2374 - val_accuracy: 0.9208\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 267s 7s/step - loss: 0.0824 - accuracy: 0.9777 - val_loss: 0.2409 - val_accuracy: 0.9505\n",
      "13/13 [==============================] - 19s 1s/step\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 402s 7s/step - loss: 0.6606 - accuracy: 0.7562 - val_loss: 0.4246 - val_accuracy: 0.8342\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 435s 8s/step - loss: 0.3511 - accuracy: 0.8586 - val_loss: 0.5618 - val_accuracy: 0.7871\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 421s 8s/step - loss: 0.3032 - accuracy: 0.8716 - val_loss: 0.3577 - val_accuracy: 0.8738\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 444s 9s/step - loss: 0.2644 - accuracy: 0.8933 - val_loss: 0.2669 - val_accuracy: 0.9134\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 377s 7s/step - loss: 0.2500 - accuracy: 0.8927 - val_loss: 0.2904 - val_accuracy: 0.9010\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 418s 8s/step - loss: 0.2273 - accuracy: 0.9069 - val_loss: 0.2498 - val_accuracy: 0.9183\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 358s 7s/step - loss: 0.1949 - accuracy: 0.9243 - val_loss: 0.2380 - val_accuracy: 0.9109\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 387s 8s/step - loss: 0.1694 - accuracy: 0.9411 - val_loss: 0.7084 - val_accuracy: 0.7673\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 414s 8s/step - loss: 0.1849 - accuracy: 0.9274 - val_loss: 0.2193 - val_accuracy: 0.9233\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 419s 8s/step - loss: 0.1387 - accuracy: 0.9504 - val_loss: 0.2067 - val_accuracy: 0.9332\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 415s 8s/step - loss: 0.1522 - accuracy: 0.9392 - val_loss: 0.2471 - val_accuracy: 0.8960\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 428s 8s/step - loss: 0.1531 - accuracy: 0.9448 - val_loss: 0.1588 - val_accuracy: 0.9381\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 400s 8s/step - loss: 0.1078 - accuracy: 0.9628 - val_loss: 0.1432 - val_accuracy: 0.9554\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 369s 7s/step - loss: 0.0786 - accuracy: 0.9758 - val_loss: 0.1689 - val_accuracy: 0.9455\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 350s 7s/step - loss: 0.0645 - accuracy: 0.9801 - val_loss: 0.1049 - val_accuracy: 0.9678\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 326s 6s/step - loss: 0.0560 - accuracy: 0.9851 - val_loss: 0.1148 - val_accuracy: 0.9530\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 336s 7s/step - loss: 0.0490 - accuracy: 0.9870 - val_loss: 0.1186 - val_accuracy: 0.9579\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 425s 8s/step - loss: 0.0484 - accuracy: 0.9888 - val_loss: 0.0860 - val_accuracy: 0.9703\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 404s 8s/step - loss: 0.0568 - accuracy: 0.9845 - val_loss: 0.0887 - val_accuracy: 0.9629\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 349s 7s/step - loss: 0.0554 - accuracy: 0.9808 - val_loss: 0.1391 - val_accuracy: 0.9554\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 374s 7s/step - loss: 0.0395 - accuracy: 0.9882 - val_loss: 0.1236 - val_accuracy: 0.9579\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 381s 7s/step - loss: 0.0418 - accuracy: 0.9876 - val_loss: 0.0708 - val_accuracy: 0.9777\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 350s 7s/step - loss: 0.0299 - accuracy: 0.9919 - val_loss: 0.2688 - val_accuracy: 0.9282\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 326s 6s/step - loss: 0.0369 - accuracy: 0.9895 - val_loss: 0.1734 - val_accuracy: 0.9307\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 400s 8s/step - loss: 0.0315 - accuracy: 0.9907 - val_loss: 0.1195 - val_accuracy: 0.9604\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 407s 8s/step - loss: 0.0252 - accuracy: 0.9919 - val_loss: 0.1159 - val_accuracy: 0.9554\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 374s 7s/step - loss: 0.0214 - accuracy: 0.9944 - val_loss: 0.1064 - val_accuracy: 0.9579\n",
      "13/13 [==============================] - 20s 1s/step\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 110s 8s/step - loss: 3.7879 - accuracy: 0.5404 - val_loss: 2.8850 - val_accuracy: 0.5062\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 71s 6s/step - loss: 0.8845 - accuracy: 0.7112 - val_loss: 0.3878 - val_accuracy: 0.8642\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 74s 7s/step - loss: 0.5041 - accuracy: 0.8043 - val_loss: 0.8046 - val_accuracy: 0.7037\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 83s 8s/step - loss: 0.3668 - accuracy: 0.8665 - val_loss: 0.3261 - val_accuracy: 0.8642\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 87s 8s/step - loss: 0.4414 - accuracy: 0.8261 - val_loss: 0.7328 - val_accuracy: 0.6914\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 73s 6s/step - loss: 0.3871 - accuracy: 0.8292 - val_loss: 0.3741 - val_accuracy: 0.8395\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 77s 7s/step - loss: 0.2879 - accuracy: 0.8882 - val_loss: 0.3248 - val_accuracy: 0.8519\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 80s 7s/step - loss: 0.2898 - accuracy: 0.8882 - val_loss: 0.4880 - val_accuracy: 0.8025\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 84s 8s/step - loss: 0.3313 - accuracy: 0.8665 - val_loss: 0.4416 - val_accuracy: 0.8272\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 85s 8s/step - loss: 0.3102 - accuracy: 0.8789 - val_loss: 0.2725 - val_accuracy: 0.9012\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 84s 8s/step - loss: 0.2987 - accuracy: 0.8509 - val_loss: 0.4586 - val_accuracy: 0.8272\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 77s 7s/step - loss: 0.2717 - accuracy: 0.9068 - val_loss: 0.4914 - val_accuracy: 0.8025\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 82s 7s/step - loss: 0.2361 - accuracy: 0.9068 - val_loss: 0.2788 - val_accuracy: 0.8889\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 77s 7s/step - loss: 0.2206 - accuracy: 0.9193 - val_loss: 0.4536 - val_accuracy: 0.8148\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 79s 7s/step - loss: 0.2085 - accuracy: 0.9130 - val_loss: 0.2250 - val_accuracy: 0.9383\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 73s 7s/step - loss: 0.2479 - accuracy: 0.9006 - val_loss: 0.3760 - val_accuracy: 0.8395\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 89s 8s/step - loss: 0.2041 - accuracy: 0.9224 - val_loss: 0.3597 - val_accuracy: 0.8395\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 90s 8s/step - loss: 0.1766 - accuracy: 0.9348 - val_loss: 0.2627 - val_accuracy: 0.9259\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 85s 8s/step - loss: 0.1907 - accuracy: 0.9224 - val_loss: 0.4166 - val_accuracy: 0.8148\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 85s 8s/step - loss: 0.2089 - accuracy: 0.9286 - val_loss: 0.2206 - val_accuracy: 0.9136\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 87s 8s/step - loss: 0.2144 - accuracy: 0.9161 - val_loss: 0.2451 - val_accuracy: 0.9136\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 95s 9s/step - loss: 0.2306 - accuracy: 0.8975 - val_loss: 0.5147 - val_accuracy: 0.8148\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 76s 7s/step - loss: 0.2923 - accuracy: 0.8882 - val_loss: 0.2155 - val_accuracy: 0.9383\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 76s 7s/step - loss: 0.1765 - accuracy: 0.9224 - val_loss: 0.4310 - val_accuracy: 0.8395\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 75s 7s/step - loss: 0.2267 - accuracy: 0.9099 - val_loss: 0.2298 - val_accuracy: 0.9383\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 83s 7s/step - loss: 0.1871 - accuracy: 0.9193 - val_loss: 0.3202 - val_accuracy: 0.8642\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 75s 7s/step - loss: 0.1831 - accuracy: 0.9379 - val_loss: 0.9016 - val_accuracy: 0.7531\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 76s 7s/step - loss: 0.2395 - accuracy: 0.8944 - val_loss: 0.2634 - val_accuracy: 0.8765\n",
      "3/3 [==============================] - 6s 1s/step\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 111s 8s/step - loss: 3.4729 - accuracy: 0.5155 - val_loss: 1.6238 - val_accuracy: 0.5556\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 95s 9s/step - loss: 0.7278 - accuracy: 0.6801 - val_loss: 0.7023 - val_accuracy: 0.7531\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 80s 7s/step - loss: 0.5619 - accuracy: 0.7764 - val_loss: 1.2199 - val_accuracy: 0.6049\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 82s 8s/step - loss: 0.4472 - accuracy: 0.8075 - val_loss: 0.7245 - val_accuracy: 0.7531\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 78s 7s/step - loss: 0.3593 - accuracy: 0.8634 - val_loss: 0.7689 - val_accuracy: 0.7531\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 76s 7s/step - loss: 0.3192 - accuracy: 0.8789 - val_loss: 0.5993 - val_accuracy: 0.8272\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 80s 7s/step - loss: 0.2928 - accuracy: 0.8820 - val_loss: 0.5806 - val_accuracy: 0.8148\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 76s 7s/step - loss: 0.2659 - accuracy: 0.8913 - val_loss: 0.5709 - val_accuracy: 0.8148\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 77s 7s/step - loss: 0.2354 - accuracy: 0.9068 - val_loss: 0.5293 - val_accuracy: 0.8272\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 94s 9s/step - loss: 0.2196 - accuracy: 0.9037 - val_loss: 0.6165 - val_accuracy: 0.8025\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 87s 8s/step - loss: 0.2190 - accuracy: 0.9006 - val_loss: 0.5178 - val_accuracy: 0.8272\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 80s 7s/step - loss: 0.1952 - accuracy: 0.9317 - val_loss: 0.5811 - val_accuracy: 0.8272\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 80s 7s/step - loss: 0.1923 - accuracy: 0.9193 - val_loss: 0.5139 - val_accuracy: 0.8148\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 77s 7s/step - loss: 0.1712 - accuracy: 0.9410 - val_loss: 0.6844 - val_accuracy: 0.8025\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 77s 7s/step - loss: 0.2103 - accuracy: 0.9068 - val_loss: 0.5458 - val_accuracy: 0.8395\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 76s 7s/step - loss: 0.1643 - accuracy: 0.9410 - val_loss: 0.6853 - val_accuracy: 0.8148\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 77s 7s/step - loss: 0.1551 - accuracy: 0.9503 - val_loss: 0.5841 - val_accuracy: 0.8395\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 81s 7s/step - loss: 0.1457 - accuracy: 0.9627 - val_loss: 0.7374 - val_accuracy: 0.7901\n",
      "3/3 [==============================] - 8s 1s/step\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 114s 8s/step - loss: 1.5996 - accuracy: 0.5311 - val_loss: 1.7444 - val_accuracy: 0.5309\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 91s 8s/step - loss: 0.4632 - accuracy: 0.8385 - val_loss: 1.0988 - val_accuracy: 0.6173\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 90s 8s/step - loss: 0.3106 - accuracy: 0.8913 - val_loss: 0.6137 - val_accuracy: 0.7654\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 92s 8s/step - loss: 0.2912 - accuracy: 0.8913 - val_loss: 0.3878 - val_accuracy: 0.8395\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 86s 8s/step - loss: 0.2463 - accuracy: 0.9193 - val_loss: 0.4070 - val_accuracy: 0.8272\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 84s 8s/step - loss: 0.2184 - accuracy: 0.9193 - val_loss: 0.4105 - val_accuracy: 0.8395\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 85s 8s/step - loss: 0.1890 - accuracy: 0.9286 - val_loss: 0.3875 - val_accuracy: 0.8395\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 91s 8s/step - loss: 0.2329 - accuracy: 0.8975 - val_loss: 0.3411 - val_accuracy: 0.8642\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 88s 8s/step - loss: 0.1944 - accuracy: 0.9224 - val_loss: 0.4664 - val_accuracy: 0.8272\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 79s 7s/step - loss: 0.2291 - accuracy: 0.9224 - val_loss: 0.3598 - val_accuracy: 0.8642\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 79s 7s/step - loss: 0.2437 - accuracy: 0.9130 - val_loss: 0.3166 - val_accuracy: 0.8519\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 87s 8s/step - loss: 0.1685 - accuracy: 0.9348 - val_loss: 0.3175 - val_accuracy: 0.8642\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 90s 8s/step - loss: 0.1588 - accuracy: 0.9472 - val_loss: 0.3226 - val_accuracy: 0.8642\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 95s 9s/step - loss: 0.1456 - accuracy: 0.9472 - val_loss: 0.3086 - val_accuracy: 0.8642\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 92s 8s/step - loss: 0.1414 - accuracy: 0.9472 - val_loss: 0.3224 - val_accuracy: 0.8765\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 94s 8s/step - loss: 0.1197 - accuracy: 0.9627 - val_loss: 0.4642 - val_accuracy: 0.8272\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 97s 9s/step - loss: 0.1269 - accuracy: 0.9472 - val_loss: 0.2930 - val_accuracy: 0.8642\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 96s 9s/step - loss: 0.1292 - accuracy: 0.9503 - val_loss: 0.3005 - val_accuracy: 0.8765\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 93s 8s/step - loss: 0.1156 - accuracy: 0.9627 - val_loss: 0.6346 - val_accuracy: 0.7531\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 93s 8s/step - loss: 0.2262 - accuracy: 0.9161 - val_loss: 0.3490 - val_accuracy: 0.8642\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 94s 8s/step - loss: 0.1158 - accuracy: 0.9410 - val_loss: 0.3756 - val_accuracy: 0.8395\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 93s 9s/step - loss: 0.1098 - accuracy: 0.9658 - val_loss: 0.2800 - val_accuracy: 0.8642\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 91s 8s/step - loss: 0.0984 - accuracy: 0.9689 - val_loss: 0.3026 - val_accuracy: 0.9012\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 95s 9s/step - loss: 0.0998 - accuracy: 0.9720 - val_loss: 0.2919 - val_accuracy: 0.8889\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 86s 8s/step - loss: 0.0971 - accuracy: 0.9689 - val_loss: 0.3264 - val_accuracy: 0.9012\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 97s 9s/step - loss: 0.0832 - accuracy: 0.9658 - val_loss: 0.3452 - val_accuracy: 0.8765\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 86s 8s/step - loss: 0.0786 - accuracy: 0.9752 - val_loss: 0.2928 - val_accuracy: 0.8642\n",
      "3/3 [==============================] - 6s 1s/step\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 122s 9s/step - loss: 2.7275 - accuracy: 0.5000 - val_loss: 0.9775 - val_accuracy: 0.6296\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 88s 8s/step - loss: 0.7342 - accuracy: 0.6584 - val_loss: 1.2702 - val_accuracy: 0.5802\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 88s 8s/step - loss: 0.4923 - accuracy: 0.7981 - val_loss: 1.9221 - val_accuracy: 0.5432\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 75s 7s/step - loss: 0.4879 - accuracy: 0.7981 - val_loss: 0.8979 - val_accuracy: 0.6790\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 112s 10s/step - loss: 0.3110 - accuracy: 0.8696 - val_loss: 0.7807 - val_accuracy: 0.7407\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 77s 7s/step - loss: 0.2934 - accuracy: 0.8758 - val_loss: 0.5201 - val_accuracy: 0.7901\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 78s 7s/step - loss: 0.2745 - accuracy: 0.8851 - val_loss: 0.7579 - val_accuracy: 0.7407\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 78s 7s/step - loss: 0.2429 - accuracy: 0.9006 - val_loss: 0.6952 - val_accuracy: 0.7654\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 91s 8s/step - loss: 0.2196 - accuracy: 0.9224 - val_loss: 0.4655 - val_accuracy: 0.8272\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 89s 8s/step - loss: 0.2397 - accuracy: 0.9068 - val_loss: 1.0250 - val_accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 80s 7s/step - loss: 0.2095 - accuracy: 0.9161 - val_loss: 0.4106 - val_accuracy: 0.8272\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 93s 8s/step - loss: 0.1949 - accuracy: 0.9286 - val_loss: 0.8017 - val_accuracy: 0.7531\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 83s 8s/step - loss: 0.2023 - accuracy: 0.9130 - val_loss: 0.5018 - val_accuracy: 0.8148\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 89s 8s/step - loss: 0.2084 - accuracy: 0.9130 - val_loss: 0.5272 - val_accuracy: 0.7778\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 109s 10s/step - loss: 0.2354 - accuracy: 0.9037 - val_loss: 0.3841 - val_accuracy: 0.8272\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 85s 8s/step - loss: 0.1971 - accuracy: 0.9255 - val_loss: 0.3654 - val_accuracy: 0.8395\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 90s 8s/step - loss: 0.1993 - accuracy: 0.9255 - val_loss: 0.5341 - val_accuracy: 0.8148\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 105s 10s/step - loss: 0.1389 - accuracy: 0.9472 - val_loss: 0.3563 - val_accuracy: 0.8395\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 108s 10s/step - loss: 0.1221 - accuracy: 0.9658 - val_loss: 0.3122 - val_accuracy: 0.8395\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 86s 8s/step - loss: 0.1163 - accuracy: 0.9534 - val_loss: 0.3404 - val_accuracy: 0.8395\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 89s 8s/step - loss: 0.1052 - accuracy: 0.9658 - val_loss: 0.3319 - val_accuracy: 0.8889\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 82s 7s/step - loss: 0.1086 - accuracy: 0.9720 - val_loss: 0.5082 - val_accuracy: 0.8272\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 76s 7s/step - loss: 0.1197 - accuracy: 0.9565 - val_loss: 0.5507 - val_accuracy: 0.8519\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 76s 7s/step - loss: 0.0962 - accuracy: 0.9658 - val_loss: 0.9164 - val_accuracy: 0.7654\n",
      "WARNING:tensorflow:5 out of the last 23 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7febeb2d6c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 14:57:31,604 - WARNING - 5 out of the last 23 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7febeb2d6c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 5s 1s/step\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 105s 7s/step - loss: 4.3138 - accuracy: 0.5186 - val_loss: 1.9654 - val_accuracy: 0.5309\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 83s 8s/step - loss: 0.9036 - accuracy: 0.6460 - val_loss: 1.2275 - val_accuracy: 0.5926\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 78s 7s/step - loss: 0.4941 - accuracy: 0.7795 - val_loss: 0.6073 - val_accuracy: 0.8148\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 82s 7s/step - loss: 0.4246 - accuracy: 0.8292 - val_loss: 0.7466 - val_accuracy: 0.8025\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 82s 8s/step - loss: 0.4048 - accuracy: 0.8385 - val_loss: 0.7176 - val_accuracy: 0.8148\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 91s 8s/step - loss: 0.3877 - accuracy: 0.8447 - val_loss: 0.5406 - val_accuracy: 0.8519\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 89s 8s/step - loss: 0.3838 - accuracy: 0.8354 - val_loss: 0.9420 - val_accuracy: 0.7160\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 91s 8s/step - loss: 0.4050 - accuracy: 0.8261 - val_loss: 0.4888 - val_accuracy: 0.8765\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 83s 7s/step - loss: 0.3547 - accuracy: 0.8416 - val_loss: 0.4991 - val_accuracy: 0.8765\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 82s 7s/step - loss: 0.3375 - accuracy: 0.8696 - val_loss: 0.5701 - val_accuracy: 0.8519\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 81s 7s/step - loss: 0.3156 - accuracy: 0.8665 - val_loss: 0.6617 - val_accuracy: 0.8272\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 78s 7s/step - loss: 0.3158 - accuracy: 0.8727 - val_loss: 0.6959 - val_accuracy: 0.8272\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 87s 8s/step - loss: 0.2896 - accuracy: 0.8882 - val_loss: 0.4762 - val_accuracy: 0.8519\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 97s 9s/step - loss: 0.3575 - accuracy: 0.8292 - val_loss: 0.6305 - val_accuracy: 0.8395\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 90s 8s/step - loss: 0.6100 - accuracy: 0.7950 - val_loss: 0.8842 - val_accuracy: 0.7778\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 89s 8s/step - loss: 0.3193 - accuracy: 0.8820 - val_loss: 0.7132 - val_accuracy: 0.8519\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 81s 7s/step - loss: 0.3129 - accuracy: 0.8634 - val_loss: 0.4841 - val_accuracy: 0.8642\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 80s 7s/step - loss: 0.3079 - accuracy: 0.8696 - val_loss: 0.7352 - val_accuracy: 0.8395\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fec3c808700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 15:23:30,616 - WARNING - 5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fec3c808700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 6s 1s/step\n",
      "Epoch 1/100\n",
      "51/51 [==============================] - 391s 7s/step - loss: 0.5950 - accuracy: 0.7990 - val_loss: 0.4015 - val_accuracy: 0.8663\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 356s 7s/step - loss: 0.3773 - accuracy: 0.8468 - val_loss: 0.8259 - val_accuracy: 0.6980\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 352s 7s/step - loss: 0.3272 - accuracy: 0.8666 - val_loss: 0.4360 - val_accuracy: 0.8342\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 352s 7s/step - loss: 0.2613 - accuracy: 0.8896 - val_loss: 0.2635 - val_accuracy: 0.9084\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 347s 7s/step - loss: 0.2526 - accuracy: 0.8976 - val_loss: 0.2549 - val_accuracy: 0.9208\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 349s 7s/step - loss: 0.2362 - accuracy: 0.9032 - val_loss: 0.2458 - val_accuracy: 0.9381\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 349s 7s/step - loss: 0.1948 - accuracy: 0.9293 - val_loss: 0.2580 - val_accuracy: 0.9109\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 347s 7s/step - loss: 0.1984 - accuracy: 0.9280 - val_loss: 0.5907 - val_accuracy: 0.8267\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 345s 7s/step - loss: 0.2063 - accuracy: 0.9175 - val_loss: 0.2101 - val_accuracy: 0.9431\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 349s 7s/step - loss: 0.1541 - accuracy: 0.9435 - val_loss: 0.2311 - val_accuracy: 0.9332\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 350s 7s/step - loss: 0.2386 - accuracy: 0.9274 - val_loss: 0.2114 - val_accuracy: 0.9356\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 348s 7s/step - loss: 0.1586 - accuracy: 0.9498 - val_loss: 0.3113 - val_accuracy: 0.9109\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 350s 7s/step - loss: 0.1437 - accuracy: 0.9541 - val_loss: 0.2766 - val_accuracy: 0.8960\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 350s 7s/step - loss: 0.1239 - accuracy: 0.9529 - val_loss: 0.4527 - val_accuracy: 0.8441\n",
      "13/13 [==============================] - 17s 1s/step\n",
      "13/13 [==============================] - 15s 1s/step\n",
      "13/13 [==============================] - 17s 1s/step\n",
      "13/13 [==============================] - 16s 1s/step\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 612s 9s/step - loss: 0.6062 - accuracy: 0.7460 - val_loss: 0.6843 - val_accuracy: 0.7315\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 543s 9s/step - loss: 0.3460 - accuracy: 0.8547 - val_loss: 0.6875 - val_accuracy: 0.5071\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 548s 9s/step - loss: 0.3116 - accuracy: 0.8760 - val_loss: 0.6863 - val_accuracy: 0.5123\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 546s 9s/step - loss: 0.2693 - accuracy: 0.8938 - val_loss: 0.6886 - val_accuracy: 0.5068\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 545s 9s/step - loss: 0.2491 - accuracy: 0.8973 - val_loss: 0.6884 - val_accuracy: 0.5062\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 545s 9s/step - loss: 0.2455 - accuracy: 0.9043 - val_loss: 0.7166 - val_accuracy: 0.5062\n",
      "113/113 [==============================] - 149s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 17:46:56,422 - INFO - All analyses completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import json\n",
    "import logging\n",
    "import seaborn as sns\n",
    "from scipy.signal import resample\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Dataset definitions\n",
    "datasets = [\n",
    "    {\"name\": \"CUSPH-SR-AF\", \"data\": \"data/data_2class_normal.npy\", \"labels\": \"data/labels_2class_normal.npy\", \"num_classes\": 2, \"input_shape\": (5000, 12)},\n",
    "    {\"name\": \"CSPC18-SR-AF\", \"data\": \"data/data_2class_cpsc18.npy\", \"labels\": \"data/labels_2class_cpsc18.npy\", \"num_classes\": 2, \"input_shape\": (15000, 12)},\n",
    "]\n",
    "\n",
    "filter_combinations = [[32, 64, 128]]\n",
    "\n",
    "def save_results(results, dataset_name, experiment_type, train_condition, test_condition):\n",
    "    filename = f\"robustness/results/{dataset_name}_{experiment_type}_train_{train_condition}_test_{test_condition}.json\"\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "def save_confusion_matrix(cm, dataset_name, experiment_name):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {dataset_name} - {experiment_name}')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"robustness/results/{dataset_name}_{experiment_name}_confusion_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "def downsample_block(x, filters):\n",
    "    x = layers.Conv1D(filters // 2, 1, strides=1, padding='same')(x)\n",
    "    x = mixed_pool_operator(x)\n",
    "    return x\n",
    "\n",
    "def branched_nodal_operator(x, filters, kernel_size=5, activation='relu'):\n",
    "    y1 = layers.Conv1D(filters // 2, kernel_size, dilation_rate=2, padding='same')(x)\n",
    "    y1 = layers.BatchNormalization()(y1)\n",
    "    y1 = layers.Activation(activation)(y1)\n",
    "\n",
    "    y2 = layers.SeparableConv1D(filters // 2, kernel_size, padding='same')(x)\n",
    "    y2 = layers.BatchNormalization()(y2)\n",
    "    y2 = layers.Activation(activation)(y2)\n",
    "\n",
    "    y = layers.Concatenate()([y1, y2])\n",
    "    return y\n",
    "\n",
    "def mixed_pool_operator(x, pool_size=2, strides=1):\n",
    "    y1 = layers.AveragePooling1D(pool_size, strides, padding='same')(x)\n",
    "    y2 = layers.MaxPooling1D(pool_size, strides, padding='same')(x)\n",
    "    y = layers.Concatenate()([y1, y2])\n",
    "    return y\n",
    "\n",
    "def squeeze_and_excitation_block(x, ratio=16):\n",
    "    num_channels = x.shape[-1]\n",
    "    squeeze = layers.GlobalAveragePooling1D()(x)\n",
    "    excitation = layers.Dense(num_channels // ratio, activation='relu')(squeeze)\n",
    "    excitation = layers.Dense(num_channels, activation='sigmoid')(excitation)\n",
    "    excitation = layers.Reshape((1, num_channels))(excitation)\n",
    "    scale = layers.Multiply()([x, excitation])\n",
    "    return scale\n",
    "\n",
    "def residual_block_SERN_AwGOP(x, filters, kernel_size=5, downsample=False):\n",
    "    y = branched_nodal_operator(x, filters, kernel_size)\n",
    "    y = branched_nodal_operator(y, filters, kernel_size)\n",
    "\n",
    "    if downsample:\n",
    "        x = downsample_block(x, filters)\n",
    "\n",
    "    y = squeeze_and_excitation_block(y)\n",
    "\n",
    "    attention_weights = layers.Dense(1, activation='sigmoid')(x)\n",
    "    gop_out = layers.Multiply()([attention_weights, y])\n",
    "    gop_out = layers.Add()([gop_out, x])\n",
    "    gop_out = layers.Activation('relu')(gop_out)\n",
    "    return gop_out\n",
    "\n",
    "def create_SERN_AwGOP(input_shape, num_classes, filters):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv1D(filters[0], 5, strides=2, padding='same', activation='relu')(inputs)\n",
    "    x = layers.MaxPooling1D(pool_size=3, strides=2, padding='same')(x)\n",
    "\n",
    "    for f in filters[1:]:\n",
    "        x = residual_block_SERN_AwGOP(x, f, downsample=True)\n",
    "        x = residual_block_SERN_AwGOP(x, f)\n",
    "        x = residual_block_SERN_AwGOP(x, f)\n",
    "        x = residual_block_SERN_AwGOP(x, f)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    if num_classes == 2:\n",
    "        outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    else:\n",
    "        outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    if num_classes == 2:\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    else:\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val):\n",
    "    try:\n",
    "        history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        return history\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in train_model: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, num_classes):\n",
    "    try:\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1) if num_classes > 2 else (y_pred > 0.5).astype(int).flatten()\n",
    "\n",
    "        results = {\n",
    "            'accuracy': float(accuracy_score(y_test, y_pred_classes)),\n",
    "            'precision_weighted': float(precision_score(y_test, y_pred_classes, average='weighted')),\n",
    "            'recall_weighted': float(recall_score(y_test, y_pred_classes, average='weighted')),\n",
    "            'f1_weighted': float(f1_score(y_test, y_pred_classes, average='weighted')),\n",
    "        }\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred_classes)\n",
    "        sensitivity = cm[1,1] / (cm[1,1] + cm[1,0])\n",
    "        specificity = cm[0,0] / (cm[0,0] + cm[0,1])\n",
    "        results['sensitivity_unweighted'] = float(sensitivity)\n",
    "        results['specificity_unweighted'] = float(specificity)\n",
    "\n",
    "        if num_classes == 2:\n",
    "            results['auc_roc'] = float(roc_auc_score(y_test, y_pred))\n",
    "            results['average_precision'] = float(average_precision_score(y_test, y_pred))\n",
    "\n",
    "        return results, cm\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in evaluate_model: {str(e)}\")\n",
    "        return {}, None\n",
    "\n",
    "def data_efficiency_analysis(dataset, model_fn, filters, fractions=[0.1, 0.25, 0.5, 0.75, 1.0]):\n",
    "    try:\n",
    "        data = np.load(dataset['data'])\n",
    "        labels = np.load(dataset['labels'])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "        results = {}\n",
    "        for fraction in fractions:\n",
    "            n_samples = int(len(X_train) * fraction)\n",
    "            X_train_subset = X_train[:n_samples]\n",
    "            y_train_subset = y_train[:n_samples]\n",
    "\n",
    "            model = model_fn(dataset['input_shape'], dataset['num_classes'], filters)\n",
    "            history = train_model(model, X_train_subset, y_train_subset, X_test, y_test)\n",
    "            test_results, cm = evaluate_model(model, X_test, y_test, dataset['num_classes'])\n",
    "            results[fraction] = test_results\n",
    "            \n",
    "            # Save confusion matrix for each fraction\n",
    "            save_confusion_matrix(cm, dataset['name'], f\"data_efficiency_{fraction}\")\n",
    "\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in data_efficiency_analysis: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "def longitudinal_analysis(dataset, model_fn, filters, num_time_points=5):\n",
    "    try:\n",
    "        data = np.load(dataset['data'])\n",
    "        labels = np.load(dataset['labels'])\n",
    "\n",
    "        time_point_size = len(data) // num_time_points\n",
    "        results = []\n",
    "\n",
    "        for i in range(num_time_points):\n",
    "            start_idx = i * time_point_size\n",
    "            end_idx = (i + 1) * time_point_size\n",
    "            X_train, X_test, y_train, y_test = train_test_split(data[start_idx:end_idx], labels[start_idx:end_idx], test_size=0.2, random_state=42)\n",
    "\n",
    "            model = model_fn(dataset['input_shape'], dataset['num_classes'], filters)\n",
    "            history = train_model(model, X_train, y_train, X_test, y_test)\n",
    "            test_results, cm = evaluate_model(model, X_test, y_test, dataset['num_classes'])\n",
    "            results.append(test_results)\n",
    "            \n",
    "            # Save confusion matrix for each time point\n",
    "            save_confusion_matrix(cm, dataset['name'], f\"longitudinal_timepoint_{i}\")\n",
    "\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in longitudinal_analysis: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def add_gaussian_noise(data, noise_factor=0.05):\n",
    "    noise = np.random.normal(loc=0, scale=1, size=data.shape)\n",
    "    return data + noise_factor * noise\n",
    "\n",
    "def add_powerline_interference(data, frequency=50, amplitude=0.1):\n",
    "    t = np.arange(data.shape[1]) / 1000  # Assume 1000 Hz sampling rate\n",
    "    noise = amplitude * np.sin(2 * np.pi * frequency * t)\n",
    "    return data + noise.reshape(1, -1, 1)\n",
    "\n",
    "def add_electrode_motion_artifact(data, artifact_duration=100, amplitude=0.5):\n",
    "    artifact = np.zeros(data.shape)\n",
    "    for i in range(data.shape[0]):\n",
    "        start = np.random.randint(0, data.shape[1] - artifact_duration)\n",
    "        artifact[i, start:start+artifact_duration, :] = amplitude * np.random.randn(artifact_duration, data.shape[2])\n",
    "    return data + artifact\n",
    "\n",
    "def robustness_testing(dataset, model_fn, filters):\n",
    "    try:\n",
    "        data = np.load(dataset['data'])\n",
    "        labels = np.load(dataset['labels'])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "        model = model_fn(dataset['input_shape'], dataset['num_classes'], filters)\n",
    "        history = train_model(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        # Test on clean data\n",
    "        clean_results, clean_cm = evaluate_model(model, X_test, y_test, dataset['num_classes'])\n",
    "        results['clean'] = clean_results\n",
    "        save_confusion_matrix(clean_cm, dataset['name'], \"robustness_clean\")\n",
    "\n",
    "        # Test with Gaussian noise\n",
    "        noisy_data = add_gaussian_noise(X_test)\n",
    "        noise_results, noise_cm = evaluate_model(model, noisy_data, y_test, dataset['num_classes'])\n",
    "        results['gaussian_noise'] = noise_results\n",
    "        save_confusion_matrix(noise_cm, dataset['name'], \"robustness_gaussian_noise\")\n",
    "\n",
    "        # Test with powerline interference\n",
    "        powerline_data = add_powerline_interference(X_test)\n",
    "        powerline_results, powerline_cm = evaluate_model(model, powerline_data, y_test, dataset['num_classes'])\n",
    "        results['powerline_interference'] = powerline_results\n",
    "        save_confusion_matrix(powerline_cm, dataset['name'], \"robustness_powerline_interference\")\n",
    "\n",
    "        # Test with electrode motion artifact\n",
    "        motion_data = add_electrode_motion_artifact(X_test)\n",
    "        motion_results, motion_cm = evaluate_model(model, motion_data, y_test, dataset['num_classes'])\n",
    "        results['electrode_motion'] = motion_results\n",
    "        save_confusion_matrix(motion_cm, dataset['name'], \"robustness_electrode_motion\")\n",
    "\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in robustness_testing: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "def cross_dataset_validation(train_dataset, test_dataset, model_fn, filters):\n",
    "    try:\n",
    "        train_data = np.load(train_dataset['data'])\n",
    "        train_labels = np.load(train_dataset['labels'])\n",
    "        test_data = np.load(test_dataset['data'])\n",
    "        test_labels = np.load(test_dataset['labels'])\n",
    "\n",
    "        # Ensure compatible shapes\n",
    "        if train_data.shape[1:] != test_data.shape[1:]:\n",
    "            test_data = resample(test_data, train_data.shape[1], axis=1)\n",
    "\n",
    "        model = model_fn(train_dataset['input_shape'], train_dataset['num_classes'], filters)\n",
    "        history = train_model(model, train_data, train_labels, test_data, test_labels)\n",
    "        test_results, cm = evaluate_model(model, test_data, test_labels, test_dataset['num_classes'])\n",
    "        \n",
    "        # Save confusion matrix for cross-dataset validation\n",
    "        save_confusion_matrix(cm, f\"{train_dataset['name']}_{test_dataset['name']}\", \"cross_validation\")\n",
    "\n",
    "        return test_results\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in cross_dataset_validation: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "def main():\n",
    "    results_dict = {}\n",
    "    for dataset in datasets:\n",
    "        results_dict[dataset['name']] = {}\n",
    "        for filters in filter_combinations:\n",
    "            logging.info(f\"Processing dataset: {dataset['name']} with filters: {filters}\")\n",
    "\n",
    "            try:\n",
    "                # Data Efficiency Analysis\n",
    "                efficiency_results = data_efficiency_analysis(dataset, create_SERN_AwGOP, filters)\n",
    "                results_dict[dataset['name']]['data_efficiency'] = efficiency_results\n",
    "                save_results(efficiency_results, dataset['name'], \"data_efficiency\", \"various\", \"clean\")\n",
    "\n",
    "                # Longitudinal Analysis\n",
    "                longitudinal_results = longitudinal_analysis(dataset, create_SERN_AwGOP, filters)\n",
    "                results_dict[dataset['name']]['longitudinal'] = longitudinal_results\n",
    "                save_results(longitudinal_results, dataset['name'], \"longitudinal\", \"various\", \"clean\")\n",
    "\n",
    "                # Robustness Testing\n",
    "                robustness_results = robustness_testing(dataset, create_SERN_AwGOP, filters)\n",
    "                results_dict[dataset['name']]['robustness'] = robustness_results\n",
    "                save_results(robustness_results, dataset['name'], \"robustness\", \"original\", \"various\")\n",
    "\n",
    "                # Cross-dataset Validation\n",
    "                for test_dataset in datasets:\n",
    "                    if test_dataset['name'] != dataset['name']:\n",
    "                        cross_results = cross_dataset_validation(dataset, test_dataset, create_SERN_AwGOP, filters)\n",
    "                        results_dict[dataset['name']][f'cross_validation_{test_dataset[\"name\"]}'] = cross_results\n",
    "                        save_results(cross_results, f\"{dataset['name']}_{test_dataset['name']}\", \"cross_validation\", dataset['name'], test_dataset['name'])\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing {dataset['name']}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    logging.info(\"All analyses completed successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q1/d82dt4ns3kd7h9yk5cv3ysfr0000gn/T/ipykernel_70049/1428961103.py:99: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.tight_layout()\n",
      "/var/folders/q1/d82dt4ns3kd7h9yk5cv3ysfr0000gn/T/ipykernel_70049/1428961103.py:99: UserWarning: Tight layout not applied. tight_layout cannot make axes height small enough to accommodate all axes decorations.\n",
      "  plt.tight_layout()\n",
      "/var/folders/q1/d82dt4ns3kd7h9yk5cv3ysfr0000gn/T/ipykernel_70049/1428961103.py:100: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig('ecg_transformations_visualization.png', dpi=300, bbox_inches='tight')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Image size of 4964x942782 pixels is too large. It must be less than 2^16 in each direction.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 100\u001b[0m\n\u001b[1;32m     97\u001b[0m ax4\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAmplitude\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     99\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[0;32m--> 100\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mecg_transformations_visualization.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_inches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m plt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisualization saved as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mecg_transformations_visualization.png\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/matplotlib/pyplot.py:1023\u001b[0m, in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[38;5;241m.\u001b[39msavefig)\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msavefig\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1022\u001b[0m     fig \u001b[38;5;241m=\u001b[39m gcf()\n\u001b[0;32m-> 1023\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1024\u001b[0m     fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/matplotlib/figure.py:3378\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3374\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[1;32m   3375\u001b[0m         stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[1;32m   3376\u001b[0m             ax\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39m_cm_set(facecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m-> 3378\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/matplotlib/backend_bases.py:2366\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2362\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2363\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2364\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[1;32m   2365\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[0;32m-> 2366\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2367\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2368\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2369\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2370\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2371\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2372\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2373\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/matplotlib/backend_bases.py:2232\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2228\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2230\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m   2231\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[0;32m-> 2232\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:509\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    463\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 509\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:457\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_print_pil\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, fmt, pil_kwargs, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    453\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;124;03m    Draw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;124;03m    *pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 457\u001b[0m     \u001b[43mFigureCanvasAgg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m     mpl\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimsave(\n\u001b[1;32m    459\u001b[0m         filename_or_obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_rgba(), \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mfmt, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    460\u001b[0m         dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi, metadata\u001b[38;5;241m=\u001b[39mmetadata, pil_kwargs\u001b[38;5;241m=\u001b[39mpil_kwargs)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:394\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;66;03m# docstring inherited\u001b[39;00m\n\u001b[0;32m--> 394\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_renderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/matplotlib/_api/deprecation.py:384\u001b[0m, in \u001b[0;36mdelete_parameter.<locals>.wrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39minner_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minner_kwargs):\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inner_args) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m name_idx \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m inner_kwargs:\n\u001b[1;32m    382\u001b[0m         \u001b[38;5;66;03m# Early return in the simple, non-deprecated case (much faster than\u001b[39;00m\n\u001b[1;32m    383\u001b[0m         \u001b[38;5;66;03m# calling bind()).\u001b[39;00m\n\u001b[0;32m--> 384\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minner_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minner_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m     arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39minner_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minner_kwargs)\u001b[38;5;241m.\u001b[39marguments\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_varargs \u001b[38;5;129;01mand\u001b[39;00m arguments\u001b[38;5;241m.\u001b[39mget(name):\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:411\u001b[0m, in \u001b[0;36mFigureCanvasAgg.get_renderer\u001b[0;34m(self, cleared)\u001b[0m\n\u001b[1;32m    409\u001b[0m reuse_renderer \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lastKey \u001b[38;5;241m==\u001b[39m key)\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reuse_renderer:\n\u001b[0;32m--> 411\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer \u001b[38;5;241m=\u001b[39m \u001b[43mRendererAgg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lastKey \u001b[38;5;241m=\u001b[39m key\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m cleared:\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:84\u001b[0m, in \u001b[0;36mRendererAgg.__init__\u001b[0;34m(self, width, height, dpi)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m width\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m=\u001b[39m height\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_renderer \u001b[38;5;241m=\u001b[39m \u001b[43m_RendererAgg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter_renderers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_methods()\n",
      "\u001b[0;31mValueError\u001b[0m: Image size of 4964x942782 pixels is too large. It must be less than 2^16 in each direction."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/IPython/core/events.py:89: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  func(*args, **kwargs)\n",
      "/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Image size of 1654x314261 pixels is too large. It must be less than 2^16 in each direction.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/IPython/core/formatters.py:340\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    342\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/IPython/core/pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 152\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/matplotlib/backend_bases.py:2366\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2362\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2363\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2364\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[1;32m   2365\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[0;32m-> 2366\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2367\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2368\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2369\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2370\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2371\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2372\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2373\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/matplotlib/backend_bases.py:2232\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2228\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2230\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m   2231\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[0;32m-> 2232\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:509\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    463\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 509\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:457\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_print_pil\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, fmt, pil_kwargs, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    453\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;124;03m    Draw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;124;03m    *pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 457\u001b[0m     \u001b[43mFigureCanvasAgg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m     mpl\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimsave(\n\u001b[1;32m    459\u001b[0m         filename_or_obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_rgba(), \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mfmt, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    460\u001b[0m         dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi, metadata\u001b[38;5;241m=\u001b[39mmetadata, pil_kwargs\u001b[38;5;241m=\u001b[39mpil_kwargs)\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:394\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;66;03m# docstring inherited\u001b[39;00m\n\u001b[0;32m--> 394\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_renderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/matplotlib/_api/deprecation.py:384\u001b[0m, in \u001b[0;36mdelete_parameter.<locals>.wrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39minner_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minner_kwargs):\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inner_args) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m name_idx \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m inner_kwargs:\n\u001b[1;32m    382\u001b[0m         \u001b[38;5;66;03m# Early return in the simple, non-deprecated case (much faster than\u001b[39;00m\n\u001b[1;32m    383\u001b[0m         \u001b[38;5;66;03m# calling bind()).\u001b[39;00m\n\u001b[0;32m--> 384\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minner_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minner_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m     arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39minner_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minner_kwargs)\u001b[38;5;241m.\u001b[39marguments\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_varargs \u001b[38;5;129;01mand\u001b[39;00m arguments\u001b[38;5;241m.\u001b[39mget(name):\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:411\u001b[0m, in \u001b[0;36mFigureCanvasAgg.get_renderer\u001b[0;34m(self, cleared)\u001b[0m\n\u001b[1;32m    409\u001b[0m reuse_renderer \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lastKey \u001b[38;5;241m==\u001b[39m key)\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reuse_renderer:\n\u001b[0;32m--> 411\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer \u001b[38;5;241m=\u001b[39m \u001b[43mRendererAgg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lastKey \u001b[38;5;241m=\u001b[39m key\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m cleared:\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/SERN-AwGOP-FPGA/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:84\u001b[0m, in \u001b[0;36mRendererAgg.__init__\u001b[0;34m(self, width, height, dpi)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m width\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m=\u001b[39m height\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_renderer \u001b[38;5;241m=\u001b[39m \u001b[43m_RendererAgg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter_renderers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_methods()\n",
      "\u001b[0;31mValueError\u001b[0m: Image size of 1654x314261 pixels is too large. It must be less than 2^16 in each direction."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import resample\n",
    "\n",
    "# Load data\n",
    "data = np.load('data/data_2class_normal.npy')\n",
    "labels = np.load('data/labels_2class_normal.npy')\n",
    "\n",
    "# Select a random AF sample\n",
    "af_indices = np.where(labels == 1)[0]\n",
    "random_af_index = np.random.choice(af_indices)\n",
    "sample = data[random_af_index]\n",
    "\n",
    "# Ensure sample is (5000, 12)\n",
    "if sample.shape[0] > 5000:\n",
    "    sample = resample(sample, 5000, axis=0)\n",
    "\n",
    "# Define transformation functions\n",
    "def add_gaussian_noise(data, noise_factor=0.05):\n",
    "    noise = np.random.normal(loc=0, scale=1, size=data.shape)\n",
    "    return data + noise_factor * noise\n",
    "\n",
    "def add_random_baseline_wander(data, max_amplitude=0.1):\n",
    "    t = np.linspace(0, 1, data.shape[0])\n",
    "    baseline = max_amplitude * np.sin(2 * np.pi * np.random.rand() * t)\n",
    "    return data + baseline.reshape(-1, 1)\n",
    "\n",
    "def time_warp(data, sigma=0.2, knot=4):\n",
    "    orig_steps = np.arange(data.shape[0])\n",
    "    random_warps = np.random.normal(loc=1.0, scale=sigma, size=(knot+2,))\n",
    "    warp_steps = np.linspace(0, data.shape[0]-1, num=knot+2)\n",
    "    warper = np.interp(orig_steps, warp_steps, random_warps)\n",
    "    return data * warper.reshape(-1, 1)\n",
    "\n",
    "def simulate_hardware_issues(data, corruption_rate=0.1):\n",
    "    corrupted_data = data.copy()\n",
    "    mask = np.random.choice([0, 1], size=data.shape, p=[1-corruption_rate, corruption_rate])\n",
    "    corrupted_data[mask.astype(bool)] = np.random.normal(loc=0, scale=1, size=corrupted_data[mask.astype(bool)].shape)\n",
    "    return corrupted_data\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "# First subplot: All 12 electrodes\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax1.set_title(\"Original 12-lead ECG\")\n",
    "for i in range(12):\n",
    "    ax1.plot(sample[:, i] + i*4, label=f'Lead {i+1}')\n",
    "ax1.set_yticks(np.arange(0, 48, 4))\n",
    "ax1.set_yticklabels([f'Lead {i+1}' for i in range(12)])\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Amplitude')\n",
    "\n",
    "# Second subplot: Transformations on specific electrodes\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax2.set_title(\"Transformations on Specific Leads\")\n",
    "\n",
    "# Apply transformations\n",
    "noisy = add_gaussian_noise(sample[:, 1])\n",
    "baseline_wander = add_random_baseline_wander(sample[:, 3])\n",
    "time_warped = time_warp(sample[:, 5])\n",
    "all_combined = time_warp(add_random_baseline_wander(add_gaussian_noise(sample[:, 7])))\n",
    "\n",
    "ax2.plot(sample[:, 1], label='Original (Lead 2)')\n",
    "ax2.plot(noisy, label='Noisy (Lead 2)')\n",
    "ax2.plot(baseline_wander, label='Baseline Wander (Lead 4)')\n",
    "ax2.plot(time_warped, label='Time Warped (Lead 6)')\n",
    "ax2.plot(all_combined, label='All Combined (Lead 8)')\n",
    "ax2.legend()\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('Amplitude')\n",
    "\n",
    "# Third subplot: Hardware corruption on all electrodes\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax3.set_title(\"Hardware Corruption on All Leads\")\n",
    "corrupted = simulate_hardware_issues(sample)\n",
    "for i in range(12):\n",
    "    ax3.plot(corrupted[:, i] + i*4, label=f'Lead {i+1}')\n",
    "ax3.set_yticks(np.arange(0, 48, 4))\n",
    "ax3.set_yticklabels([f'Lead {i+1}' for i in range(12)])\n",
    "ax3.set_xlabel('Time')\n",
    "ax3.set_ylabel('Amplitude')\n",
    "\n",
    "# Fourth subplot: Longitudinal segments\n",
    "ax4 = fig.add_subplot(224)\n",
    "ax4.set_title(\"Longitudinal Segments\")\n",
    "num_segments = 5\n",
    "segment_length = sample.shape[0] // num_segments\n",
    "for i in range(12):\n",
    "    for j in range(num_segments):\n",
    "        start = j * segment_length\n",
    "        end = (j + 1) * segment_length\n",
    "        ax4.plot(range(start, end), sample[start:end, i] + i*4, label=f'Lead {i+1}, Segment {j+1}' if j == 0 else \"\")\n",
    "ax4.set_yticks(np.arange(0, 48, 4))\n",
    "ax4.set_yticklabels([f'Lead {i+1}' for i in range(12)])\n",
    "ax4.set_xlabel('Time')\n",
    "ax4.set_ylabel('Amplitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ecg_transformations_visualization.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"Visualization saved as 'ecg_transformations_visualization.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-26 09:00:01,219 - INFO - Processing dataset: CUSPH-SR-AF with filters: [32, 64, 128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "91/91 [==============================] - 256s 3s/step - loss: 0.2052 - accuracy: 0.9189 - val_loss: 0.5794 - val_accuracy: 0.5645\n",
      "Epoch 2/100\n",
      "91/91 [==============================] - 232s 3s/step - loss: 0.0670 - accuracy: 0.9809 - val_loss: 0.3977 - val_accuracy: 0.9542\n",
      "Epoch 3/100\n",
      "91/91 [==============================] - 227s 2s/step - loss: 0.0384 - accuracy: 0.9899 - val_loss: 0.3533 - val_accuracy: 0.9043\n",
      "Epoch 4/100\n",
      "91/91 [==============================] - 227s 2s/step - loss: 0.0283 - accuracy: 0.9924 - val_loss: 0.1956 - val_accuracy: 0.9626\n",
      "Epoch 5/100\n",
      "91/91 [==============================] - 227s 2s/step - loss: 0.0442 - accuracy: 0.9868 - val_loss: 0.9304 - val_accuracy: 0.5589\n",
      "Epoch 6/100\n",
      "91/91 [==============================] - 229s 3s/step - loss: 0.0360 - accuracy: 0.9893 - val_loss: 0.0373 - val_accuracy: 0.9903\n",
      "Epoch 7/100\n",
      "91/91 [==============================] - 232s 3s/step - loss: 0.0292 - accuracy: 0.9899 - val_loss: 0.0520 - val_accuracy: 0.9861\n",
      "Epoch 8/100\n",
      "91/91 [==============================] - 233s 3s/step - loss: 0.0168 - accuracy: 0.9965 - val_loss: 0.0353 - val_accuracy: 0.9945\n",
      "Epoch 9/100\n",
      "91/91 [==============================] - 233s 3s/step - loss: 0.0130 - accuracy: 0.9965 - val_loss: 0.0216 - val_accuracy: 0.9945\n",
      "Epoch 10/100\n",
      "91/91 [==============================] - 234s 3s/step - loss: 0.0341 - accuracy: 0.9906 - val_loss: 0.0215 - val_accuracy: 0.9972\n",
      "Epoch 11/100\n",
      "91/91 [==============================] - 235s 3s/step - loss: 0.0146 - accuracy: 0.9962 - val_loss: 0.0347 - val_accuracy: 0.9931\n",
      "Epoch 12/100\n",
      "91/91 [==============================] - 237s 3s/step - loss: 0.0431 - accuracy: 0.9872 - val_loss: 0.0316 - val_accuracy: 0.9945\n",
      "Epoch 13/100\n",
      "91/91 [==============================] - 237s 3s/step - loss: 0.0173 - accuracy: 0.9941 - val_loss: 0.0305 - val_accuracy: 0.9945\n",
      "Epoch 14/100\n",
      "91/91 [==============================] - 237s 3s/step - loss: 0.0108 - accuracy: 0.9958 - val_loss: 0.0337 - val_accuracy: 0.9945\n",
      "Epoch 15/100\n",
      "91/91 [==============================] - 237s 3s/step - loss: 0.0386 - accuracy: 0.9879 - val_loss: 0.0189 - val_accuracy: 0.9986\n",
      "Epoch 16/100\n",
      "91/91 [==============================] - 237s 3s/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.0341 - val_accuracy: 0.9931\n",
      "Epoch 17/100\n",
      "91/91 [==============================] - 236s 3s/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0220 - val_accuracy: 0.9958\n",
      "Epoch 18/100\n",
      "91/91 [==============================] - 238s 3s/step - loss: 0.0045 - accuracy: 0.9993 - val_loss: 0.0304 - val_accuracy: 0.9945\n",
      "Epoch 19/100\n",
      "91/91 [==============================] - 240s 3s/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0213 - val_accuracy: 0.9958\n",
      "Epoch 20/100\n",
      "91/91 [==============================] - 241s 3s/step - loss: 0.0246 - accuracy: 0.9931 - val_loss: 0.0869 - val_accuracy: 0.9764\n",
      "23/23 [==============================] - 12s 438ms/step\n",
      "23/23 [==============================] - 10s 442ms/step\n",
      "23/23 [==============================] - 9s 411ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-26 10:19:19,140 - INFO - All hardware corruption tests completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "def downsample_block(x, filters):\n",
    "    x = layers.Conv1D(filters // 2, 1, strides=1, padding='same')(x)\n",
    "    x = mixed_pool_operator(x)\n",
    "    return x\n",
    "\n",
    "def branched_nodal_operator(x, filters, kernel_size=5, activation='relu'):\n",
    "    y1 = layers.Conv1D(filters // 2, kernel_size, dilation_rate=2, padding='same')(x)\n",
    "    y1 = layers.BatchNormalization()(y1)\n",
    "    y1 = layers.Activation(activation)(y1)\n",
    "\n",
    "    y2 = layers.SeparableConv1D(filters // 2, kernel_size, padding='same')(x)\n",
    "    y2 = layers.BatchNormalization()(y2)\n",
    "    y2 = layers.Activation(activation)(y2)\n",
    "\n",
    "    y = layers.Concatenate()([y1, y2])\n",
    "    return y\n",
    "\n",
    "def mixed_pool_operator(x, pool_size=2, strides=1):\n",
    "    y1 = layers.AveragePooling1D(pool_size, strides, padding='same')(x)\n",
    "    y2 = layers.MaxPooling1D(pool_size, strides, padding='same')(x)\n",
    "    y = layers.Concatenate()([y1, y2])\n",
    "    return y\n",
    "\n",
    "def squeeze_and_excitation_block(x, ratio=16):\n",
    "    num_channels = x.shape[-1]\n",
    "    squeeze = layers.GlobalAveragePooling1D()(x)\n",
    "    excitation = layers.Dense(num_channels // ratio, activation='relu')(squeeze)\n",
    "    excitation = layers.Dense(num_channels, activation='sigmoid')(excitation)\n",
    "    excitation = layers.Reshape((1, num_channels))(excitation)\n",
    "    scale = layers.Multiply()([x, excitation])\n",
    "    return scale\n",
    "\n",
    "def residual_block_SERN_AwGOP(x, filters, kernel_size=5, downsample=False):\n",
    "    y = branched_nodal_operator(x, filters, kernel_size)\n",
    "    y = branched_nodal_operator(y, filters, kernel_size)\n",
    "\n",
    "    if downsample:\n",
    "        x = downsample_block(x, filters)\n",
    "\n",
    "    y = squeeze_and_excitation_block(y)\n",
    "\n",
    "    attention_weights = layers.Dense(1, activation='sigmoid')(x)\n",
    "    gop_out = layers.Multiply()([attention_weights, y])\n",
    "    gop_out = layers.Add()([gop_out, x])\n",
    "    gop_out = layers.Activation('relu')(gop_out)\n",
    "    return gop_out\n",
    "\n",
    "def create_SERN_AwGOP(input_shape, num_classes, filters):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv1D(filters[0], 5, strides=2, padding='same', activation='relu')(inputs)\n",
    "    x = layers.MaxPooling1D(pool_size=3, strides=2, padding='same')(x)\n",
    "\n",
    "    for f in filters[1:]:\n",
    "        x = residual_block_SERN_AwGOP(x, f, downsample=True)\n",
    "        x = residual_block_SERN_AwGOP(x, f)\n",
    "        x = residual_block_SERN_AwGOP(x, f)\n",
    "        x = residual_block_SERN_AwGOP(x, f)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    if num_classes == 2:\n",
    "        outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    else:\n",
    "        outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    if num_classes == 2:\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    else:\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val):\n",
    "    try:\n",
    "        history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "        return history\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in train_model: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, num_classes):\n",
    "    try:\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1) if num_classes > 2 else (y_pred > 0.5).astype(int).flatten()\n",
    "\n",
    "        results = {\n",
    "            'accuracy': float(accuracy_score(y_test, y_pred_classes)),\n",
    "            'precision_weighted': float(precision_score(y_test, y_pred_classes, average='weighted')),\n",
    "            'recall_weighted': float(recall_score(y_test, y_pred_classes, average='weighted')),\n",
    "            'f1_weighted': float(f1_score(y_test, y_pred_classes, average='weighted')),\n",
    "        }\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred_classes)\n",
    "        results['confusion_matrix'] = cm.tolist()  # Convert to list for JSON serialization\n",
    "        \n",
    "        if num_classes == 2:\n",
    "            sensitivity = cm[1,1] / (cm[1,1] + cm[1,0])\n",
    "            specificity = cm[0,0] / (cm[0,0] + cm[0,1])\n",
    "            results['sensitivity_unweighted'] = float(sensitivity)\n",
    "            results['specificity_unweighted'] = float(specificity)\n",
    "            results['auc_roc'] = float(roc_auc_score(y_test, y_pred))\n",
    "            results['average_precision'] = float(average_precision_score(y_test, y_pred))\n",
    "\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in evaluate_model: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "def simulate_hardware_issues(data, corruption_level):\n",
    "    corrupted_data = data.copy()\n",
    "    corruption_rate = corruption_level * 0.05\n",
    "    disconnection_rate = corruption_level * 0.02\n",
    "    saturation_threshold = 7.0 / corruption_level\n",
    "\n",
    "    # Simulate random noise (general corruption)\n",
    "    noise_mask = np.random.choice([0, 1], size=data.shape, p=[1-corruption_rate, corruption_rate])\n",
    "    corrupted_data[noise_mask.astype(bool)] = np.random.normal(loc=0, scale=0.5, size=corrupted_data[noise_mask.astype(bool)].shape)\n",
    "    \n",
    "    # Simulate electrode disconnections (set segments of channels to zero)\n",
    "    for channel in range(corrupted_data.shape[2]):  # Assuming shape is (samples, time_steps, channels)\n",
    "        if np.random.rand() < disconnection_rate:\n",
    "            segment_length = np.random.randint(low=1, high=data.shape[1] // 4)  # Random segment length\n",
    "            start = np.random.randint(low=0, high=data.shape[1] - segment_length)\n",
    "            corrupted_data[:, start:start+segment_length, channel] = 0\n",
    "    \n",
    "    # Simulate amplifier saturation (clipping)\n",
    "    corrupted_data = np.clip(corrupted_data, -saturation_threshold, saturation_threshold)\n",
    "    \n",
    "    return corrupted_data\n",
    "\n",
    "def save_results(results, dataset_name, experiment_type):\n",
    "    filename = f\"results/{dataset_name}_{experiment_type}_hw_corruption.json\"\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "def hardware_corruption_test(dataset, model_fn, filters):\n",
    "    try:\n",
    "        data = np.load(dataset['data'])\n",
    "        labels = np.load(dataset['labels'])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Train on clean data\n",
    "        model = model_fn(dataset['input_shape'], dataset['num_classes'], filters)\n",
    "        history = train_model(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        # Test with different levels of hardware corruption\n",
    "        corruption_levels = [1, 2, 3]  # Low, medium, high corruption\n",
    "        for level in corruption_levels:\n",
    "            corrupted_data = simulate_hardware_issues(X_test, level)\n",
    "            hw_results = evaluate_model(model, corrupted_data, y_test, dataset['num_classes'])\n",
    "            results[f'hardware_corruption_level_{level}'] = hw_results\n",
    "\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in hardware_corruption_test: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "def main():\n",
    "    datasets = [\n",
    "        {\"name\": \"CUSPH-SR-AF\", \"data\": \"data/data_2class_normal.npy\", \"labels\": \"data/labels_2class_normal.npy\", \"num_classes\": 2, \"input_shape\": (5000, 12)},\n",
    "    ]\n",
    "\n",
    "    filter_combinations = [[32, 64, 128]]\n",
    "\n",
    "    for dataset in datasets:\n",
    "        for filters in filter_combinations:\n",
    "            logging.info(f\"Processing dataset: {dataset['name']} with filters: {filters}\")\n",
    "\n",
    "            try:\n",
    "                # Hardware Corruption Test\n",
    "                hw_results = hardware_corruption_test(dataset, create_SERN_AwGOP, filters)\n",
    "                save_results(hw_results, dataset['name'], \"hardware_corruption\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing {dataset['name']}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    logging.info(\"All hardware corruption tests completed successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SERN-AwGOP-FPGA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
